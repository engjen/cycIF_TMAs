{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze TMAs <a name=\"intro\"></a> \n",
    "\n",
    "[contents](#contents)\n",
    "\n",
    "**Samples:** \n",
    "- JP-TMA-1 (survival data and patient characteristics: age, stage, tumor size)\n",
    "- JP-TMA-2 (mostly TNBC; only 2 ER+, survival data, some neoadjuvant)\n",
    "- IMC Basel TMA (survival data and patient characteristics)\n",
    "- IMC Zurich TMA (no survival data)\n",
    "- MIBI TMA (TNBC only, survival data)\n",
    "\n",
    "** note **\n",
    "\n",
    "Use only IMC images thats pass QC on ER staining.\n",
    "\n",
    "**Analysis**: \n",
    "\n",
    "- Mean cell fraction in tissue versus clinical outcome\n",
    "- Heiarchical clustering of patient tissues based on stromal and epithelial cell types\n",
    "- Correlation of stromal and epithelial cell types and subtypes\n",
    "- Comparison of immune cell types, fuctional status and clustering in high proliferation versus low proliferation tissues\n",
    "- Co-expression of functional markers (Patwa et al Comm Biol 2021)\n",
    "\n",
    "**Spatial  metrics**: \n",
    "\n",
    "Process counted cells with their XY coordinates in 20-40 microns radius from a single cell, then run the following: \n",
    "1.   Number of neighbors of pairs of cells (**Janiszewska et al.  JCI Insight, 2021**)\n",
    "   2. Mixing score (**Keren et al. Cell 2018**)\n",
    "3. Lymphocyte Clusters (**Wortman et al. npj Breast Cancer 2021**)\n",
    "4.   Homotypic and heterotypic interactions (**Ali et al. Nat Cancer 2020**)\n",
    "\n",
    "Additional spatial analyses\n",
    "\n",
    "1. Ripley’s L (a density normalized measure of clustering) (**spatstat**)\n",
    "2. Multitype K function (Kcross; a density normalized measure of two celltypes’ co-localization) (**spatstat**)\n",
    "3. Multitype G function (G cross; a measure of two celltypes’ co-localization) (**spatstat**)\n",
    "4. Spatial LDA Latent Dirichlet Allocation; (**Chen et al. J Comput Biol. 2020**), followed by kmeans clustering\n",
    "5. K means clustering of neighborhood counts (control for Chen et al. J Comput Biol. 2020)\n",
    "6. Voronoi interactions (**Patwa et al Comm Biol 2021**)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create environment\n",
    "\n",
    "After installing python3/miniconda, enter the following in the terminal to set up an `analysis` environment. \n",
    "\n",
    "**Automatically:**\n",
    "\n",
    "`conda env create -f environment.yml`\n",
    "\n",
    "`conda activate analysis`\n",
    "\n",
    "**Or manually:**\n",
    "\n",
    "`conda create -n analysis`\n",
    "\n",
    "`conda activate analysis`\n",
    "\n",
    "`conda install seaborn scikit-learn statsmodels numba pytables pandas ipykernel`\n",
    "\n",
    "`conda install -c conda-forge jupyterlab matplotlib python-igraph leidenalg scikit-image opencv tifffile libpysal shapely lifelines umap-learn napari scanpy statsmodels`\n",
    "\n",
    "`conda install -c anaconda psutil pysal pillow`\n",
    "\n",
    "`conda install -c bioconda anndata`\n",
    "\n",
    "`pip install DeepCell`\n",
    "\n",
    "`git clone https://gitlab.com/engje/mplex_image.git`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load libraries\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import seaborn as sns\n",
    "import math\n",
    "import warnings\n",
    "import importlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm, gridspec\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "mpl.rc('figure', max_open_warning = 0)\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import minmax_scale, scale, FunctionTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "import lifelines\n",
    "from lifelines import KaplanMeierFitter, CoxPHFitter\n",
    "from lifelines.statistics import multivariate_logrank_test\n",
    "from lifelines import exceptions\n",
    "warnings.filterwarnings(\"ignore\",category = exceptions.ApproximationWarning)\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import entropy, norm\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import statsmodels\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "import anndata\n",
    "from anndata import AnnData\n",
    "\n",
    "import util\n",
    "import plotting\n",
    "\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "mpl.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#original paths\n",
    "#update codedir to reflect to path where you have your code\n",
    "codedir = os.getcwd() #'/home/groups/graylab_share/Chin_Lab/ChinData/engje/Data/20200000/20200406_JP-TMAs'  \n",
    "\n",
    "#load mplex_imge: you will change this to location of mplex_image repo\n",
    "#os.chdir('/home/groups/graylab_share/Chin_Lab/ChinData/engje/Data')\n",
    "#os.chdir('..')\n",
    "#from mplex_image import visualize as viz#, process, preprocess, normalize, mics, mpimage\n",
    "#from spatial import spatial\n",
    "np.random.seed(912)\n",
    "\n",
    "#download data from synapse.org and place in folder called \"data\"\n",
    "# https://www.synapse.org/#!Synapse:syn50134757/. (Free account required).\n",
    "datadir = f'{codedir}/data'\n",
    "s_date = '20241112'#\n",
    "os.chdir(codedir)\n",
    "try:\n",
    "    if not os.path.exists(s_date):\n",
    "        os.mkdir(s_date)\n",
    "        os.mkdir(f'{s_date}/Survival_Plots')\n",
    "        os.mkdir(f'{s_date}/Survival_Plots_Both')\n",
    "    b_binder=False\n",
    "except:\n",
    "    print('binder')\n",
    "    b_binder=True\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents <a name=\"contents\"></a>\n",
    "0. [Intro](#intro)\n",
    "1. [functions](#func)\n",
    "2. [Load annotation](#loadold)\n",
    "3. [Load cell types and name](#cluster)\n",
    "4. [Tissue means](#tissue)\n",
    "5. [Single variable survival](#surv) [Spatial LDA survival](#clin)\n",
    "6. [Multivariable Subtyping](#subtIMC) [1 Platforms together (epithelial)](#st1) [2 Platforms separate (stromal)](#st2)  \n",
    "7. [Tissue correlation (Pearson & chi square)](#st3) [Spatial LDA correlation and survival](#lda_corr) [Figure 5 scatterplots](#lda_scatter)\n",
    "8. [Categorical Regression](#st4) [Neoadjuvant](#neoadj) 8a. [ER+ vs endothelial](#slide15) [TNBC, ER+ high low prolif](#byimmune)\n",
    "8. [Mixing score vs survival](#n1) \n",
    "9. [Boxplots Kmeans Neighborhoods](#leidneigh)  [Survival](#leidneighsurv)\n",
    "10. [Immune phenotype of proliferating tumors](#imph)  11a. [Tumor phenotype of tumor subtypes (CD44)](#imphCD44)\n",
    "11. [Immune spatial distribution](#imm_sp)  \n",
    "12. [Neighborhoods](#nbrhood)    [Lymphocyte Clusters](#agg)    [Ripleys K](#kest)    [Kcross](#kcross)     [Occupancy](#nolan)        [G cross](#gcross)\n",
    "12. [Correlation of spatial metrics](#metric)\n",
    "13. [**Immunoregulatory**](#sqpy)\n",
    "14. [**MIBI vs cycIF**](#mibivs)\n",
    "12. [Old](#dist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions <a name=\"func\"></a> \n",
    "\n",
    "\n",
    "[contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions\n",
    "from scipy.spatial import Delaunay, delaunay_plot_2d, Voronoi, voronoi_plot_2d\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "import seaborn\n",
    "from itertools import combinations\n",
    "from itertools import product\n",
    "\n",
    "#from patwa et al\n",
    "\n",
    "def create_voronoi(centdf): #returns the Voronoi diagram object\n",
    "    vor = Voronoi(np.c_[centdf.column.values, centdf.row.values])\n",
    "    return vor\n",
    "def plot_voronoi(vor, identifier): #Void - just plots the graph\n",
    "    fig, ax = plt.subplots(figsize=(16, 16))\n",
    "\n",
    "    fig = voronoi_plot_2d(vor, ax, show_vertices=False, line_colors='blue', \n",
    "                      line_width=2, point_size=2)\n",
    "    ax.set_xlim([0, 2048])\n",
    "    ax.set_ylim([2048, 0])\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"/Users/aalokpatwa/Desktop/MIBI/voronoi/voronoi_plotsv2/\" + identifier + \".pdf\", dpi=300)\n",
    "    plt.close()\n",
    "    #plt.show()\n",
    "\n",
    "def make_voronoi_dataframe(voronoi, centroiddf):\n",
    "    count_skipped = 0\n",
    "    number_centroids = voronoi.points.shape[0]\n",
    "    information_list = []\n",
    "    for centroid in range(number_centroids):\n",
    "        centroid_list = []\n",
    "        centroid_y = voronoi.points[centroid][0]\n",
    "        centroid_x = voronoi.points[centroid][1]\n",
    "        centroid_list.append(centroid)\n",
    "        centroid_list.append((centroid_x, centroid_y))\n",
    "        region_index = voronoi.point_region[centroid]\n",
    "        centroid_list.append(region_index)\n",
    "        vertices = voronoi.regions[region_index]\n",
    "        if -1 in vertices:\n",
    "            count_skipped += 1\n",
    "            continue\n",
    "        else:\n",
    "            vertex_list = []\n",
    "            for vertex in vertices:\n",
    "                y_coord = int(round(voronoi.vertices[vertex][0]))\n",
    "                x_coord = int(round(voronoi.vertices[vertex][1]))\n",
    "                vertex_list.append((y_coord, x_coord))\n",
    "            centroid_list.append(vertex_list)\n",
    "        centroid_list.append(centroiddf.at[centroid, \"celltype\"])\n",
    "        information_list.append(centroid_list)       \n",
    "    infodf = pd.DataFrame(information_list, columns=[\"CentroidIndex\",\"CentroidCoord\", \"RegionIndex\",\n",
    "                                                     \"Vertices\", \"Celltype\"])\n",
    "    return infodf, count_skipped\n",
    "\n",
    "def extract_current_mask(vertexlist):\n",
    "    img = Image.new(\"L\", (2048,2048), 0)\n",
    "    ImageDraw.Draw(img).polygon(vertexlist, fill=1)\n",
    "    mask = np.array(img)\n",
    "    binary_mask = np.where(mask==1)\n",
    "    coordinates = list(zip(binary_mask[0], binary_mask[1]))\n",
    "    return coordinates, len(coordinates)\n",
    "\n",
    "def expression_within_cell(biomarker_image, pixellist, size):\n",
    "    total_vector = np.zeros(44)\n",
    "    for pixel in pixellist:\n",
    "        expression_vector = biomarker_image[pixel[0], pixel[1]]\n",
    "        total_vector += expression_vector\n",
    "    total_vector = total_vector / size\n",
    "    return total_vector\n",
    "\n",
    "def create_multimarker_image(imagepath):\n",
    "    biomarker_pil = Image.open(imagepath)\n",
    "    n_frames = biomarker_pil.n_frames\n",
    "    \n",
    "    first_level = np.array(biomarker_pil, dtype=\"uint8\")\n",
    "    first_level = np.reshape(first_level, (2048,2048,1))\n",
    "        \n",
    "    combined_image = first_level\n",
    "    \n",
    "    for frame in range(1, n_frames):\n",
    "        biomarker_pil.seek(frame)\n",
    "        current_level = np.array(biomarker_pil, dtype=\"uint8\").reshape((2048,2048,1))\n",
    "        combined_image = np.concatenate((combined_image, current_level), axis=2)\n",
    "    return combined_image\n",
    "\n",
    "def create_neighbor_matrix(voronoi, voronoi_df):\n",
    "    number_regions = len(voronoi_df.index)\n",
    "    adjacency_list = []\n",
    "    for region in range(number_regions):\n",
    "        adjacency_list.append([])\n",
    "    ridge_points = voronoi.ridge_points\n",
    "    for edge in ridge_points:\n",
    "        first_centroid = edge[0]\n",
    "        second_centroid = edge[1]\n",
    "        first_cell = voronoi_df[voronoi_df[\"CentroidIndex\"] == first_centroid]\n",
    "        second_cell = voronoi_df[voronoi_df[\"CentroidIndex\"] == second_centroid]\n",
    "        if (first_cell.empty or second_cell.empty):\n",
    "            continue\n",
    "        first_index = int(first_cell.index[0])\n",
    "        second_index = int(second_cell.index[0])\n",
    "        adjacency_list[first_index].append(second_centroid)\n",
    "        adjacency_list[second_index].append(first_centroid)\n",
    "    new_df = voronoi_df.copy()\n",
    "    new_df[\"Adjacency\"] = adjacency_list\n",
    "    return new_df\n",
    "\n",
    "# author: engjen\n",
    "def pie_chart_labels(df):\n",
    "    s_name = df.index.name\n",
    "    labels = [f'{s_name} {item}' for item in df.index]\n",
    "    percentages = [x for x in df.iloc[:,0]]\n",
    "    linebreak = '\\n'\n",
    "    return [f'{p}{linebreak}{i} Pts.' for p,i in zip(labels,percentages)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load annotation <a name=\"loadold\"></a>\n",
    "\n",
    "- patient\n",
    "- clinical subtype\n",
    "- clinical outcome\n",
    "\n",
    "[contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cyclic patients and subtypes\n",
    "df_cyc_sub = pd.read_csv(f'data/JP-TMAs_CoreID_Clinical-Subtype.csv',index_col=0)\n",
    "#collapse Subtypes\n",
    "d_replace = {'0':'other','?':'other', np.nan:'other'}\n",
    "df_cyc_sub['ID'] = df_cyc_sub.ID.replace(d_replace)\n",
    "df_cyc_sub.loc[df_cyc_sub.index.str.contains('JP-TMA2-1'),'Accession'] = df_cyc_sub.loc[df_cyc_sub.index.str.contains('JP-TMA2-1')].index\n",
    "#add subtype and patient\n",
    "d_cyc_sub = dict(zip(df_cyc_sub.index.tolist(),df_cyc_sub.ID.tolist()))\n",
    "d_patient = dict(zip(df_cyc_sub.index,df_cyc_sub.Accession))\n",
    "# JP-TMA2 subtypes\n",
    "d_cyc_sub2 = {'JP-TMA2-1_scene01': 'TNBC', 'JP-TMA2-1_scene02': 'TNBC', 'JP-TMA2-1_scene03': 'TNBC', 'JP-TMA2-1_scene04': 'TNBC',\n",
    " 'JP-TMA2-1_scene05': 'TNBC', 'JP-TMA2-1_scene06': 'TNBC', 'JP-TMA2-1_scene07': 'TNBC', 'JP-TMA2-1_scene08': 'ER+HER2+',\n",
    " 'JP-TMA2-1_scene09': 'TNBC', 'JP-TMA2-1_scene10': 'TNBC', 'JP-TMA2-1_scene11': 'TNBC', 'JP-TMA2-1_scene12': 'TNBC',\n",
    " 'JP-TMA2-1_scene13': 'TNBC', 'JP-TMA2-1_scene14': 'TNBC', 'JP-TMA2-1_scene15': 'TNBC', 'JP-TMA2-1_scene16': 'TNBC',\n",
    " 'JP-TMA2-1_scene17': 'TNBC', 'JP-TMA2-1_scene18': 'TNBC', 'JP-TMA2-1_scene19': 'TNBC', 'JP-TMA2-1_scene20': 'TNBC',\n",
    " 'JP-TMA2-1_scene21': 'TNBC', 'JP-TMA2-1_scene22': 'TNBC', 'JP-TMA2-1_scene23': 'TNBC', 'JP-TMA2-1_scene24': 'TNBC',\n",
    " 'JP-TMA2-1_scene25': 'TNBC', 'JP-TMA2-1_scene26': 'TNBC', 'JP-TMA2-1_scene27': 'TNBC', 'JP-TMA2-1_scene28': 'TNBC',\n",
    " 'JP-TMA2-1_scene29': 'TNBC', 'JP-TMA2-1_scene30': 'TNBC', 'JP-TMA2-1_scene31': 'TNBC', 'JP-TMA2-1_scene32': 'TNBC',\n",
    " 'JP-TMA2-1_scene33': 'TNBC', 'JP-TMA2-1_scene34': 'TNBC', 'JP-TMA2-1_scene35': 'TNBC', 'JP-TMA2-1_scene36': 'TNBC',\n",
    " 'JP-TMA2-1_scene37': 'TNBC', 'JP-TMA2-1_scene38': 'TNBC', 'JP-TMA2-1_scene39': 'TNBC', 'JP-TMA2-1_scene40': 'TNBC',\n",
    " 'JP-TMA2-1_scene41': 'TNBC', 'JP-TMA2-1_scene42': 'TNBC',} #'HR+HER2+'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data wrangling from various sources (already done)\n",
    "# #survival\n",
    "# df_surv_cyc = pd.read_csv(f'{codedir}/data/cycIF_clinical_outcome.csv',index_col=0)\n",
    "# df_surv_cyc['Platform'] = 'cycIF'\n",
    "# df_surv_cyc.rename({'Recurence_time':'Recurrence_time'},axis=1,inplace=True)\n",
    "\n",
    "# # clinical variables\n",
    "# df_cyc_a = pd.read_csv('annotation/JP-TMAs_Clinical_Variables.csv',index_col=0)\n",
    "\n",
    "# #combine\n",
    "# d_sub_both = dict(zip(df_cyc_sub.Accession,df_cyc_sub.ID))\n",
    "# d_sub_both.update(d_cyc_sub2)\n",
    "# df_surv_cyc['subtype'] = df_surv_cyc.index.map(d_sub_both)\n",
    "# df_surv_cyc.head()\n",
    "# #load validation data (available on request)\n",
    "# df_tma2 = pd.read_excel(f'{codedir}/annotation/JP-TMA2_TMA101+followup+map.xlsx',\n",
    "#                          sheet_name='FU')\n",
    "\n",
    "# df_tma2_surv = df_tma2.rename({'CycIF ID':'Matrix'},axis=1).merge(df_cyc_sub.loc[df_cyc_sub.index.str.contains('JP-TMA2'),['TMA_scene.1','Matrix','ID']],on='Matrix').sort_values(by='Matrix')\n",
    "# d_rename_surv_names = {'RSF_time':'Recurrence_time',\n",
    "#                        'RSF_status':'Recurrence',\n",
    "#                        'OS_time':'Survival_time',\n",
    "#                        'OS_status':'Survival'\n",
    "#                       }\n",
    "# df_tma2_surv = df_tma2_surv.set_index('TMA_scene.1').rename(d_rename_surv_names,axis=1)\n",
    "# df_tma2_surv.sort_values(by ='Matrix')\n",
    "\n",
    "\n",
    "# ls_surv_col = ['Survival', 'Survival_time', 'Recurrence', 'Recurrence_time']\n",
    "# df_surv_val = df_tma2_surv.loc[:,ls_surv_col].copy()\n",
    "# df_surv_val['Platform'] = 'cycIF'\n",
    "# df_surv_val['subtype'] = 'TNBC'\n",
    "# #months to days\n",
    "# for s_months in ['Survival_time','Recurrence_time']:\n",
    "#     df_surv_val.loc[:,s_months] = df_surv_val.loc[:,s_months] * 30.437\n",
    "# df_surv_val.head()\n",
    "# # add in TMA2\n",
    "# df_surv_cyc = pd.concat([df_surv_cyc,df_surv_val])\n",
    "\n",
    "\n",
    "# #add neoadjuvant treatment\n",
    "# # ls_neo = ['FAC','Adriam+cytoxan']\n",
    "# # df_cyc_a[df_cyc_a.Neo_adj_trt_Y_or_N.isin(ls_neo)].index\n",
    "# # ls_neo_pts_1 = ['98-15913-C', '97-19088-2K', '03-7604-1P', '95-20479-2B']\n",
    "# # df_tma2[df_tma2.NAT!='no'].loc[:,'CycIF ID'].tolist()\n",
    "# # ls_neo_pts_2 = ['A3','B3','C3','D4','E4','F3','F4', 'G1','G4',\n",
    "# #  'H4','I2','I4','I5','J4','J5']\n",
    "# #df_tma2_surv[df_tma2_surv.Matrix.isin(ls_neo_pts_2)].index\n",
    "\n",
    "# ls_neo_pts = ['JP-TMA2-1_scene03', 'JP-TMA2-1_scene07', 'JP-TMA2-1_scene11',\n",
    "#        'JP-TMA2-1_scene16', 'JP-TMA2-1_scene20', 'JP-TMA2-1_scene23',\n",
    "#        'JP-TMA2-1_scene24', 'JP-TMA2-1_scene25', 'JP-TMA2-1_scene28',\n",
    "#        'JP-TMA2-1_scene31', 'JP-TMA2-1_scene34', 'JP-TMA2-1_scene36',\n",
    "#        'JP-TMA2-1_scene37', 'JP-TMA2-1_scene41', 'JP-TMA2-1_scene42',\n",
    "#              '98-15913-C', '97-19088-2K', '03-7604-1P', '95-20479-2B']\n",
    "# df_surv_cyc['Neoadjuvant'] = False\n",
    "# df_surv_cyc.loc[df_surv_cyc.index.isin(ls_neo_pts),'Neoadjuvant']=True\n",
    "\n",
    "# #IMC annotation\n",
    "# # download IMC data from Zenodo\n",
    "# # instructions at https://github.com/BodenmillerGroup/SCPathology_publication\n",
    "# # specify the folder where you put the data\n",
    "# imcdir = '/home/groups/graylab_share/Chin_Lab/ChinData/engje/Data/IMC_Data_publication'\n",
    "# df_a = pd.read_csv(f'{imcdir}/BaselTMA/Basel_PatientMetadata.csv')\n",
    "# df_z = pd.read_csv(f'{imcdir}/ZurichTMA/Zuri_PatientMetadata.csv',index_col=0)\n",
    "# df_z['PID'] = ['Z'+item.split('_')[2] for item in df_z.core]\n",
    "# df_a = pd.concat([df_a,df_z]) \n",
    "# df_imc_a = pd.DataFrame(data=pd.Series(data=dict(zip(df_a.PID,df_a.clinical_type))),columns=['subtype'])\n",
    "\n",
    "# df_imc_a['Survival_time'] = df_imc_a.index.map(dict(zip(df_a.PID,df_a.OSmonth)))/12*365\n",
    "# df_imc_a['Survival'] = df_imc_a.index.map(dict(zip(df_a.PID,df_a.Patientstatus.str.contains('death'))))\n",
    "# df_imc_a['Survival'] = df_imc_a.Survival.replace({True:1,False:0})\n",
    "# # recurrence\n",
    "# df_imc_a['Recurrence_time'] = df_imc_a.index.map(dict(zip(df_a.PID,df_a.DFSmonth)))/12*365\n",
    "# df_imc_a['Recurrence'] = df_imc_a.index.map(dict(zip(df_a.PID,(df_a.Patientstatus.str.contains('death') | df_a.Patientstatus.str.contains('metastases')))))\n",
    "# df_imc_a['Recurrence'] = df_imc_a.Recurrence.replace({True:1,False:0})\n",
    "# df_imc_a['Platform'] = 'IMC'\n",
    "# df_imc_a['subtype'] = df_imc_a.subtype.replace({'TripleNeg':'TNBC','HR+HER2-':'ER+'})\n",
    "\n",
    "# #\n",
    "# df_surv2 = pd.concat([df_surv_cyc,df_imc_a]) \n",
    "# df_imc_a.head()\n",
    "\n",
    "# #MIBI: dowload clinical data from \n",
    "# # https://github.com/aalokpatwa/rasp-mibi/tree/main/rawdata\n",
    "# # specify directory where you put it\n",
    "# mibidir = '/home/groups/graylab_share/Chin_Lab/ChinData/engje/Data/Keren et al_'\n",
    "# df_mib_a = pd.read_csv(f'{mibidir}/clinical_data.csv',index_col=0)\n",
    "# df_mib_a['Platform'] = 'MIBI'\n",
    "# df_mib_a['subtype'] = 'TNBC'\n",
    "# df_mib_a.index = ['M'+str(item) for item in df_mib_a.index]\n",
    "# df_surv = pd.concat([df_surv2,df_mib_a])\n",
    "# df_mib_a.head()\n",
    "\n",
    "# # more IMC data\n",
    "# df_stain_IMC = pd.read_csv(f'{imcdir}/Basel_Zuri_StainingPanel.csv')\n",
    "\n",
    "# #load qc (see paper for explanation)\n",
    "# df_qc = pd.read_csv(f'{imcdir}/Basel_Zurich_ER_QC.csv')\n",
    "# df_qc.rename({'Unnamed: 0':'FileName_FullStack'},axis=1,inplace=True)\n",
    "# df_qc = df_a.merge(df_qc,on='FileName_FullStack')\n",
    "# df_qc['name'] = [item.split('2017')[1] for item in df_qc.loc[:,'FileName_FullStack']]\n",
    "# df_qc['slide_scene'] = [f\"{item.split('_')[2]}_{item.split('_')[3]}-{item.split('_')[4]}\" for item in df_qc.name]\n",
    "\n",
    "# # add cyclic samples with survival data withheld from training\n",
    "# df_surv.subtype = df_surv.subtype.replace({'HR-HER2+':'HER2+','HR+HER2+':'ER+HER2+'})\n",
    "\n",
    "# ls_index = ['JP-TMA2-1_scene01', 'JP-TMA2-1_scene02', 'JP-TMA2-1_scene03',\n",
    "#        'JP-TMA2-1_scene04', 'JP-TMA2-1_scene05', 'JP-TMA2-1_scene06',\n",
    "#        'JP-TMA2-1_scene07', 'JP-TMA2-1_scene08', 'JP-TMA2-1_scene09',\n",
    "#        'JP-TMA2-1_scene10', 'JP-TMA2-1_scene11', 'JP-TMA2-1_scene12',\n",
    "#        'JP-TMA2-1_scene13', 'JP-TMA2-1_scene14', 'JP-TMA2-1_scene15',\n",
    "#        'JP-TMA2-1_scene16', 'JP-TMA2-1_scene17', 'JP-TMA2-1_scene18',\n",
    "#        'JP-TMA2-1_scene19', 'JP-TMA2-1_scene20', 'JP-TMA2-1_scene21',\n",
    "#        'JP-TMA2-1_scene22', 'JP-TMA2-1_scene23', 'JP-TMA2-1_scene24',\n",
    "#        'JP-TMA2-1_scene25', 'JP-TMA2-1_scene26', 'JP-TMA2-1_scene27',\n",
    "#        'JP-TMA2-1_scene28', 'JP-TMA2-1_scene29', 'JP-TMA2-1_scene30',\n",
    "#        'JP-TMA2-1_scene31', 'JP-TMA2-1_scene32', 'JP-TMA2-1_scene33',\n",
    "#        'JP-TMA2-1_scene34', 'JP-TMA2-1_scene35', 'JP-TMA2-1_scene36',\n",
    "#        'JP-TMA2-1_scene37', 'JP-TMA2-1_scene38', 'JP-TMA2-1_scene39',\n",
    "#        'JP-TMA2-1_scene40', 'JP-TMA2-1_scene41', 'JP-TMA2-1_scene42']\n",
    "# if not df_surv.index.isin(ls_index).any():\n",
    "#     print('appending TMA2')\n",
    "#     df_to_append =pd.DataFrame(index=ls_index,data='cycIF',columns=['Platform'])\n",
    "#     df_surv = pd.concat([df_surv,df_to_append]) \n",
    "#     df_surv.loc[ls_index,'subtype'] = 'TNBC'\n",
    "# if not df_surv.index.isin(['M22', 'M38']).any():\n",
    "#     print('appending MIBI')\n",
    "#     df_to_append = pd.DataFrame(index=['M22', 'M38'],data='MIBI',columns=['Platform'])\n",
    "#     df_to_append['subtype'] = 'TNBC'\n",
    "#     df_surv = pd.concat([df_surv,df_to_append]) \n",
    "# #error in recurrence time\n",
    "# df_surv.loc[(df_surv.Platform=='cycIF')&(df_surv.Recurrence==0),'Recurrence_time'] = df_surv.loc[(df_surv.Platform=='cycIF')&(df_surv.Recurrence==0),'Survival_time']\n",
    "# df_surv.loc['JP-TMA2-1_scene08','subtype'] = 'ER+HER2+'\n",
    "# df_surv.loc['NB-05-12002','Platform'] = 'cycIF'\n",
    "# #strings!\n",
    "# df_surv.index = df_surv.index.astype('str')\n",
    "\n",
    "# #clinical variables\n",
    "# import re\n",
    "# #IMC\n",
    "# df_imc_a = df_a[df_a.diseasestatus=='tumor'].copy()\n",
    "# df_imc_a['Stage'] = [re.sub(\"[^0-9]\", \"\",str(item)) for item in df_imc_a.loc[:,'PTNM_T']]\n",
    "# df_imc_a['N_Stage'] = [re.sub(\"[^0-9]\", \"\",str(item)) for item in df_imc_a.loc[:,'PTNM_N']]\n",
    "# df_imc_a.index = df_imc_a.PID\n",
    "\n",
    "# #cyclic\n",
    "# df_cyc_a['Stage'] = [re.sub(\"[^0-9]\", \"\",str(item)).replace('99','').replace('0','') for item in df_cyc_a.loc[:,'PathT']]\n",
    "# df_cyc_a['N_Stage'] = [re.sub(\"[^0-9]\", \"\",str(item)).replace('99','').replace('0','') for item in df_cyc_a.loc[:,'PathN']]\n",
    "\n",
    "# d_replace = {'Age_at_diagnosis':'age', }\n",
    "# df_cyc_a = df_cyc_a.rename(d_replace,axis=1)\n",
    "# d_path = {'unknown':np.nan, 'small':'1', '< 2':'1', '??':np.nan, 'T2':'3.5'}\n",
    "# df_cyc_a['tumor_size'] = df_cyc_a.path_size.replace(d_path).astype('float64')\n",
    "# #df_cyc_a.columns\n",
    "\n",
    "# #both\n",
    "# df_clin = df_imc_a.loc[~df_imc_a.index.duplicated(),['age','grade', 'tumor_size','Stage','N_Stage']]\n",
    "# df_clin = pd.concat([df_clin,df_cyc_a.loc[:,['age', 'tumor_size','Stage','N_Stage']]])\n",
    "# df_clin.index = df_clin.index.astype('str')\n",
    "\n",
    "# ### add jp-TMA2 clincal variables\n",
    "# d_stage_name = {'IIB':'2', 'IIA':'2', 'III':'3', 'I':'1', '2A':'2',\n",
    "#                  'yIIIA':'3', 'yIIA':'2', 'I ':'1', 'IIIC':'3','II':'2',\n",
    "#                  'IIIA':'3', 'yI':'1', 'yIIIC':'3', 'IIA ':'2',\n",
    "#                  'IIA\\xa0':'2', 'yIIB':'2', 'y0':'0'}\n",
    "# df_tma2_surv['Stage'] = df_tma2_surv.Stage.replace(d_stage_name)\n",
    "# df_tma2_surv['tumor_size'] = (df_tma2_surv.loc[:,'T size']*10)\n",
    "# df_tma2_surv['age'] = df_tma2_surv.loc[:,'Age at dx']\n",
    "# df_tma2_surv.loc[:,['age', 'tumor_size','Stage']].dropna(how='any')\n",
    "\n",
    "# df_clin = pd.concat([df_clin,df_tma2_surv.loc[:,['age', 'tumor_size','Stage']]])\n",
    "# df_clin.loc[:,['age', 'tumor_size','Stage']].dropna(how='any')\n",
    "\n",
    "# df_surv.loc['NB-05-12002','subtype'] = 'Normal Breast'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save (done)\n",
    "# if not os.path.exists('TMA_Survival_Subtype.csv'):\n",
    "#     print('saving')\n",
    "#     df_surv.to_csv('TMA_Survival_Subtype.csv')\n",
    "\n",
    "#load survival data\n",
    "df_surv = pd.read_csv('data/TMA_Survival_Subtype.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save (done)\n",
    "# if not os.path.exists('TMA_Clinical_Variables.csv'):\n",
    "#     print('saving')\n",
    "#     df_clin.to_csv('TMA_Clinical_Variables.csv')\n",
    "\n",
    "#load clinical data\n",
    "df_clin = pd.read_csv('data/TMA_Clinical_Variables.csv',index_col=0)\n",
    "df_clin.dropna(how='all',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_drop = df_surv[~df_surv.subtype.isin(['ER+','TNBC','ER+HER2+','HER2+'])].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clin['Platform'] = pd.NA\n",
    "df_clin.loc[df_clin.index.str.contains('-'),'Platform'] = 'cycIF'\n",
    "df_clin['Platform'] = df_clin.Platform.fillna('IMC')\n",
    "#df_clin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "for s_clin in ['Stage','grade']:\n",
    "    df = pd.DataFrame(df_clin.loc[~df_clin.index.isin(ls_drop),s_clin].value_counts())\n",
    "    df.index.name = s_clin\n",
    "    df.rename({'count':'No. Pts.'},axis=1,inplace=True)\n",
    "    # if s_clin == 'Stage':\n",
    "    #     df.drop('',inplace=True)\n",
    "    df.to_csv(f'Table_of_{s_clin}.csv')\n",
    "    df.sort_index(inplace=True,ascending=True)\n",
    "    fig, ax = plt.subplots(dpi=300)\n",
    "    ax.pie(df.loc[:,'No. Pts.'],labels=pie_chart_labels(df),autopct='%1.1f%%',\n",
    "           startangle=0,pctdistance=0.7)\n",
    "    ax.set_title(s_clin)\n",
    "    fig.savefig(f'{s_date}/pie_{s_clin}.pdf')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#separate cohorts\n",
    "for s_subtype in ['ER+','TNBC']:\n",
    "    df_count_total= pd.DataFrame()\n",
    "    ls_keep = df_surv[df_surv.subtype==s_subtype].index #,'ER+HER2+','HER2+'\n",
    "    ls_drop_stage = ['','0']\n",
    "    width = 0.8\n",
    "    for s_clin in ['Stage','grade']:\n",
    "        df = df_clin.loc[(df_clin.index.isin(ls_keep)) & (~df_clin.loc[:,s_clin].isin(ls_drop_stage)),[s_clin,'Platform']].groupby('Platform').value_counts(normalize=True)\n",
    "        df_count = df_clin.loc[(df_clin.index.isin(ls_keep)) & (~df_clin.loc[:,s_clin].isin(ls_drop_stage)),[s_clin,'Platform']].groupby('Platform').value_counts()\n",
    "        df = df.reset_index().rename({'proportion':'No. Pts.'},axis=1)\n",
    "        df.sort_values(by=s_clin,inplace=True)\n",
    "        fig,ax=plt.subplots(figsize=(2,3),dpi=300)\n",
    "        bottom = np.zeros(2)\n",
    "        species = sorted(df.loc[:,'Platform'].unique())\n",
    "        weight_counts = {}\n",
    "        if s_clin == 'Stage':\n",
    "            df_count_total = pd.concat([df_count_total,df_count])\n",
    "        for s_stage in df.loc[:,s_clin].unique():\n",
    "            print(s_stage)\n",
    "            df_stage = df[df.loc[:,s_clin]==s_stage]\n",
    "            try:\n",
    "                v1 = df_stage.loc[df_stage.Platform==species[0],'No. Pts.'].values[0]\n",
    "            except:\n",
    "                v1=0\n",
    "            try:\n",
    "                v2 = df_stage.loc[df_stage.Platform==species[1],'No. Pts.'].values[0]\n",
    "            except:\n",
    "                v2=0\n",
    "            a = np.array([v1,v2])\n",
    "            weight_counts.update({s_stage:a})\n",
    "        for boolean, weight_count in weight_counts.items():\n",
    "            p = ax.bar(species, weight_count, width, label=boolean, bottom=bottom)\n",
    "            bottom += weight_count\n",
    "        plt.legend(bbox_to_anchor=(1,1),title=s_clin)\n",
    "        ax.set_title(f'{s_clin} vs. Platform in {s_subtype}\\n n={len(a)}')\n",
    "        ax.set_ylim(0,1.05)\n",
    "        fig.savefig(f'{s_date}/pie_{s_clin}_{s_subtype}.pdf')\n",
    "        #break\n",
    "    print(f'{s_subtype} {df_count_total.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_venn = pd.read_excel('data/marker_panels.xlsx',sheet_name=None,header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install -y -c conda-forge matplotlib-venn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib_venn import venn3, venn3_circles\n",
    "from matplotlib_venn import venn2, venn2_circles, venn2_unweighted\n",
    "ls_drop = set(['Antigen', 'Cytokeratins','Adhesion Molecules', 'Hormone Receptors','RTK Signaling','Endothelial', \n",
    "          'Stromal Markers', 'Epigenetic Mark','Transcription Factors','Cell Growth and Division','Immune Context',\n",
    "          'Nuclear','Cell Death',np.nan])\n",
    "\n",
    "\n",
    "#venn\n",
    "d_marker = {}\n",
    "for s_plat in d_venn.keys():\n",
    "    d_venn[s_plat]\n",
    "    es_marker = set(d_venn[s_plat].iloc[:,0]) | set(d_venn[s_plat].iloc[:,2])\n",
    "    es_marker = es_marker - ls_drop\n",
    "    d_marker.update({s_plat:es_marker})\n",
    "fig,ax = plt.subplots(figsize=(4,2.5),dpi=300)\n",
    "venn3([d_marker['CycIF'], d_marker['IMC'], d_marker['MIBI']], ('CycIF', 'IMC', 'MIBI'),ax=ax)\n",
    "ax.set_title('Marker Overlap')\n",
    "fig.savefig(f'{s_date}/marker_overlap.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#neo vs survival plot\n",
    "df_surv.Neoadjuvant = df_surv.Neoadjuvant.replace({True:'Yes',False:'No'})\n",
    "importlib.reload(plotting)\n",
    "s_col = 'Neoadjuvant'\n",
    "for s_time, s_censor in [('Survival_time','Survival'),('Recurrence_time','Recurrence')]:\n",
    "    for s_subtype in ['TNBC','ER+','both']:\n",
    "        df=df_surv.loc[df_surv.subtype==s_subtype,[s_col,s_time, s_censor]].dropna()\n",
    "        if s_subtype == 'both':\n",
    "            s_subtype = ''\n",
    "            df=df_surv.loc[df_surv.subtype.isin(['ER+','TNBC']),[s_col,s_time, s_censor]].dropna()\n",
    "        fig,ax,ls_order = plotting.km_plot_cat(df,s_col,s_time,s_censor,fontsize='medium',loc='upper center')\n",
    "        ax.set_title(f'Neoadjuvant {s_subtype}')\n",
    "        fig.savefig(f'{s_date}/Neoadjuvant_{s_subtype}_{s_censor}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = df_clin.merge(df_surv,left_index=True,right_index=True,suffixes=('','_x'))\n",
    "df_p = df_p[(df_p.Neoadjuvant.notna()) & (df_p.subtype.isin(['TNBC','ER+']))]\n",
    "s_marker= 'Neoadjuvant'\n",
    "for s_time, s_censor in [('Survival_time','Survival'),('Recurrence_time','Recurrence')]:\n",
    "    fig2,ax,cph,df_marker = plotting.clinical_cph(df_p,s_marker,s_time,s_censor,\n",
    "                    alpha=1,ls_clin=['age','tumor_size','Stage'],figsize=(3.2,1.6))\n",
    "    ax.set_title(f'{s_marker} {s_censor}\\np={cph.summary.loc[s_marker,\"p\"]:.2} n={len(df_marker)}')\n",
    "    plt.tight_layout()\n",
    "    fig2.savefig(f'{s_date}/Neoadjuvant_CPH_{s_censor}.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cph.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_marker.Neoadjuvant.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result, pvalue = stats.ttest_ind(df_marker.loc[df_marker.Neoadjuvant,'tumor_size'],df_marker.loc[~df_marker.Neoadjuvant,'tumor_size'])\n",
    "fig,ax=plt.subplots(dpi=300,figsize=(3,3))\n",
    "sns.stripplot(data=df_marker,x='Neoadjuvant',y='tumor_size',ax=ax,alpha=0.7,hue='Neoadjuvant',legend=False)\n",
    "ax.set_title(f'Neoadjuvant vs Tumor size\\nT-test p={pvalue:.2} n={len(df_marker)}')\n",
    "plt.tight_layout()\n",
    "fig.savefig(f'{s_date}/Neoadjuvant_tumor_size.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_marker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and name cell types  <a name=\"cluster\"></a>\n",
    "\n",
    "- leiden results\n",
    "    - anotate\n",
    "- mean intensity\n",
    "\n",
    "\n",
    "[contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name celltypes\n",
    "\n",
    "d_celltype_cycif = {'4':'Luminal ER+ t.', '12':'Basal t.', '15':'HER2+ Ki67+ t.', '18':'HER2++ t.','22':'HER2++ t.', '19':'endothelial', '20':'EGFR+ t.', '5':'Prolif. t.',\n",
    " '9':'Macrophage', '17':'Myoepithelial', '14':'ColI+ FB', '6':'Vim+ FB', '10':'FB', '16':'Quies. str.', '8':'Quies. str.',\n",
    " '2':'Vim+ FB', '7':'CK lo. t.', '3s':'CD44+ str.', '3t':'CD44+ t.', '0':'Luminal t.', '11':'CK lo. t.', '13':'CD8 T cell',\n",
    " '1':'CD4 T cell', '21':'CD20 B cell'}\n",
    "\n",
    "#new 4/13\n",
    "d_celltype_IMC = {'7b':'Basal t.', '21':'Luminal ER+ t.', '22':'EGFR+ t.', '23':'Luminal ER+ t.', '13':'HER2+ ER+ t.',\n",
    " '16':'HER2+ ER+ PR+ t.', '14':'Luminal ER+ t.', '2':'Luminal ER+ t.', '17':'CD44+ t.', '12':'Prolif. t.',\n",
    " '7':'Myoepithelial', '10':'CK lo. t.', '11':'Luminal ER+ t.', '18':'Luminal t.', '19':'HER2+ Ki67+ t.',\n",
    " '4':'HER2+ ER+ t.', '6':'FN+ FB', '3':'Vim+ FB', '1':'Luminal t.', #or CKlo?\n",
    " '0':'Quies. str.', '5':'Quies. str.','0b':'FN+ FB','7c':'Pericyte SMA+FB',\n",
    " '9':'CD3 T cell', '9b':'CD20 B cell', '15':'Macrophage', '8':'endothelial'}\n",
    "\n",
    "#update 4/12\n",
    "d_celltype_MIBI = {'3':'CD4 T cell','3b':'CD20 B cell', '3c':'Dendritic cell', '2b':'CD8 T cell', '2':'CD4 T cell', '17':'FoxP3 Treg',\n",
    " '7':'Basal t.', '15':'PD-L1+ Basal t.', '14':'IDO+ Basal t.', '14b':'Dendritic cell', '18':'NK cell', '12':'endothelial',\n",
    " '20':'CD209+ imm.', #DC-SIGN  # artifact'21':'quiesc str',\n",
    " '9':'Prolif. t.', '6':'CK lo. t.', '5':'Myoepithelial', '19':'EGFR+ t.', '11':'CD63+ t.', '13':'CK lo. t.',\n",
    " '1':'FB', '4':'Quies. str.', '0':'Luminal t.', '8':'EGFR+ Basal t.', '10':'Macrophage', '16':'Neutrophil'} #0412"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leiden clustering results\n",
    "df_lei_both = pd.DataFrame()\n",
    "\n",
    "#IMC\n",
    "#download from synapse: https://www.synapse.org/Synapse:syn61455523\n",
    "df_lei = pd.read_csv(f'data/20220201_IMC-TMAs_qc_s_g_LeidenClusteringGating_neighbors30_resolution0.6_markers22_all.csv',index_col=0)\n",
    "df_lei.drop(['DAPI_Xc', 'DAPI_Yc','slide_scenec'],axis=1,inplace=True) #'DAPI_Xc.1', 'DAPI_Yc.1', 'slide_scenec.1'\n",
    "df_lei['Platform'] = 'IMC'\n",
    "df_lei['Patient'] = [item.replace('B','') for item in df_lei.Patient]\n",
    "df_lei['subtype'] = df_lei.subtype.replace({'TripleNeg':'TNBC','HR+HER2-':'ER+','HR+HER2+':'ER+ HER2+', 'HR-HER2+':'HER2+'})\n",
    "df_lei.leidencelltype3 = df_lei.leidencelltype3.fillna(df_lei.gatedcelltype3).replace({'str.':'stromal','imm.':'immune'})\n",
    "df_lei.leidencelltype4 = df_lei.leidencelltype4.fillna(df_lei.gatedcelltype3).replace({'str.':'stromal','imm.':'immune'})\n",
    "df_lei.leidencelltype5 = df_lei.leidencelltype5.fillna(df_lei.gatedcelltype5)\n",
    "#celltype names\n",
    "df_lei['leiden'] = df_lei.leiden.astype('str').replace(d_celltype_IMC)\n",
    "print(len(df_lei))\n",
    "print(df_lei.loc[:,['DAPI_X','DAPI_Y']].median())\n",
    "#append IMC\n",
    "df_lei_both = pd.concat([df_lei_both,df_lei])\n",
    "\n",
    "#leiden cell types (cyclic)\n",
    "df_lei = pd.read_csv(f'data/20220408_JP-TMAs_LeidenClustering_neighbors30_resolution0.4_markers23_all.csv',index_col=0)\n",
    "df_lei['slide_scene'] = [item.split('_cell')[0] for item in df_lei.index]\n",
    "df_lei['Platform'] = 'cycIF'\n",
    "df_lei['Patient'] = df_lei.slide_scene.map(dict(zip(df_cyc_sub.index,df_cyc_sub.Accession)))\n",
    "df_lei['subtype'] = df_lei.slide_scene.map(dict(zip(df_cyc_sub.index,df_cyc_sub.ID)))\n",
    "df_lei['gatedcelltype3'] = df_lei.celltype.replace({'endothelial':'stromal'})\n",
    "df_lei['leiden'] = df_lei.leiden.replace(d_celltype_cycif)\n",
    "#rename columns\n",
    "df_lei = df_lei.rename({'aSMA':'SMA'},axis=1)\n",
    "#rescale\n",
    "print(df_lei.loc[:,['DAPI_X','DAPI_Y']].median())\n",
    "df_lei.loc[:,['DAPI_X','DAPI_Y']] = df_lei.loc[:,['DAPI_X','DAPI_Y']]*.325\n",
    "print(len(df_lei))\n",
    "print(df_lei.loc[:,['DAPI_X','DAPI_Y']].median())\n",
    "#append cycIF\n",
    "df_lei_both = pd.concat([df_lei_both,df_lei])\n",
    "\n",
    "#mibi\n",
    "#0.39 μm per pixel\n",
    "df_lei = pd.read_csv(f'data/20220316_MIBI_s_LeidenClusteringGating_neighbors30_resolution0.6_markers35_Filtered.csv',index_col=0)\n",
    "df_lei['slide_scene'] = [item.split('_cell')[0] for item in df_lei.index]\n",
    "df_lei['Platform'] = 'MIBI'\n",
    "df_lei['Patient'] = ['M'+str(item) for item in df_lei.slide]\n",
    "df_lei['subtype'] = 'TNBC'\n",
    "#rescale\n",
    "print(df_lei.loc[:,['DAPI_X','DAPI_Y']].median())\n",
    "df_lei.loc[:,['DAPI_X','DAPI_Y']] = df_lei.loc[:,['DAPI_X','DAPI_Y']]*.39\n",
    "df_lei['leiden'] = df_lei.leiden.replace(d_celltype_MIBI)\n",
    "d_replace = { 'immune':'stromal', 'fibroblast':'stromal', 'endothelial':'stromal'}\n",
    "df_lei['leidencelltype2'] = df_lei.leidencelltype5.replace(d_replace)\n",
    "print(len(df_lei))\n",
    "print(df_lei.loc[:,['DAPI_X','DAPI_Y']].median())\n",
    "#append mibi\n",
    "df_lei_both = pd.concat([df_lei_both,df_lei])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lei_both.Platform.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Median radius of tissues from each platform\n",
    "df_lei_both.loc[:,['DAPI_X','DAPI_Y','Platform']].groupby('Platform').median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lei_both.Patient.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save combined dataframes of celltype\n",
    "s_out = f'{codedir}/data/20220420_JP-TMAs_IMC-TMAs_MIBI_CombinedCelltypes_all.csv' #20220204_JP-TMAs_BaselTMA_CombinedCelltypes.csv\n",
    "if not os.path.exists(s_out):\n",
    "    print('saving csv')\n",
    "    #df_lei_both.to_csv(s_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize Tissue Variables <a name=\"tissue\"></a>\n",
    "\n",
    "per patient means\n",
    "\n",
    "\n",
    "[contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load combined\n",
    "s_sample = '20220420_JP-TMAs_IMC-TMAs_MIBI' \n",
    "s_type = 'all'\n",
    "#download from synapse: https://www.synapse.org/Synapse:syn61455523\n",
    "df_lei = pd.read_csv(f'{codedir}/data/{s_sample}_CombinedCelltypes_{s_type}.csv',index_col=0,low_memory=False)\n",
    "df_lei['celltype1'] = 'all'\n",
    "df_lei['countme'] = True\n",
    "df_lei['leidencelltype2_tofill'] = df_lei.leidencelltype3.replace({'tumor':'epithelial','endothelial':'stromal',\n",
    "                                                            'immune':'stromal','imm.':'stromal','str.':'stromal'})\n",
    "df_lei['leidencelltype2'] = df_lei.leidencelltype2.fillna(df_lei.leidencelltype2_tofill)\n",
    "df_lei.subtype = df_lei.subtype.replace({'ER+HER2+':'ER+ HER2+'})\n",
    "df_lei.Patient = df_lei.Patient.astype('str')\n",
    "df_lei.leiden = df_lei.leiden.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib_venn import venn3, venn3_circles\n",
    "from matplotlib_venn import venn2, venn2_circles, venn2_unweighted\n",
    "\n",
    "#venn\n",
    "d_marker = {}\n",
    "for s_plat in df_lei.Platform.unique():\n",
    "    es_marker = set(df_lei[df_lei.Platform==s_plat].leiden.unique()) | set(['CD3 T cell','CD3 T cell'])\n",
    "    d_marker.update({s_plat:es_marker})\n",
    "fig,ax = plt.subplots(figsize=(4,2.5),dpi=300)\n",
    "venn3([d_marker['cycIF'], d_marker['IMC'], d_marker['MIBI']], ('cycIF', 'IMC', 'MIBI'),ax=ax)\n",
    "ax.set_title('Cell Type Overlap')\n",
    "fig.savefig(f'{s_date}/cell_type_overlap.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#stacked bar\n",
    "print(df_lei.Platform.unique())\n",
    "print(df_lei.subtype.unique())\n",
    "for s_cell in ['gatedcelltype5','leidencelltype5',]:\n",
    "    for s_subtype in ['ER+', 'TNBC', 'HER2+']:\n",
    "        df_both = pd.DataFrame(index = ['endothelial', 'epithelial', 'fibroblast', 'immune', 'stromal'])\n",
    "        ls_plat_pt = []\n",
    "        for s_plat in sorted(df_lei[df_lei.subtype==s_subtype].Platform.unique()):\n",
    "            df_mib = df_lei[(df_lei.subtype==s_subtype)&(df_lei.Platform==s_plat)]\n",
    "            df_st = df_mib.groupby(s_cell).CD31.count()/len(df_mib)\n",
    "            df = pd.DataFrame(df_st).rename({'CD31':s_plat},axis=1)\n",
    "            df_both = pd.concat([df_both,df],axis=1)\n",
    "            ls_plat_pt.append(str(df_mib.Patient.nunique()))\n",
    "        #corr\n",
    "        se_corr = df_both.corr(method='pearson').unstack().loc['cycIF']\n",
    "        i_corr = se_corr[se_corr != 1].mean()\n",
    "        fig,ax = plt.subplots(figsize=(3,3),dpi=300)\n",
    "        pd.DataFrame(df_both).T.plot(kind='bar',stacked=True,title=s_subtype,ax=ax)\n",
    "        ax.legend(bbox_to_anchor=(1,.7),title=s_cell,frameon=False)\n",
    "        ax.set_title('')\n",
    "        ax.set_title(f'No. Pts.={\", \".join(ls_plat_pt)}',fontsize='medium',loc='right')\n",
    "        fig.suptitle(f'{s_subtype}  r={i_corr:.2}',x=.29,y=.9)\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(f'{codedir}/{s_date}/Cell_Fractions_{s_subtype}_{s_cell}.pdf')\n",
    "    #     break\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_both.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_both = pd.DataFrame(index = ['ER+',  'HER2+','ER+ HER2+','TNBC',])\n",
    "for s_plat in ['IMC', 'cycIF', 'MIBI']:\n",
    "    df_mib = df_lei[(df_lei.Platform==s_plat)]\n",
    "    df_mib.index = df_mib.Patient\n",
    "    df_st = df_mib[~df_mib.index.duplicated()].groupby('subtype').CD31.count()\n",
    "    df = pd.DataFrame(df_st).rename({'CD31':s_plat},axis=1)\n",
    "    print(s_plat)\n",
    "    print(df)\n",
    "    df_both = pd.concat([df_both,df],axis=1)\n",
    "fig,ax = plt.subplots(figsize=(4.3,2),dpi=300)\n",
    "pd.DataFrame(df_both).T.plot(kind='barh',stacked=True,title='No. Pts.',ax=ax)\n",
    "ax.legend(bbox_to_anchor=(1,.95),title='subtype')\n",
    "plt.tight_layout()\n",
    "fig.savefig(f'{codedir}/{s_date}/Subtype_Fractions_{s_subtype}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d_both = {}\n",
    "for s_plat in ['IMC', 'cycIF', 'MIBI']:\n",
    "    df_mib = df_lei[(df_lei.Platform==s_plat)]\n",
    "    df_st = df_mib.groupby('Patient').CD31.count()\n",
    "    d_both.update({s_plat:df_st})\n",
    "    \n",
    "df_both = pd.DataFrame(d_both)\n",
    "fig,ax=plt.subplots(figsize=(3,3),dpi=300)\n",
    "sns.violinplot(data=df_both,order=['IMC','MIBI','cycIF'],cut=0,ax=ax)\n",
    "sns.stripplot(data=df_both,order=['IMC','MIBI','cycIF'],palette='dark',s=1,ax=ax)\n",
    "ax.set_title('Number of Cells per Patient')\n",
    "plt.tight_layout()\n",
    "fig.savefig(f'{codedir}/{s_date}/Number of Cells per Patient.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(f'{codedir}/Results/'):\n",
    "    print('make results file folder')\n",
    "    if not b_binder:\n",
    "        os.mkdir(f'{codedir}/Results/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import sys\n",
    "# import os\n",
    "# save out the source data (done)\n",
    "# idx = 0\n",
    "# with pd.ExcelWriter('Source_Data.xlsx') as writer:\n",
    "#     for csvfilename in sorted(os.listdir('data')):\n",
    "#         if csvfilename.find('.csv') > -1:\n",
    "#             size_mb = (os.path.getsize(f'data/{csvfilename}')/1024)/1024\n",
    "#             if size_mb < 10:\n",
    "#                 print(f'good size: {csvfilename}')\n",
    "#                 idx+=1\n",
    "#                 df = pd.read_csv(f'data/{csvfilename}')#,index_col=0\n",
    "#                 sheet_name = csvfilename[:31]\n",
    "#                 df.to_excel(writer, sheet_name=sheet_name)\n",
    "#             else:\n",
    "#                 print(f'too large: {csvfilename}')\n",
    "#     print(idx)\n",
    "#     for csvfilename in sorted(os.listdir('Results')):\n",
    "#         if csvfilename.find('.csv') > -1:\n",
    "#             size_mb = (os.path.getsize(f'Results/{csvfilename}')/1024)/1024\n",
    "#             if size_mb < 50:\n",
    "#                 print(f'good size: {csvfilename}')\n",
    "#                 df = pd.read_csv(f'Results/{csvfilename}')#,index_col=0\n",
    "#                 if csvfilename.find('subtyping_') >-1:\n",
    "#                     sheet_name = csvfilename.split(\"subtyping_\")[1].replace('LeidenClustering','LeidenClust')[-31:]\n",
    "#                 else:\n",
    "#                     sheet_name = csvfilename.split(\"results_\")[1][:31]\n",
    "#                 df.to_excel(writer, sheet_name=sheet_name)\n",
    "#             else:\n",
    "#                 print(f'too large: {csvfilename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save gated and clustering cell lineages (fraction per patient)\n",
    "def prop_positive(df_data,s_cell,s_grouper):\n",
    "    #df_data['countme'] = True\n",
    "    df_cell = df_data.loc[:,[s_cell,s_grouper,'countme']].dropna()\n",
    "    df_prop = (df_cell.groupby([s_cell,s_grouper]).countme.count()/df_cell.groupby([s_grouper]).countme.count()).unstack().T\n",
    "    return(df_prop)\n",
    "\n",
    "s_grouper='Patient'\n",
    "ls_cell = ['leidencelltype5','gatedcelltype5']#,'celltype' 'leidencelltype3','leidencelltype4',\n",
    "for s_cell in ls_cell:\n",
    "    df_prop = prop_positive(df_lei,s_cell=s_cell,s_grouper=s_grouper)\n",
    "    s_out = f'results_{s_sample}_GatedCellTypes_by{s_grouper}_by{s_cell}_{s_type}.csv'\n",
    "    print(s_out)\n",
    "    if not os.path.exists(f'{codedir}/Results/{s_out}'):\n",
    "        print('saving')\n",
    "        #df_prop.to_csv(f'{codedir}/Results/{s_out}')\n",
    "    #break\n",
    "print(len(df_lei))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## leiden celltypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corrections (ER+ artifacts in TN tissues)\n",
    "ls_TNBC = ['103', '114', '116', '129', '163', '272', '00-8939-2D', '90-526-2M', 'JP-TMA2-1_scene21', 'JP-TMA2-1_scene26',\n",
    " 'JP-TMA2-1_scene31', 'Z28']\n",
    "ls_ERneg = ['3', '4', '18', '24', '29', '32', '35', '38', '44', '48', '50', '56', '62', '65', '76', '79', '80', '83', '86',\n",
    " '92', '100', '101', '102', '108', '109', '118', '119', '120', '122', '126', '128', '130', '131', '138', '141', '146', '148',\n",
    " '153', '158', '169', '170', '173', '177', '183', '188', '206', '210', '211', '212', '217', '219', '221', '223', '225', '234',\n",
    " '237', '239', '242', '245', '247', '248', '250', '256', '260', '263', '264', '268', '271', '273', '279', '281', '282']\n",
    "print(s_date)\n",
    "if not s_date == '20220412': #produced results_20220420_JP-TMAs_IMC-TMAs_MIBI\n",
    "    print('update ER status')\n",
    "    df_lei.loc[(df_lei.Patient.isin(ls_TNBC)) & (df_lei.leiden=='Luminal ER+ t.'),'leiden'] = 'Luminal t.'\n",
    "print(len(df_lei))\n",
    "\n",
    "#Save leiden celltypes (fraction per patient)\n",
    "\n",
    "for s_celltype in ['leidencelltype2','celltype1']: #'celltype3','celltype',\n",
    "    for s_cell in df_lei.loc[:,s_celltype].unique():\n",
    "        df_cell = df_lei.loc[df_lei.loc[:,s_celltype]==s_cell]\n",
    "        df_prop = prop_positive(df_cell,s_cell='leiden',s_grouper='Patient')\n",
    "        s_out = f'results_{s_sample}_LeidenClustering_byPatient_by{s_celltype}_in{s_cell}_{s_type}.csv'\n",
    "        for s_plat in df_lei.Platform.unique():\n",
    "            ls_patient = df_lei[df_lei.Platform==s_plat].Patient.unique()\n",
    "            df_prop.loc[ls_patient,~df_prop.loc[ls_patient].isna().all()] = df_prop.loc[ls_patient,~df_prop.loc[ls_patient].isna().all()].fillna(0)\n",
    "        if not os.path.exists(f'{codedir}/Results/{s_out}'):\n",
    "            print('saving')\n",
    "            #df_prop.to_csv(f'{codedir}/Results/{s_out}')\n",
    "        print(s_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survival analysis <a name=\"surv\"></a>\n",
    "\n",
    "\n",
    "- single variable\n",
    "\n",
    "\n",
    "[contents](#contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load annotation\n",
    "df_surv = pd.read_csv('data/TMA_Survival_Subtype.csv',index_col=0)\n",
    "df_clin = pd.read_csv('data/TMA_Clinical_Variables.csv',index_col=0)\n",
    "df_surv.loc[df_surv.index.str.contains('JP-TMA2'),'Platform'] = 'cycIF2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load per patient means\n",
    "s_sample = '20220420_JP-TMAs_IMC-TMAs_MIBI'#\n",
    "\n",
    "df_file = pd.DataFrame()\n",
    "for s_file in os.listdir('Results'):\n",
    "    if s_file.find(f'results_{s_sample}_LeidenClustering_') > -1:\n",
    "        s_type = 'LeidenClustering'\n",
    "        s_subtype = s_file.split('.csv')[0].split('_')[-1]\n",
    "        s_partition = s_file.split('.csv')[0].split('_')[-3].split('by')[1]\n",
    "        s_cell = s_file.split('.csv')[0].split('_')[-2].split('in')[1]   \n",
    "    elif s_file.find(f'results_{s_sample}_Density_') > -1:\n",
    "        s_type = 'Density'\n",
    "        s_subtype = s_file.split('.csv')[0].split('_')[-1]\n",
    "        s_partition = s_file.split('.csv')[0].split('_')[-2].split('by')[1]\n",
    "        s_cell = 'density'\n",
    "    else:\n",
    "        continue\n",
    "    df_file.loc[s_file,'subtype'] = s_subtype\n",
    "    df_file.loc[s_file,'type'] = s_type\n",
    "    df_file.loc[s_file,'partition'] = s_partition\n",
    "    df_file.loc[s_file,'cell'] = s_cell\n",
    "    #break\n",
    "\n",
    "df_surv.index = df_surv.index.astype('str')\n",
    "ls_file = ['results_20220420_JP-TMAs_IMC-TMAs_MIBI_LeidenClustering_byPatient_bycelltype1_inall_all.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file\n",
    "ls_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find cutpoints \n",
    "\n",
    "Find the quantile that binarizes patients into high and low with maximum difference in survival, using cycIF data.\n",
    "\n",
    "Test tertitles and median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#single platform survival for supplement\n",
    "importlib.reload(util)\n",
    "alpha = 0.05\n",
    "%matplotlib inline\n",
    "# cycif results - ER+ CD44+ tum TNBC: CD20 b cell, CD3 t cell,  CD44+ tum, CD44+ str.\n",
    "#[CD8 t cell,CD4 t cell] macrophage, myoep, prolif tum, endothelial\n",
    "savedir = f'{codedir}/{s_date}'\n",
    "\n",
    "for s_time, s_censor in [('Survival_time','Survival'),('Recurrence_time','Recurrence')]:\n",
    "    for s_index in ls_file: \n",
    "        print(s_index)\n",
    "        s_type = df_file.loc[s_index,'type']\n",
    "        s_cell = df_file.loc[s_index,'cell']\n",
    "        df_all=pd.read_csv(f'results/{s_index}',index_col=0)\n",
    "        df_all.index = df_all.index.astype('str')\n",
    "        ls_marker = df_all.columns\n",
    "        df_all = df_all.merge(df_surv,left_index=True,right_index=True)\n",
    "        if df_all.columns.str.contains('CD4 T cell').any():\n",
    "            df_all.loc[df_all.Platform!='IMC','CD3 T cell'] = df_all.loc[df_all.Platform!='IMC',['CD4 T cell','CD8 T cell']].sum(axis=1)\n",
    "        for s_subtype in ['ER+','TNBC',]:#,'HER2+'\n",
    "            for s_plat in ['cycIF','IMC','MIBI',]:\n",
    "                for s_col in ls_marker:\n",
    "                    #s_col = 'Vim+ FB' #'CD8 T cell'#\n",
    "                    for cutp in [0.33,.5,.66,]:\n",
    "                        util.single_km(df_all,s_cell,s_subtype,s_plat,s_col,savedir,alpha,cutp,s_time,s_censor)\n",
    "                        #break\n",
    "                    #break\n",
    "                break #platform, only test cycIF\n",
    "            #break #subtype\n",
    "        break #only test in all\n",
    "    break #survival/recur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combine platforms\n",
    "\n",
    "FDR multiple testing  correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load high and low proliferation output\n",
    "df_prolif = pd.read_csv(f'{codedir}/data/Prolif._t._high_low.csv',index_col=0)\n",
    "df_prolif.index = df_prolif.index.astype('str')\n",
    "df_prolif.rename({'Prolif. t. abundance':'abundance'},axis=1,inplace=True)\n",
    "d_prolif = dict(zip(df_prolif.index,df_prolif.abundance))\n",
    "print(len(df_prolif))\n",
    "#read dataframe with more cell types\n",
    "s_index ='results_20220420_JP-TMAs_IMC-TMAs_MIBI_LeidenClustering_byPatient_bycelltype1_inall_all.csv'\n",
    "df_all=pd.read_csv(f'Results/{s_index}',index_col=0)\n",
    "print(len(df_all))\n",
    "df_all.index = df_all.index.astype('str')\n",
    "df = df_all.merge(df_surv,left_index=True,right_index=True,how='left')\n",
    "df.loc[df.Platform!='IMC','CD3 T cell'] = df.loc[df.Platform!='IMC',['CD4 T cell','CD8 T cell']].sum(axis=1)\n",
    "df['prolif'] = df.index.map(d_prolif)\n",
    "df.index = df.index.astype('str')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# combine platforms for survival analysis by all, and by low/high proliferation\n",
    "\n",
    "savedir = f\"{codedir}/{s_date}\"\n",
    "#what do i correct for? 4 cell types\n",
    "d_cut = {'CD20 B cell':0.33,\n",
    "             ##'CD8 T cell':0.33, 'CD4 T cell':0.33, #not found in IMC (use CD3 T cell \n",
    "             ##'CD44+ str.':0.33,'Myoepithelial':0.66, #not found in MIBI\n",
    "             ##'CD44+ t.':0.33,  #discovery  #not found in MIBI\n",
    "             'CD3 T cell':0.33, #discover (CD8)\n",
    "          'endothelial':0.33, 'Prolif. t.':0.5,\n",
    "             ##'Vim+ FB':0.5, #discovery #Vim+ FB not prognostic, plotting to compare to Vim+ spatial LDA neighborhood\n",
    "            }\n",
    "\n",
    "alpha = 1.05\n",
    "#df_prolif = pd.DataFrame()\n",
    "d_discovery = {'Discovery':['cycIF'],\n",
    "    'Validation':['IMC','MIBI','cycIF2'],\n",
    "               'Clinical':['IMC','MIBI','cycIF2','cycIF']}\n",
    "for s_discovery, ls_plat in d_discovery.items():\n",
    "    if s_discovery == 'Discovery':\n",
    "        print(s_discovery)\n",
    "        alphad=0.05\n",
    "    else:\n",
    "        alphad=0.000001\n",
    "    for s_time, s_censor in [('Survival_time','Survival'),('Recurrence_time','Recurrence')]:\n",
    "        for s_subtype in ['ER+','TNBC',]:\n",
    "            for s_cell in ['low-prolif','high-prolif','all',]: #,\n",
    "                if (s_cell.find('prolif')>-1) & (s_subtype=='ER+') & (s_discovery=='Validation'):\n",
    "                    print('including cycIF')\n",
    "                    ls_plat = ['IMC','cycIF','cycIF2']\n",
    "                ls_pval = []\n",
    "                d_data = {}\n",
    "                for s_col, cutp in d_cut.items():\n",
    "                    #combine all samples high and low across platforms\n",
    "                    df_both=pd.DataFrame()\n",
    "                    print(ls_plat)\n",
    "                    for s_plat in ls_plat:\n",
    "                        if s_cell == 'all':\n",
    "                            df_all = df.drop('prolif',axis=1).copy()\n",
    "                            df_all.index = df_all.index.astype('str')\n",
    "                        elif s_cell == 'high-prolif':\n",
    "                            s_discovery = s_cell\n",
    "                            s_low_high = 'high'\n",
    "                            df_all = df.loc[df.prolif==s_low_high,:].copy()\n",
    "                        elif s_cell == 'low-prolif':\n",
    "                            s_discovery = s_cell\n",
    "                            s_low_high = 'low'\n",
    "                            df_all = df.loc[df.prolif==s_low_high,:].copy()\n",
    "                        else:\n",
    "                            df_all = df.loc[df.leiden==s_cell,:].copy()\n",
    "\n",
    "                        df_p = util.single_km(df_all,s_cell,s_subtype,s_plat,s_col,savedir,alpha=alphad,cutp=cutp,s_time=s_time,s_censor=s_censor) \n",
    "                        df_both = pd.concat([df_both,df_p])\n",
    "                    df_both_surv = df_both.dropna()\n",
    "                    #log rank\n",
    "                    if len(df_both_surv) > 0:\n",
    "                        results = util.multivariate_logrank_test(event_durations=df_both_surv.loc[:,s_time],\n",
    "                                                        groups=df_both_surv.abundance, event_observed=df_both_surv.loc[:,s_censor])\n",
    "                    d_data.update({s_col:[df_both_surv,cutp]})\n",
    "                    ls_pval.append(results.summary.p[0])\n",
    "                #'''\n",
    "                #run multiple test correction\n",
    "                reject, corrected, __, __ = statsmodels.stats.multitest.multipletests(ls_pval,method='fdr_bh')# #'fdr_bh'\n",
    "                d_correct = dict(zip(d_cut.keys(),corrected))\n",
    "                d_orig = dict(zip(d_cut.keys(),ls_pval))\n",
    "                ls_pval_cph = []\n",
    "                ls_cph_markers = []\n",
    "                for s_col, p_correct in d_correct.items():\n",
    "                    df_both_surv = d_data[s_col][0]\n",
    "                    cutp = d_data[s_col][1]\n",
    "                    s_title2 = f'{s_col} n={len(df_both_surv)}'\n",
    "                    s_title1 = f'{s_subtype} {s_censor}'\n",
    "                    if s_cell.find('prolif') > -1:\n",
    "                        s_title1 = f'{s_subtype} {s_cell} {s_censor}' \n",
    "                    #kaplan meier plotting\n",
    "                    if (s_col == 'CD3 T cell') & (s_subtype == 'ER+'):\n",
    "                        alpha=.99\n",
    "                    else:\n",
    "                        alpha=1.05\n",
    "                    if p_correct < alpha:\n",
    "                        #if s_discovery== 'Discovery':\n",
    "                       #cool plotting function for all platforms\n",
    "                        s_title1 = f'{s_subtype} {s_discovery}'\n",
    "                        s_title2 = f'{s_col} Abundance'\n",
    "                        fig1, fig2, pval_cph, pval_km = util.km_cph_all(df_both_surv,df_clin,s_title1,s_title2,s_col,alpha=alpha,s_time=s_time, s_censor=s_censor,\n",
    "                               s_groups='abundance',s_cph_model='high',ls_clin=['age','tumor_size','Stage'],p_correct=p_correct)\n",
    "                        if not fig1 is None:\n",
    "                            #continue\n",
    "                            fig1.savefig(f\"{codedir}/{s_date}/Survival_Plots/KM_{s_title1.replace(' ','_')}_{s_title2.replace(' ','_')}_{cutp}.pdf\")\n",
    "                        if not fig2 is None:\n",
    "                            #continue\n",
    "                            fig2.savefig(f\"{codedir}/{s_date}/Survival_Plots/CPH_{s_title1.replace(' ','_')}_{s_title2.replace(' ','_')}_{cutp}.pdf\")\n",
    "                        ls_pval_cph.append(pval_cph)\n",
    "                        ls_cph_markers.append(s_col)\n",
    "                try:\n",
    "                    reject2, corrected2, __, __ = statsmodels.stats.multitest.multipletests(ls_pval_cph,alpha=0.1,method='fdr_bh')\n",
    "                    print(f'{s_discovery} {s_subtype}')\n",
    "                    [print(f'{ls_cph_markers[idx]} {corrected2[idx]}') for idx,item in enumerate(reject2) if item]\n",
    "                except:\n",
    "                    print('')\n",
    "                #df_prolif = pd.concat([df_prolif,df_both])\n",
    "                #'''\n",
    "                #break  #all, high low prolif\n",
    "            #break #subtype\n",
    "        break #recurrence\n",
    "    #break #disc/val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #output high low (done)\n",
    "# df_prolif = pd.DataFrame()\n",
    "# s_low_high = 'high'\n",
    "# ls_col = ['Prolif. t.',\n",
    "#     'CD3 T cell']\n",
    "# df_all_prolif = pd.DataFrame()\n",
    "# for s_col in ls_col:\n",
    "#     df_prolif=pd.DataFrame()\n",
    "#     for s_subtype in ['TNBC','ER+']:\n",
    "#         #print(s_subtype)\n",
    "#         for s_plat in ['IMC','MIBI','cycIF','cycIF2']:\n",
    "#             df_all = df.drop('prolif',axis=1).copy()\n",
    "#             df_p = low_high_abun(df_all,s_subtype,s_plat,s_col)\n",
    "#             #print(len(df_p))\n",
    "#             df_prolif = pd.concat([df_prolif,df_p])\n",
    "#     print(len(df_prolif))\n",
    "#     df_prolif.rename({'abundance':f'{s_col} abundance'},axis=1,inplace=True)\n",
    "#     if not os.path.exists(f'{s_date}/{s_col.replace(\" \",\"_\")}_high_low.csv'):\n",
    "#         print('saving')\n",
    "#         df_prolif.to_csv(f'{s_date}/{s_col.replace(\" \",\"_\")}_high_low.csv')\n",
    "#     #print(df_prolif.groupby(f'{s_col} abundance').mean())\n",
    "#     #print(df_prolif[df_prolif.loc[:,f'{s_col} abundance'].isna()].loc[:,s_col])\n",
    "#     if s_col == 'Prolif. t.':\n",
    "#         #print(s_col)\n",
    "#         df_all_prolif = pd.concat([df_all_prolif,df_prolif])\n",
    "#     else:\n",
    "#         df_all_prolif = df_all_prolif.merge(df_prolif.loc[:,[f'{s_col} abundance']],left_index=True,right_index=True)\n",
    "\n",
    "# df_all_prolif['ProlifTum_Tcell'] = df_all_prolif.loc[:,'Prolif. t. abundance'] + '_' + df_all_prolif.loc[:,'CD3 T cell abundance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load T cell above/below median (i.e. high low)\n",
    "df_tcell = pd.read_csv('data/CD3_T_cell_high_low.csv',index_col=0)\n",
    "df_all_prolif = df_prolif.merge(df_tcell.loc[:,~df_tcell.columns.isin(df_prolif.columns)],\n",
    "                left_index=True,right_index=True,)\n",
    "#combine\n",
    "df_all_prolif['ProlifTum_Tcell'] = df_all_prolif.abundance + '_' + df_all_prolif.loc[:,'CD3 T cell abundance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#combine platforms\n",
    "importlib.reload(plotting)\n",
    "s_col = 'ProlifTum_Tcell'\n",
    "s_time = 'Survival_time'\n",
    "s_censor = 'Survival'\n",
    "for s_subtype in ['TNBC','ER+']:\n",
    "        df_sub = df_all_prolif[(df_all_prolif.subtype==s_subtype)]\n",
    "        fig,ax = plotting.cat_km(df_sub,s_col,s_time,s_censor)\n",
    "        fig.suptitle(f'All {s_subtype}',fontsize='medium',x=0.35,y=.91)\n",
    "        ax.set_xlabel('Survival time (days)')\n",
    "        ax.set_ylabel('Fraction Alive')\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(f'{s_date}/KM_{s_col}_allplat_{s_subtype}_{s_censor}.pdf')\n",
    "        #plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s_col = 'ProlifTum_Tcell'\n",
    "s_time = 'Survival_time'\n",
    "s_censor = 'Survival'\n",
    "for s_subtype in ['TNBC','ER+']:\n",
    "    for s_plat in ['IMC','cycIF','MIBI']:\n",
    "        df_sub = df_all_prolif[(df_all_prolif.Platform==s_plat) & (df_all_prolif.subtype==s_subtype)]\n",
    "        fig,ax = plotting.cat_km(df_sub,s_col,s_time,s_censor,figsize=(2.5,3))\n",
    "        fig.suptitle(f'{s_plat} {s_subtype}',fontsize='medium',x=0.5,y=.91)\n",
    "        plt.legend().remove()\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(f'{s_date}/KM_{s_col}_{s_plat}_{s_subtype}_{s_censor}.pdf')\n",
    "        #plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_col = 'ProlifTum_Tcell'\n",
    "# df_all_prolif.to_csv(f'{s_date}/{s_col.replace(\" \",\"_\")}_high_low.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir('Results')\n",
    "sns.set_palette('tab10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial LDA  <a name=\"clin\"></a> \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LDA\n",
    "dd_discover={}\n",
    "savedir = f\"{codedir}/{s_date}\"\n",
    "alpha = 0.99\n",
    "s_type = 'SpatialLDA'\n",
    "s_cell = 'Kmeans'\n",
    "k=8\n",
    "df_prolif = pd.DataFrame()\n",
    "d_discovery = {'Discovery':['cycIF'],\n",
    "               'Validation':['IMC','cycIF2'], \n",
    "               'Clinical':['IMC','cycIF','cycIF2']} #'MIBI',\n",
    "dd_validate = {'TNBC':{'Vim+ FB':0.66,'T cell':0.33}, #'T cell':0.33,\n",
    "               'ER+':{'mixed FB':0.66}}\n",
    "\n",
    "for s_discovery, ls_plat in d_discovery.items():\n",
    "    for s_time, s_censor in [('Survival_time','Survival'),('Recurrence_time','Recurrence')]:\n",
    "        for s_subtype in ['ER+','TNBC',]:\n",
    "            d_cut = dd_validate[s_subtype]\n",
    "            print(f'{s_subtype} {s_censor} cells to test: {len(d_cut)}')\n",
    "            ls_pval = []\n",
    "            d_data = {}\n",
    "            for s_col, cutp in d_cut.items():\n",
    "                print(s_col)\n",
    "                df_both = pd.DataFrame()\n",
    "                for s_plat in ls_plat: \n",
    "                    if s_plat == 'cycIF2':\n",
    "                        s_plat_read = 'cycIF'\n",
    "                    else:\n",
    "                        s_plat_read = s_plat\n",
    "                    df_all=pd.read_csv(f'{codedir}/Results/results_{s_subtype}_{s_plat_read}_SpatialLDA_byPatient_byKmeans_k{k}.csv',index_col=0)\n",
    "                    df_all.index = df_all.index.astype('str')\n",
    "                    df_all = df_all.merge(df_surv,left_index=True,right_index=True)  \n",
    "                    if df_all.columns.isin([s_col]).any():\n",
    "                        df_km_out = util.single_km(df_all,s_cell,s_subtype,s_plat,s_col,savedir,alpha=0.00001,cutp=cutp,s_time=s_time,s_censor=s_censor)\n",
    "                        df_both = pd.concat([df_both, df_km_out])\n",
    "                        print(len(df_both))\n",
    "                df_both_surv = df_both.dropna()\n",
    "                print(len(df_both_surv))\n",
    "                #log rank\n",
    "                results = multivariate_logrank_test(event_durations=df_both_surv.loc[:,s_time],\n",
    "                                                    groups=df_both_surv.loc[:,'abundance'], \n",
    "                                                    event_observed=df_both_surv.loc[:,s_censor])\n",
    "                d_data.update({s_col:[df_both_surv,cutp]})\n",
    "                ls_pval.append(results.summary.p[0])\n",
    "            print(f'pvals: {len(ls_pval)}')\n",
    "            #run multiple test correction\n",
    "            reject, corrected, __, __ = statsmodels.stats.multitest.multipletests(ls_pval,method='fdr_bh')# #'fdr_bh'\n",
    "            d_correct = dict(zip(d_cut.keys(),corrected))\n",
    "            d_orig = dict(zip(d_cut.keys(),ls_pval))\n",
    "            ls_pval_cph = []\n",
    "            ls_cph_markers = []        \n",
    "            if s_discovery == 'Discovery':\n",
    "                p_correct_used=None\n",
    "            else:\n",
    "                p_correct_used= None #p_correct # \n",
    "            ###########################################\n",
    "            for s_col, p_correct in d_correct.items():\n",
    "                df_both_surv = d_data[s_col][0]\n",
    "                print(len(df_both_surv))\n",
    "                cutp = d_data[s_col][1]\n",
    "                s_title2 = f'{s_col} n={len(df_both_surv)}'\n",
    "                s_title1 = f'{s_subtype} {s_censor}'\n",
    "                if p_correct < alpha:\n",
    "                    #if s_discovery== 'Discovery':\n",
    "                   #cool plotting function for all platforms\n",
    "                    s_title1 = f'{s_subtype} {s_discovery}'\n",
    "                    s_title2 = f'{s_col} Neighborhoods'\n",
    "                    fig1, fig2, pval_cph, pval_km = util.km_cph_all(df_both_surv,df_clin,s_title1,s_title2,s_col,alpha=alpha,s_time=s_time, s_censor=s_censor,\n",
    "                           s_groups='abundance',s_cph_model='high',ls_clin=['age','tumor_size','Stage'],p_correct=p_correct_used)\n",
    "                    if not fig1 is None:\n",
    "                        #continue\n",
    "                        fig1.savefig(f\"{codedir}/{s_date}/Survival_Plots/KM_LDA_{s_title1.replace(' ','_')}_{s_title2.replace(' ','_')}_{cutp}_{s_censor}.pdf\")\n",
    "                    if not fig2 is None:\n",
    "                        #continue\n",
    "                        fig2.savefig(f\"{codedir}/{s_date}/Survival_Plots/CPH_LDA_{s_title1.replace(' ','_')}_{s_title2.replace(' ','_')}_{cutp}_{s_censor}.pdf\")\n",
    "                    ls_pval_cph.append(pval_cph)\n",
    "                    ls_cph_markers.append(s_col)\n",
    "#             try:\n",
    "#                 reject2, corrected2, __, __ = statsmodels.stats.multitest.multipletests(ls_pval_cph,alpha=alpha,method='fdr_bh')\n",
    "#                 #print(f'{s_discovery} {s_subtype}')\n",
    "#                 [print(f'{ls_cph_markers[idx]} {corrected2[idx]}') for idx,item in enumerate(reject2) if item]\n",
    "#             except:\n",
    "#                 print('not correct')\n",
    "            df_prolif = pd.concat([df_prolif,df_both])\n",
    "            dd_discover.update({f'{s_subtype}_{s_censor}':d_orig})\n",
    "                \n",
    "            #break #subtype\n",
    "        #break #recurrence\n",
    "    #break #disc/val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subtyping analysis <a name=\"subtIMC\"></a>\n",
    "\n",
    "- IMC and cyclic\n",
    "\n",
    "- Basel (ERneg removed), Zurich and cyclic\n",
    "\n",
    "- common celltypes\n",
    "\n",
    "\n",
    "[contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results data\n",
    "s_cell ='epithelial'\n",
    "s_sample = '20220420_JP-TMAs_IMC-TMAs_MIBI'\n",
    "#savedir=f'{codedir}/20220408/Survival_Plots_Both'\n",
    "df_file = pd.read_csv(f'{codedir}/Results/{s_sample}_results_files.csv',index_col=0)\n",
    "df_file[(df_file.cell==s_cell) & (df_file.type!='MeanIntensity')]\n",
    "\n",
    "#load annotation\n",
    "df_surv = pd.read_csv('data/TMA_Survival_Subtype.csv',index_col=0)\n",
    "df_clin = pd.read_csv('data/TMA_Clinical_Variables.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Platforms together <a name=\"st1\"></a>\n",
    "\n",
    "- celltype5 and  epithelial\n",
    "\n",
    "- gatedcelltype5 not prognostic\n",
    "\n",
    "- epithelial is prog!!!\n",
    "\n",
    "\n",
    "[contents](#contents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### adata\n",
    "importlib.reload(util)\n",
    "import sklearn\n",
    "ls_her2 = ['1', '10', '117', '118', '120', '136', '148', '16', '17', '182', '183',\n",
    "       '2', '225', '226', '237', '253', '259', '261', '267', '29', '48', '51',\n",
    "       '53', '54', '55', '57', '7', '9', 'Z1', 'Z15', 'Z43', 'Z44', 'Z47',\n",
    "       'Z51', 'Z55', 'Z56', 'Z70', 'Z8']\n",
    "savedir = f'{codedir}/{s_date}/Survival_Plots_Both'\n",
    "n_neighbors =  6 #\n",
    "savedir = f'{codedir}/{s_date}/Survival_Plots_Both'\n",
    "dd_bad = {'epithelial':{'TNBC_HER2+ ER+ t.':'Luminal t.',#\n",
    "                        'TNBC_Luminal ER+ t.':'Luminal t.'}}\n",
    "for s_cell in ['epithelial']:\n",
    "    d_bad = dd_bad[s_cell]\n",
    "    df_load = df_file[(df_file.cell==s_cell) & (df_file.type!='MeanIntensity')]\n",
    "    s_index = df_load.index[0]\n",
    "    print(s_index)\n",
    "    df = pd.read_csv(f'{codedir}/results/{s_index}',index_col=0)\n",
    "    s_subtype = df_file.loc[s_index,'subtype'] \n",
    "    s_type = df_file.loc[s_index,'type'] \n",
    "    s_partition = df_file.loc[s_index,'partition'] \n",
    "    s_cell =df_file.loc[s_index,'cell'] \n",
    "    #subtyping adata\n",
    "    if s_cell == 'epithelial':\n",
    "        ls_col = df.columns[df.dtypes=='float64'][df.loc[:,df.columns[df.dtypes=='float64']].sum()/len(df) > 0.04].to_list()\n",
    "    else:\n",
    "        ls_col = df.columns[df.dtypes=='float64'][df.loc[:,df.columns[df.dtypes=='float64']].sum()/len(df) > 0.02].to_list()\n",
    "\n",
    "    #update bad cell typing (ER+ in ER negative)\n",
    "    df['subtype'] = df.index.map(dict(zip(df_surv.index,df_surv.subtype)))\n",
    "    df.loc[ls_her2,'subtype'] = 'ER+HER2+'\n",
    "    print(df.subtype.unique())\n",
    "    #drop normal breast\n",
    "    df = df.drop('NB-05-12002',axis=0)\n",
    "    df=df\n",
    "    df['subtype'] = df['subtype'].fillna('TNBC')\n",
    "    for s_bad, s_good in d_bad.items():\n",
    "        s_bad_sub = s_bad.split('_')[0]\n",
    "        s_bad_cell = s_bad.split('_')[1]\n",
    "        #add them \n",
    "        df.loc[df.subtype==s_bad_sub,s_good] = df.loc[df.subtype==s_bad_sub,s_bad_cell].fillna(0) + df.loc[df.subtype==s_bad_sub,s_good].fillna(0)\n",
    "        # get rid of bad\n",
    "        df.loc[df.subtype==s_bad_sub,s_bad_cell] = np.nan\n",
    "    df = df.drop('subtype',axis=1) \n",
    "    adata = util.make_adata(df, ls_col,df_surv, n_neighbors, s_subtype, s_type, s_partition, s_cell)\n",
    "    \n",
    "    #normalize (standard scale features within platforms)\n",
    "    df_raw = pd.DataFrame(adata.raw.X,index=adata.obs.index,columns=adata.var.index).merge(adata.obs,left_index=True,right_index=True)\n",
    "    df_norm =pd.DataFrame()\n",
    "    for s_subtype in ['TNBC','ER+']: #,'HER2+'\n",
    "        df_sub = df_raw[df_raw.subtype==s_subtype]\n",
    "        df_norm_sub = df_sub.copy()\n",
    "        for s_plat in df_sub.Platform.unique():\n",
    "            df_plat = df_sub[df_sub.Platform==s_plat]\n",
    "            X = df_plat.loc[:,ls_col].values\n",
    "            #X_tr = sklearn.preprocessing.robust_scale(X, axis=0, with_centering=True, with_scaling=True)\n",
    "            X_tr = sklearn.preprocessing.scale(X, axis=0)\n",
    "            df_norm_sub.loc[df_plat.index,ls_col] = X_tr\n",
    "        df_norm = pd.concat([df_norm,df_norm_sub])\n",
    "    ls_col.remove('HER2+ ER+ t.')\n",
    "    adata = util.make_adata(df_norm, ls_col,df_surv, n_neighbors, s_subtype, s_type, s_partition, s_cell,ncols=3)\n",
    "    break\n",
    "\n",
    "# resolution = 0.2\n",
    "# adata = cluster_leiden(adata, resolution,n_neighbors, s_subtype, s_type, s_partition, s_cell)\n",
    "# for s_subtype in ['TNBC','ER+','HER2+']: #'ER+',\n",
    "#     s_plat = 'Both'\n",
    "#     df_p, cph = km_cph(adata,df_surv,s_subtype,s_plat,s_type,s_partition,s_cell,savedir=savedir)\n",
    "#     #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm.index.nunique()\n",
    "adata.obs.index.nunique()\n",
    "45+21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#normalization looks good\n",
    "ls_bad = []\n",
    "for s_col in ls_col:\n",
    "    for s_subtype in ['TNBC','ER+']:\n",
    "        fig, ax = plt.subplots(2,1,figsize=(4,5))\n",
    "        try:\n",
    "            sns.kdeplot(data=df_raw[df_raw.subtype==s_subtype], x=s_col, hue='Platform',ax=ax[0],common_norm=False)\n",
    "            __, pvalue = group_median_diff(df_raw[df_raw.subtype==s_subtype],s_group='Platform',s_marker=s_col)\n",
    "        except:\n",
    "            pvalue=1.00\n",
    "        if pvalue < 0.05:\n",
    "            ax[0].set_title(f'Raw: {s_subtype} {s_col}\\n p={pvalue:.2}')\n",
    "        else:\n",
    "            ax[0].set_title(f'Raw: {s_subtype} {s_col}\\n p={pvalue:.2}',fontdict={'fontweight':'bold'})\n",
    "        #norm\n",
    "        try:\n",
    "            sns.kdeplot(data=df_norm[df_norm.subtype==s_subtype], x=s_col, hue='Platform',ax=ax[1],common_norm=False)\n",
    "            __, pvalue = group_median_diff(df_norm[df_norm.subtype==s_subtype],s_group='Platform',s_marker=s_col)\n",
    "        except:\n",
    "            pvalue=1.00\n",
    "        if pvalue < 0.05:\n",
    "            ax[1].set_title(f'Normalized: {s_subtype} {s_col}\\n p={pvalue:.2}')\n",
    "            ls_bad.append(f'{s_subtype}_{s_col}')\n",
    "        else:\n",
    "            ax[1].set_title(f'Normalized: {s_subtype} {s_col}\\n p={pvalue:.2}',fontdict={'fontweight':'bold'})\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(f'{s_date}/kde_normalization_{s_subtype}_{s_col}.pdf')\n",
    "        #break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### leiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "resolution = 0.2\n",
    "adata = util.cluster_leiden(adata, resolution,n_neighbors, s_subtype, s_type, s_partition, s_cell)\n",
    "for s_subtype in ['TNBC','ER+']: #'ER+',,'HER2+'\n",
    "    s_plat = 'Both'\n",
    "    df_p, fig,fig2 = util.km_cph(adata,df_surv,s_subtype,s_plat,s_type,s_partition,s_cell,savedir=savedir)\n",
    "#df_p.to_csv(f'{s_date}/results_subtyping_{s_cell}_{s_type}_{s_plat}_{n_neighbors}_{resolution}.csv')\n",
    "fig.savefig(f'{savedir}/KM_{s_subtype}_{s_plat}_{s_type}_{s_partition}_{s_cell}_{n_neighbors}_{resolution}.pdf',dpi=300)\n",
    "fig2.savefig(f'{savedir}/CoxPH_{s_subtype}_{s_plat}_{s_type}_{s_partition}_{s_cell}_{n_neighbors}_{resolution}.pdf',dpi=300)\n",
    "print(f'{s_date}/results_subtyping_{s_cell}_{s_type}_{s_plat}_{n_neighbors}_{resolution}.csv')\n",
    "    #break#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "from itertools import combinations\n",
    "for s_subtype in ['ER+','TNBC']: #,'HER2+'\n",
    "    df_sub = adata.obs[adata.obs.subtype==s_subtype]\n",
    "    data = pd.crosstab(df_sub['Platform'],df_sub['leiden'])\n",
    "    stat, p, dof, expected = stats.chi2_contingency(data)\n",
    "    fig,ax = plt.subplots(figsize=(2,2),dpi=300)\n",
    "    sns.heatmap(data - expected,ax=ax,cmap='RdBu_r',cbar_kws={'label':'No. Pts. Act. - Exp.'},vmax=5, vmin=-5)\n",
    "    ax.set_title(f'{s_subtype} \\nChi2 p={p:.2}')\n",
    "    print(f'{s_subtype} {p:.3}')\n",
    "    fig.savefig(f'{s_date}/chi2_{s_subtype}.pdf')\n",
    "    all_combinations = list(combinations(data.columns, 2))\n",
    "    p_vals = []\n",
    "    for comb in all_combinations:\n",
    "        try:\n",
    "            # subset df into a dataframe containing only the pair \"comb\"\n",
    "            new_df = data.loc[:,(data.columns == comb[0]) | (data.columns == comb[1])]\n",
    "            # running chi2 test\n",
    "            chi2, p, dof, ex = stats.chi2_contingency(new_df, correction=False)\n",
    "            p_vals.append(p)\n",
    "        except:\n",
    "            p_vals.append(1)\n",
    "    reject_list, corrected_p_vals = multipletests(p_vals, method='fdr_bh')[:2]\n",
    "    for pair, p in dict(zip(all_combinations,corrected_p_vals)).items():\n",
    "        if p <0.05:\n",
    "            print(f\"Chi2 result for pair {pair}: corrected p-value: {p}\")\n",
    "    print(len(df_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#patient_heatmap\n",
    "ls_annot=['leiden','Subtype','Platform']\n",
    "g, df_annot = util.patient_heatmap(df_p,ls_col,ls_annot,z_score=None,figsize=(6,5),linkage='ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importlib.reload(util)\n",
    "g.savefig(f'{savedir}/clustermap_PlatformandSubtype_{s_sample}_{s_type}_{s_partition}_{s_cell}_{s_type}_{n_neighbors}_{resolution}.pdf',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#more plots\n",
    "util.more_plots(adata,df_p,s_subtype,s_type,s_partition,s_cell,n_neighbors,resolution,z_score=None,linkage='ward',\n",
    "          s_color_p='Subtype',d_color_p = {'ER+':'gold','TNBC':'darkblue','HER2+':'darkred','ER+HER2+':'darkgreen'},\n",
    "           savedir=savedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(plotting)\n",
    "for s_subtype in ['ER+','TNBC']: #'ER+',,'HER2+'\n",
    "    for s_plat in ['cycIF','IMC','MIBI']:\n",
    "        df_p, cph = plotting.km_cph(adata,df_surv,s_subtype,s_plat,s_type,\n",
    "                s_partition,s_cell,resolution,\n",
    "                n_neighbors,savedir=savedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for s_subtype in ['TNBC','ER+']: #'ER+', #epithelial entropy not prognostic\n",
    "    for s_plat in ['cycIF','IMC','MIBI']:\n",
    "        plotting.km_cph_entropy(df_p,df,ls_col,s_subtype,s_plat,s_cell,savedir=savedir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cluster the platforms separate <a name=\"st2\"></a>\n",
    "\n",
    "to get stromal subtypes. not as significant\n",
    "\n",
    "\n",
    "[contents](#contents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results data\n",
    "s_sample = '20220420_JP-TMAs_IMC-TMAs_MIBI'\n",
    "savedir=f'{codedir}/{s_date}'\n",
    "df_file = pd.read_csv(f'{codedir}/Results/{s_sample}_results_files.csv',index_col=0)\n",
    "#df_file[(df_file.cell==s_cell) & (df_file.type!='MeanIntensity')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#adata\n",
    "importlib.reload(plotting)\n",
    "n_neighbors = 3 #4 norm, 6 more\n",
    "for s_plat in ['IMC', 'MIBI','cycIF']:\n",
    "    #s_plat =  'MIBI'#\n",
    "    for s_cell in ['stromal','all','leidencelltype5','epithelial']:\n",
    "        s_cell = 'stromal'\n",
    "        df_load = df_file[(df_file.cell==s_cell) & (df_file.type!='MeanIntensity')]\n",
    "        s_index = df_load.index[0]\n",
    "        df = pd.read_csv(f'{codedir}/{s_index}',index_col=0)\n",
    "        df.index = df.index.astype('str')\n",
    "        s_subtype = df_file.loc[s_index,'subtype'] \n",
    "        s_type = df_file.loc[s_index,'type'] \n",
    "        s_partition = df_file.loc[s_index,'partition'] \n",
    "        s_cell =df_file.loc[s_index,'cell'] \n",
    "        df['Platform'] = df.index.map(df_surv.Platform)\n",
    "        #subtyping adata\n",
    "        df_plat = df[df.Platform==s_plat]\n",
    "        ls_col = df.columns[df_plat.dtypes=='float64'][df_plat.loc[:,df_plat.columns[df_plat.dtypes=='float64']].sum()/len(df_plat) > 0.02]\n",
    "        if n_neighbors == 6:\n",
    "              ls_col = df.columns[df_plat.dtypes=='float64'][df_plat.loc[:,df_plat.columns[df_plat.dtypes=='float64']].sum()/len(df_plat) > 0.01] #0.01\n",
    "        elif n_neighbors == 3:\n",
    "              ls_col = df.columns[df_plat.dtypes=='float64'][df_plat.loc[:,df_plat.columns[df_plat.dtypes=='float64']].sum()/len(df_plat) > 0.001] #0.01\n",
    "      \n",
    "        adata = util.make_adata(df_plat, ls_col,df_surv, n_neighbors, s_subtype, s_type, s_partition, s_cell)\n",
    "        break\n",
    "    if s_plat == 'cycIF':\n",
    "        resolution = 0.4\n",
    "    elif s_plat == 'MIBI':\n",
    "        resolution = 0.5\n",
    "    else:\n",
    "        resolution = 0.3\n",
    "    adata = util.cluster_leiden(adata, resolution,n_neighbors, s_subtype, s_type, s_partition, s_cell)\n",
    "    adata.obs.index = adata.obs.index.astype('str')\n",
    "    for s_subtype in ['Both']:\n",
    "        df_p, cph = plotting.km_cph(adata,df_surv,s_subtype,s_plat,s_type,s_partition,s_cell,\n",
    "                                   resolution,n_neighbors, savedir=savedir) #,savedir=f'{codedir}/20220222/Survival_Plots_Both'\n",
    "        #df_p.to_csv(f'{s_date}/results_subtyping_{s_cell}_{s_type}_{s_plat}_{n_neighbors}_{resolution}.csv')\n",
    "    #'''\n",
    "    from sklearn.cluster import AgglomerativeClustering\n",
    "    if n_neighbors ==6:\n",
    "        resolution = 9 \n",
    "    elif n_neighbors ==3:\n",
    "        resolution = 3 \n",
    "    elif s_plat =='cycIF':\n",
    "        resolution = 6 \n",
    "    elif s_plat =='MIBI':\n",
    "        resolution = 6\n",
    "    elif s_plat =='IMC':\n",
    "        resolution = 6\n",
    "    print(resolution)\n",
    "    cluster = AgglomerativeClustering(n_clusters=resolution, metric='euclidean', linkage='complete')  \n",
    "    cluster.fit_predict(df_p.loc[:,ls_col])\n",
    "    adata.obs['leiden'] = (cluster.labels_).astype('str')#'''\n",
    "    for s_subtype in ['TNBC','ER+','HER2+']:\n",
    "        df_p, cph = plotting.km_cph(adata,df_surv,s_subtype,s_plat,s_type,s_partition,s_cell,\n",
    "                                resolution,n_neighbors,savedir=savedir) #,savedir=f'{codedir}/20220222/Survival_Plots_Both'\n",
    "        #df_p.to_csv(f'{s_date}/results_subtyping_{s_cell}_{s_type}_{s_plat}_h_{resolution}.csv')\n",
    "        #break\n",
    "        #more plots\n",
    "    plotting.more_plots(adata,df_p,s_subtype,s_type,s_partition,s_cell,n_neighbors,resolution,\n",
    "                            ls_col,z_score=0,linkage='complete',s_color_p='Subtype',\n",
    "          d_color_p = {'ER+':'gold','TNBC':'darkblue','HER2+':'darkred','ER+HER2+':'darkgreen'},savedir=savedir) #savedir=f'{codedir}/20220222/Survival_Plots_Both'\n",
    "    for s_subtype in ['TNBC','ER+','HER2+']: #'ER+', #stromal entropy not prognostic\n",
    "        plotting.km_cph_entropy(df_p,df,ls_col,s_subtype,s_plat,s_cell,savedir=savedir)\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# correlation within tissue <a name=\"st3\"></a>\n",
    "\n",
    "pearson heatmap\n",
    "\n",
    "[contents](#contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation \n",
    "\n",
    "d_match = { \n",
    "    'results_subtyping_stromal_LeidenClustering_IMC_h_3.csv' :'results_subtyping_epithelial_LeidenClustering_Both_h_8.csv',\n",
    "   'results_subtyping_stromal_LeidenClustering_cycIF_h_3.csv':'results_subtyping_epithelial_LeidenClustering_Both_h_8.csv',\n",
    "    'results_subtyping_stromal_LeidenClustering_MIBI_h_3.csv' :'results_subtyping_epithelial_LeidenClustering_Both_h_8.csv',\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bioinfokit.visuz.stat.corr_mat(table, corm, cmap, r, dim, show, figtype, axtickfontsize, axtickfontname, theme)\n",
    "#imc, cycIF, MIBI\n",
    "df_all = pd.DataFrame()\n",
    "for s_str,s_epi  in d_match.items():\n",
    "    df = pd.read_csv(f'Results/{s_epi}',index_col=0)\n",
    "    ls_tum = df.loc[:,((df.dtypes=='float64') & (~df.columns.str.contains('Survival')))].columns\n",
    "    df2 = pd.read_csv(f'Results/{s_str}',index_col=0)\n",
    "    if s_str.find('IMC') < 0:\n",
    "        print('making CD3')\n",
    "        se_cd3 = df2.loc[:,['CD4 T cell','CD8 T cell']].sum(axis=1)\n",
    "        df2.insert(3, 'CD3 T cell', se_cd3)\n",
    "    print(df2.index.nunique())\n",
    "    ls_str = df2.loc[:,((df2.dtypes=='float64') & (~df2.columns.str.contains('Survival')))].columns\n",
    "    df_plot = df.merge(df2,left_index=True,right_index=True,suffixes=('','c'))\n",
    "    ls_marker = df_plot.loc[:,((df_plot.dtypes=='float64') & (~df_plot.columns.str.contains('Survival')))].columns\n",
    "    ls_drop = df_plot.loc[:,ls_marker].loc[:,df_plot.loc[:,ls_marker].mean()==0].columns\n",
    "    df_all=pd.concat([df_all, (df_plot.loc[:,ls_marker].drop(ls_drop,axis=1))])\n",
    "    #break\n",
    "df_all['subtype'] = df_all.index.map(dict(zip(df_surv.index,df_surv.subtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "dim = (8,7)\n",
    "g = sns.clustermap(df_all.loc[:,df_all.dtypes=='float64'].corr().fillna(0))\n",
    "plt.close()\n",
    "categories_order = df_all.loc[:,df_all.dtypes=='float64'].corr().iloc[g.dendrogram_col.reordered_ind,:].index.tolist()\n",
    "df_all_cats = df_all.loc[:,categories_order]\n",
    "rho = df_all_cats.corr()\n",
    "pval = df_all_cats.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
    "p_vals = pval.applymap(lambda x: ''.join(['*' for t in [0.001,0.005,0.05] if x<=t]))\n",
    "fig, ax = plt.subplots(figsize=dim,dpi=300)\n",
    "sns.heatmap(df_all_cats.corr(), vmin=-1, vmax=1, annot=p_vals, fmt = '', cmap='RdBu_r',ax=ax)\n",
    "ax.set_title(f'Cell Type Correlation', fontdict={'fontsize':16}, pad=12);\n",
    "fig.savefig(f'{codedir}/{s_date}/heatmap_Celltype.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for s_sub in ['TNBC','ER+']:\n",
    "    df_plot = df_all[df_all.subtype==s_sub].drop('subtype',axis=1)\n",
    "    df_plot = df_plot.loc[:,~df_plot.isna().all()]\n",
    "\n",
    "    dim = (8,7)\n",
    "    g = sns.clustermap(df_plot.corr().fillna(0))\n",
    "    plt.close()\n",
    "    categories_order = df_plot.corr().iloc[g.dendrogram_col.reordered_ind,:].index.tolist()\n",
    "    df_plot = df_plot.loc[:,categories_order]\n",
    "    rho = df_plot.corr()\n",
    "    pval = df_plot.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
    "    p_vals = pval.applymap(lambda x: ''.join(['*' for t in [0.001,0.005,0.05] if x<=t]))\n",
    "    fig, ax = plt.subplots(figsize=dim,dpi=300)\n",
    "    sns.heatmap(df_plot.corr(), vmin=-1, vmax=1, annot=p_vals, fmt = '', cmap='RdBu_r',ax=ax)\n",
    "    ax.set_title(f'Cell Type Correlation {s_sub}', fontdict={'fontsize':16}, pad=12);\n",
    "    fig.savefig(f'{codedir}/{s_date}/heatmap_Celltype_{s_sub}.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial LDA correlation and Survival <a name=\"lda_corr\"></a>\n",
    "\n",
    "pearson heatmap, figure 5 scatterplots\n",
    "\n",
    "[contents](#contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd_lda = {'TNBC_IMC':{'Topic-0':'Vim+ FB', 'Topic-1':'SMA+ FB', \n",
    "                      'Topic-2':'Quiesc. str.', 'Topic-3':'FN+ FB', \n",
    "                      'Topic-4':'mixed FB', 'Topic-5':'T cell',\n",
    "       'Topic-6':'endothelial', 'Topic-7':'B cell'},\n",
    "          'ER+_IMC':{'Topic-0':'Vim+ FB', 'Topic-1':'SMA+ FB', \n",
    "                      'Topic-2':'Quiesc. str.', 'Topic-3':'FN+ FB', \n",
    "                      'Topic-4':'mixed FB', 'Topic-5':'T cell',\n",
    "       'Topic-6':'endothelial', 'Topic-7':'B cell'},\n",
    "         'TNBC_cycIF':{'Topic-0':'Macrophage', 'Topic-1':'CD44+ str.', \n",
    "                       'Topic-2':'Vim+ FB', 'Topic-3':'FB', 'Topic-4':'T cell', 'Topic-5':'endothelial',\n",
    "       'Topic-6':'B cell', 'Topic-7':'Quiesc. str.'},\n",
    "         'ER+_cycIF':{'Topic-0':'Vim+ FB', 'Topic-1':'mixed FB', \n",
    "                      'Topic-2':'Quiesc. str.', 'Topic-3':'ColI FB', \n",
    "                      'Topic-4':'T cell', 'Topic-5':'endothelial',\n",
    "       'Topic-6':'T cell', 'Topic-7':'T cell'}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#survival\n",
    "\n",
    "# ran CPH in 20220408_JP-IMC-MIBI-TMAs_survival_spatial.ipynb\n",
    "df_val = pd.DataFrame()\n",
    "alpha = 0.0005\n",
    "df_surv.index = df_surv.index.astype('str')\n",
    "savedir = f'{codedir}/{s_date}/Survival_Plots'\n",
    "for s_subtype in ['TNBC','ER+',]: \n",
    "    for s_time, s_censor in [('Survival_time','Survival'),('Recurrence_time','Recurrence')]:\n",
    "        for s_col in ['Vim+ FB',#'T cell',#'quies mix str', 'endothelial'\n",
    "                      'mixed FB',]:\n",
    "            for cutp in [.5,0.66,0.33]: \n",
    "                df_both = pd.DataFrame()\n",
    "                for s_plat in ['cycIF','IMC']: \n",
    "                    s_type = 'SpatialLDA'\n",
    "                    s_cell = 'Kmeans'\n",
    "                    k=8\n",
    "                    # if s_plat == 'cycIF':\n",
    "                    #     if s_subtype == 'ER+':\n",
    "                    #         k=7\n",
    "                    df_all=pd.read_csv(f'{codedir}/Results/results_{s_subtype}_{s_plat}_SpatialLDA_byPatient_byKmeans_k{k}.csv',index_col=0)\n",
    "                    df_all.index = df_all.index.astype('str')\n",
    "                    print(f'{s_subtype} {s_plat} n={len(df_all)}')\n",
    "                    if s_col == 'Vim+ FB':\n",
    "                        df_val = pd.concat([df_val, df_all])\n",
    "                    df_all = df_all.merge(df_surv,left_index=True,right_index=True)  \n",
    "                    if df_all.columns.isin([s_col]).any():\n",
    "                        df_km_out = util.single_km(df_all,s_cell,s_subtype,s_plat,s_col,savedir,alpha,cutp,s_time,s_censor)\n",
    "                        #print(len(df_km_out))\n",
    "                        df_both = pd.concat([df_both, df_km_out])\n",
    "                #print(len(df_both))\n",
    "                # both KM\n",
    "                df_both_surv = df_both.dropna()\n",
    "                s_title2 = f'{s_col} n={len(df_both_surv)}'\n",
    "                s_title1 = f'{s_subtype} {s_censor}'\n",
    "                #log rank\n",
    "                if len(df_both_surv) > 0:\n",
    "                    results = multivariate_logrank_test(event_durations=df_both_surv.loc[:,s_time],\n",
    "                                                    groups=df_both_surv.abundance, event_observed=df_both_surv.loc[:,s_censor])\n",
    "                #kaplan meier plotting\n",
    "                if results.summary.p[0] < 0.05:\n",
    "                    kmf = KaplanMeierFitter()\n",
    "                    fig, ax = plt.subplots(figsize=(3,3),dpi=300)\n",
    "                    for s_group in ['high','low']:\n",
    "                        df_abun = df_both_surv[df_both_surv.abundance==s_group]\n",
    "                        durations = df_abun.loc[:,s_time]\n",
    "                        event_observed = df_abun.loc[:,s_censor]\n",
    "                        try:\n",
    "                            kmf.fit(durations, event_observed,label=s_group)\n",
    "                            kmf.plot(ax=ax,ci_show=False,show_censors=True)\n",
    "                        except:\n",
    "                            results.summary.p[0] = 1\n",
    "                    ax.set_ylim(-0.1,1.1)\n",
    "                    ax.set_title(f'{s_title1}\\n{s_title2}\\np={results.summary.p[0]:.2}',fontsize=10)\n",
    "                    ax.legend(loc='upper right',title=f'{cutp}')\n",
    "                    ax.set_xlabel(s_time)\n",
    "                    plt.tight_layout()\n",
    "                    fig.savefig(f\"{savedir}/KM_{s_title1.replace(' ','_')}_{s_title2.replace(' ','_')}_{cutp}.pdf\",dpi=300)\n",
    "                # #CPH\n",
    "                cph = CoxPHFitter(penalizer=0.1)\n",
    "                try:\n",
    "                    df_dummy = pd.get_dummies(df_both).loc[:,[s_time,s_censor,'abundance_high']]\n",
    "                    s_marker = s_col\n",
    "                    df_dummy = df_dummy.rename({'abundance_high':s_marker},axis=1)\n",
    "                    df_dummy.index = df_dummy.index.astype('str')\n",
    "                    df_marker = df_dummy.merge(df_clin,left_index=True,right_index=True).loc[:,[s_time,s_censor,s_marker,'age','tumor_size','Stage']]\n",
    "                    df_marker = df_marker.dropna()\n",
    "                except:\n",
    "                    continue\n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter('ignore')\n",
    "                    try:\n",
    "                        #multi\n",
    "                        cph.fit(df_marker, s_time, event_col=s_censor) \n",
    "                        pvalue = cph.summary.loc[s_marker,'p']\n",
    "                        #print(pvalue)\n",
    "                    except:\n",
    "                        pvalue = 1\n",
    "                    if pvalue < 0.15:\n",
    "                        fig, ax = plt.subplots(figsize=(3,2),dpi=200)\n",
    "                        cph.plot(ax=ax)\n",
    "                        ax.set_title(f'{s_col} Neighborhood cutoff={cutp}\\n{s_subtype} {s_censor} p={pvalue:.2} n={len(df_marker)}')\n",
    "                        plt.tight_layout()\n",
    "                        fig.savefig(f\"{savedir}/CPH_{s_col} {s_subtype} {s_censor}.pdf\")\n",
    "    #         break\n",
    "    #     break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "49 + 59 + 30 + 170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation\n",
    "importlib.reload(util)\n",
    "df_sub = df_val.merge(df_surv,left_index=True,right_index=True)\n",
    "df_sub = df_sub[~df_sub.index.duplicated()]\n",
    "s_subtype='TNBC'\n",
    "s_plat = 'IMC'\n",
    "s_col = 'Vim+ FB'\n",
    "df_p = util.single_km(df_sub,'',s_subtype,s_plat,s_col,savedir = f'{s_date}',alpha=1,\n",
    "                            cutp=0.66,s_time=s_time,s_censor=s_censor,s_propo='Spatial LDA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#topics correlation!\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "d_match = { \n",
    "    'results_subtyping_stromal_LeidenClustering_IMC_h_3.csv' :'results_subtyping_epithelial_LeidenClustering_Both_h_8.csv',\n",
    "   'results_subtyping_stromal_LeidenClustering_cycIF_h_3.csv':'results_subtyping_epithelial_LeidenClustering_Both_h_8.csv',\n",
    "    'results_subtyping_stromal_LeidenClustering_MIBI_h_3.csv' :'results_subtyping_epithelial_LeidenClustering_Both_h_8.csv',\n",
    " }\n",
    "\n",
    "\n",
    "for s_str,s_epi  in d_match.items():\n",
    "    df = pd.read_csv(f'{codedir}/Results/{s_epi}',index_col=0)\n",
    "    print(f'reading {s_epi}')\n",
    "    ls_tum = df.loc[:,((df.dtypes=='float64') & (~df.columns.str.contains('Survival')))].columns\n",
    "    df2 = pd.read_csv(f'{codedir}/Results/{s_str}',index_col=0)\n",
    "    print(f'reading {s_str}')\n",
    "    if s_str.find('IMC') < 0:\n",
    "        print('making CD3')\n",
    "        se_cd3 = df2.loc[:,['CD4 T cell','CD8 T cell']].sum(axis=1)\n",
    "        df2.insert(3, 'CD3 T cell', se_cd3)\n",
    "    ls_str = df2.loc[:,((df2.dtypes=='float64') & (~df2.columns.str.contains('Survival')))].columns\n",
    "    df_plot = df.merge(df2,left_index=True,right_index=True,suffixes=('','c'))\n",
    "    ls_marker = df_plot.loc[:,((df_plot.dtypes=='float64') & (~df_plot.columns.str.contains('Survival')))].columns\n",
    "    ls_drop = df_plot.loc[:,ls_marker].loc[:,df_plot.loc[:,ls_marker].mean()==0].columns\n",
    "    s_plat = s_str.split('_')[-3]\n",
    "    df_plot = df_plot.loc[:,ls_marker].drop(ls_drop,axis=1)\n",
    "    for s_sub in ['TNBC','ER+',]:\n",
    "        try:\n",
    "            df3 = pd.read_csv(f'{codedir}/Results/results_{s_sub}{s_plat}_SpatialLDA_byPatient_bymean_k8.csv',index_col=0)\n",
    "        except:\n",
    "            continue\n",
    "        d_rename = dd_lda[f'{s_sub}_{s_plat}']\n",
    "        df_plot['subtype'] = df_plot.index.map(dict(zip(df_surv.index,df_surv.subtype)))\n",
    "        df_plot_sub = df_plot[df_plot.subtype==s_sub].drop('subtype',axis=1)\n",
    "        df_plot_sub = df_plot_sub.loc[:,~df_plot_sub.isna().all()]\n",
    "        df3.columns = [f'{item} {d_rename[item]}' for item in df3.columns]\n",
    "        dim = (8,7)\n",
    "        df_plot_sub = df_plot_sub.merge(df3,left_index=True,right_index=True)\n",
    "        if len(df_plot_sub) >1:\n",
    "            g = sns.clustermap(df_plot_sub.corr().fillna(0))\n",
    "            plt.close()\n",
    "            categories_order = df_plot_sub.corr().iloc[g.dendrogram_col.reordered_ind,:].index.tolist()\n",
    "            df_plot_sub = df_plot_sub.loc[:,categories_order]\n",
    "            rho = df_plot_sub.corr()\n",
    "            pval = df_plot_sub.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
    "            p_vals = pval.applymap(lambda x: ''.join(['*' for t in [0.001,0.005,0.05] if x<=t]))\n",
    "            fig, ax = plt.subplots(figsize=dim,dpi=300)\n",
    "            sns.heatmap(df_plot_sub.corr(), vmin=-1, vmax=1, annot=p_vals, fmt = '', cmap='RdBu_r',ax=ax)\n",
    "            ax.set_title(f'Cell Type Correlation {s_plat} {s_sub}', fontdict={'fontsize':16}, pad=12);\n",
    "            fig.savefig(f'{codedir}/{s_date}/heatmap_Celltype_{s_plat}_{s_sub}.pdf', dpi=300, bbox_inches='tight')\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#neighborhoods correlation!\n",
    "#platforms separate\n",
    "for s_str,s_epi  in d_match.items():\n",
    "    df = pd.read_csv(f'{codedir}/Results/{s_epi}',index_col=0)\n",
    "    print(f'reading {s_epi}')\n",
    "    ls_tum = df.loc[:,((df.dtypes=='float64') & (~df.columns.str.contains('Survival')))].columns\n",
    "    df2 = pd.read_csv(f'{codedir}/Results/{s_str}',index_col=0)\n",
    "    print(f'reading {s_str}')\n",
    "    if s_str.find('IMC') < 0:\n",
    "        print('making CD3')\n",
    "        se_cd3 = df2.loc[:,['CD4 T cell','CD8 T cell']].sum(axis=1)\n",
    "        df2.insert(3, 'CD3 T cell', se_cd3)\n",
    "    ls_str = df2.loc[:,((df2.dtypes=='float64') & (~df2.columns.str.contains('Survival')))].columns\n",
    "    df_plot = df.merge(df2,left_index=True,right_index=True,suffixes=('','c'))\n",
    "    ls_marker = df_plot.loc[:,((df_plot.dtypes=='float64') & (~df_plot.columns.str.contains('Survival')))].columns\n",
    "    ls_drop = df_plot.loc[:,ls_marker].loc[:,df_plot.loc[:,ls_marker].mean()==0].columns\n",
    "    s_plat = s_str.split('_')[-3]\n",
    "    df_plot = df_plot.loc[:,ls_marker].drop(ls_drop,axis=1)\n",
    "    for s_sub in ['ER+','TNBC']:\n",
    "        try:\n",
    "            df3 = pd.read_csv(f'{codedir}/Results/results_{s_sub}_{s_plat}_SpatialLDA_byPatient_byKmeans_k8.csv',index_col=0)\n",
    "        except:\n",
    "            continue\n",
    "        df_plot['subtype'] = df_plot.index.map(dict(zip(df_surv.index,df_surv.subtype)))\n",
    "        df_plot_sub = df_plot[df_plot.subtype==s_sub].drop('subtype',axis=1)\n",
    "        df_plot_sub = df_plot_sub.loc[:,~df_plot_sub.isna().all()]\n",
    "        df3.columns = [f'{item} neighborhood' for item in df3.columns]\n",
    "        dim = (8,7)\n",
    "        df_plot_sub = df_plot_sub.merge(df3,left_index=True,right_index=True)\n",
    "        print(len(df_plot_sub))\n",
    "        if len(df_plot_sub) >1:\n",
    "            g = sns.clustermap(df_plot_sub.corr().fillna(0))\n",
    "            plt.close()\n",
    "            categories_order = df_plot_sub.corr().iloc[g.dendrogram_col.reordered_ind,:].index.tolist()\n",
    "            df_plot_sub = df_plot_sub.loc[:,categories_order]\n",
    "            rho = df_plot_sub.corr()\n",
    "            pval = df_plot_sub.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
    "            p_vals = pval.applymap(lambda x: ''.join(['*' for t in [0.001,0.005,0.05] if x<=t]))\n",
    "            fig, ax = plt.subplots(figsize=dim,dpi=300)\n",
    "            sns.heatmap(df_plot_sub.corr(), vmin=-1, vmax=1, annot=p_vals, fmt = '', cmap='RdBu_r',ax=ax)\n",
    "            ax.set_title(f'Cell Type Correlation {s_plat} {s_sub}', fontdict={'fontsize':16}, pad=12);\n",
    "            fig.savefig(f'{codedir}/{s_date}/heatmap_Kmeans_and_Celltype_{s_plat}_{s_sub}.pdf', dpi=300, bbox_inches='tight')\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## figure 5 scatterplots  \n",
    "<a name=\"lda_scatter\"></a>\n",
    "\n",
    "pearson heatmap LDA, figure 5 scatterplots\n",
    "\n",
    "[contents](#contents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#neighborhoods correlation!\n",
    "#platforms together\n",
    "dd_match = {0:{ 'results_subtyping_stromal_LeidenClustering_IMC_h_3.csv' :'results_subtyping_epithelial_LeidenClustering_Both_h_8.csv',\n",
    "   'results_subtyping_stromal_LeidenClustering_cycIF_h_3.csv':'results_subtyping_epithelial_LeidenClustering_Both_h_8.csv',\n",
    "    #'results_subtyping_stromal_LeidenClustering_MIBI_h_3.csv' :'results_subtyping_epithelial_LeidenClustering_Both_h_8.csv',\n",
    "              },\n",
    "1:{ 'results_subtyping_stromal_LeidenClustering_IMC_h_3.csv' :'results_subtyping_epithelial_LeidenClustering_Both_h_8.csv',\n",
    "   'results_subtyping_stromal_LeidenClustering_cycIF_h_3.csv':'results_subtyping_epithelial_LeidenClustering_Both_h_8.csv',\n",
    "    'results_subtyping_stromal_LeidenClustering_MIBI_h_3.csv' :'results_subtyping_epithelial_LeidenClustering_Both_h_8.csv',},\n",
    "              }\n",
    "for key,d_match in dd_match.items():\n",
    "    d_results = {}\n",
    "    for s_sub in ['TNBC','ER+']:\n",
    "        df_both = pd.DataFrame()\n",
    "        for s_str,s_epi  in d_match.items():\n",
    "            print(s_str)\n",
    "            df = pd.read_csv(f'{codedir}/Results/{s_epi}',index_col=0)\n",
    "            ls_tum = df.loc[:,((df.dtypes=='float64') & (~df.columns.str.contains('Survival')))].columns\n",
    "            df2 = pd.read_csv(f'{codedir}/Results/{s_str}',index_col=0)\n",
    "            if s_str.find('IMC') < 0:\n",
    "                print('making CD3')\n",
    "                se_cd3 = df2.loc[:,['CD4 T cell','CD8 T cell']].sum(axis=1)\n",
    "                df2.insert(3, 'CD3 T cell', se_cd3)\n",
    "            ls_str = df2.loc[:,((df2.dtypes=='float64') & (~df2.columns.str.contains('Survival')))].columns\n",
    "            df_plot = df.merge(df2,left_index=True,right_index=True,suffixes=('','c'))\n",
    "            ls_marker = df_plot.loc[:,((df_plot.dtypes=='float64') & (~df_plot.columns.str.contains('Survival')))].columns\n",
    "            ls_drop = df_plot.loc[:,ls_marker].loc[:,df_plot.loc[:,ls_marker].mean()==0].columns\n",
    "            s_plat = s_str.split('_')[-3]\n",
    "            df_plot = df_plot.loc[:,ls_marker].drop(ls_drop,axis=1)\n",
    "            try:\n",
    "                df3 = pd.read_csv(f'{codedir}/Results/results_{s_sub}_{s_plat}_SpatialLDA_byPatient_byKmeans_k8.csv',index_col=0)\n",
    "            except:\n",
    "                pass\n",
    "            #d_rename = dd_lda[f'{s_sub}_{s_plat}']\n",
    "            df_plot['subtype'] = df_plot.index.map(dict(zip(df_surv.index,df_surv.subtype)))\n",
    "            df_plot_sub = df_plot[df_plot.subtype==s_sub].drop('subtype',axis=1)\n",
    "            df_plot_sub = df_plot_sub.loc[:,~df_plot_sub.isna().all()]\n",
    "            df3.columns = [f'{item} neighborhood' for item in df3.columns]\n",
    "            dim = (9,8)\n",
    "            df_plot_sub = df_plot_sub.merge(df3,left_index=True,right_index=True,how='left')\n",
    "            #print(len(df_plot_sub))\n",
    "            df_both = pd.concat([df_both,df_plot_sub])\n",
    "        if s_sub == 'TNBC':\n",
    "            df_both.drop(['Luminal ER+ t.','HER2+ ER+ t.'],axis=1,inplace=True)\n",
    "        d_results.update({s_sub:df_both.copy()})\n",
    "        if key==0:\n",
    "            print(len(df_both))\n",
    "        if len(df_both) >1:\n",
    "            \n",
    "            g = sns.clustermap(df_both.corr().fillna(0))\n",
    "            plt.close()\n",
    "            categories_order = df_both.corr().iloc[g.dendrogram_col.reordered_ind,:].index.tolist()\n",
    "            df_both = df_both.loc[:,categories_order]\n",
    "            rho = df_both.corr()\n",
    "            pval = df_both.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
    "            p_vals = pval.applymap(lambda x: ''.join(['*' for t in [0.001,0.005,0.05] if x<=t]))\n",
    "            fig, ax = plt.subplots(figsize=dim,dpi=300)\n",
    "            sns.heatmap(df_both.corr(), vmin=-1, vmax=1, annot=p_vals, fmt = '', cmap='RdBu_r',ax=ax,yticklabels=1)\n",
    "            ax.set_title(f'Cell Type and Tumor Neighborhood \\nCorrelation {s_sub}', fontdict={'fontsize':16}, pad=12);\n",
    "            if key == 0:    \n",
    "                fig.savefig(f'{codedir}/{s_date}/heatmap_bothplatfoems_Kmeans_and_Celltype_both_{s_sub}.pdf', dpi=300, bbox_inches='tight')\n",
    "            \n",
    "            #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#make sure MIBI in scatterplots\n",
    "df_test = d_results['TNBC']\n",
    "df_test[df_test.index.str.find('M')==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#scatterplots new end or figure 5\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "hue_order = ['cycIF','IMC', 'MIBI']\n",
    "\n",
    "\n",
    "d_plots = {'TNBC':[['CD3 T cell', 'Prolif. t.'],['Macrophage', 'CD8 T cell'],['Vim+ FB neighborhood','FN+ FB neighborhood']], \n",
    "           'ER+':[['Luminal t.','CK lo. t.'],['CD3 T cell','CD20 B cell'],#['Macrophage', 'endothelial'],\n",
    "                  #['endothelial', 'Prolif. t.'],#\n",
    "                  ['CD3 T cell', 'Prolif. t.'],\n",
    "                  #['Macrophage', 'CD3 T cell'],\n",
    "                  ['T cell neighborhood', 'Prolif. t.']]}\n",
    "for s_subtype, df_plot in d_results.items():\n",
    "    df_plot['Platform'] = pd.NA\n",
    "    df_plot.loc[df_plot.index.str.contains('-'),'Platform'] = 'cycIF'\n",
    "    df_plot.loc[df_plot.index.str.find('M')==0,'Platform'] = 'MIBI'\n",
    "    df_plot['Platform'].fillna('IMC',inplace=True)\n",
    "    lls_pairs = d_plots[s_subtype]\n",
    "    for ls_pair in lls_pairs:\n",
    "        s_marker = ls_pair[0]\n",
    "        s_tum = ls_pair[1]\n",
    "        df_sub = df_plot.loc[:,[s_marker,s_tum,'Platform']].dropna()\n",
    "        print(f'{s_marker} vs {s_tum} n={len(df_sub)} plats={df_sub.groupby(\"Platform\").count()} ')\n",
    "        r, pvalue = stats.pearsonr(x=df_sub.loc[:,s_tum], y=df_sub.loc[:,s_marker])\n",
    "        fig, ax = plt.subplots(figsize=(2,2.6),dpi=200)\n",
    "        sns.scatterplot(x=s_tum, y=s_marker, data=df_plot,ax=ax,hue='Platform',hue_order=hue_order,s=15, legend=False,)\n",
    "        ax.set_title(f'{s_tum.replace(\"neighborhood\",\"NH\")} vs {s_marker.replace(\"neighborhood\",\"NH\")}\\n{s_subtype} n={len(df_sub)}\\nr={r:.2f} p={pvalue:.3f}',fontsize=12)\n",
    "        handles = [mpatches.Patch(color=f'C{pair[0]}',label=pair[1]) for pair in enumerate(hue_order)]\n",
    "        #ax.legend(handles=handles,bbox_to_anchor=(1,0.4))\n",
    "        fig.savefig(f'{codedir}/{s_date}/scatterplots__{s_subtype}_{s_marker}_{s_tum}.pdf', bbox_inches='tight')\n",
    "        #break\n",
    "ax.legend(handles=handles,bbox_to_anchor=(1,0.4),frameon=False)\n",
    "fig.savefig(f'{codedir}/{s_date}/scatterplots_legend_{s_subtype}_{s_marker}_{s_tum}.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dict(zip(df_surv.index,df_surv.subtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_plot['subtype'] = df_plot.index.map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sub[df_sub.Platform=='MIBI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scatterplots not used\n",
    "################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_match = { \n",
    "#     'results_subtyping_stromal_LeidenClustering_IMC_h_3.csv' :'results_subtyping_epithelial_LeidenClustering_Both_h_8.csv',\n",
    "#    'results_subtyping_stromal_LeidenClustering_cycIF_h_3.csv':'results_subtyping_epithelial_LeidenClustering_Both_h_8.csv',\n",
    "#     'results_subtyping_stromal_LeidenClustering_MIBI_h_3.csv' :'results_subtyping_epithelial_LeidenClustering_Both_h_8.csv',\n",
    "#  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #pearson correlation scatterplots (all subtypes)\n",
    "# alpha=0.2\n",
    "# hue_order = ['ER+','TNBC', 'HER2+', 'ER+HER2+']\n",
    "# for s_str,s_epi  in d_match.items():\n",
    "#     df = pd.read_csv(f'Results/{s_epi}',index_col=0)\n",
    "#     ls_tum = df.loc[:,((df.dtypes=='float64') & (~df.columns.str.contains('Survival')))].columns\n",
    "#     df2 = pd.read_csv(f'Results/{s_str}',index_col=0)\n",
    "#     if s_str.find('IMC') < 0:\n",
    "#         print('making CD3')\n",
    "#         df2['CD3 T cell'] = df2.loc[:,['CD4 T cell','CD8 T cell']].sum(axis=1)\n",
    "#     ls_str = df2.loc[:,((df2.dtypes=='float64') & (~df2.columns.str.contains('Survival')))].columns\n",
    "#     df_plot = df.merge(df2,left_index=True,right_index=True,suffixes=('','c'))\n",
    "    \n",
    "#     for s_marker in ls_str:\n",
    "#         s_marker = 'Luminal t.'#'CD3 T cell'\n",
    "#         for s_tum in ls_tum:\n",
    "#             s_tum = 'CK lo. t.'#'Luminal ER+ t.'#\n",
    "#             r, pvalue = stats.pearsonr(x=df_plot.loc[:,s_tum], y=df_plot.loc[:,s_marker])\n",
    "#             if pvalue < alpha:\n",
    "#                 fig, ax = plt.subplots(figsize=(2.5,2.6),dpi=200)\n",
    "#                 sns.scatterplot(x=s_tum, y=s_marker, data=df_plot,ax=ax,hue='Subtype',hue_order=hue_order,s=15, legend=False,)\n",
    "#                 #ax.set_title(f'{s_tum} vs {s_marker}')\n",
    "#                 ax.set_ylabel(f'Fraction {s_marker} in Str.')\n",
    "#                 ax.set_xlabel(f'Fraction {s_tum} in Tumor')\n",
    "#                 ax.set_title(f'{s_tum} vs {s_marker}\\n {df_plot.Platform[0]} r = {r:.2f} \\np = {pvalue:.5f} n={len(df_plot)}',fontsize=12)\n",
    "#                 #ax.legend(bbox_to_anchor=(1,.6))\n",
    "#                 plt.tight_layout()\n",
    "#                 fig.savefig(f'{s_date}/scatterplot_{s_tum}_versus_{s_marker}_in_{df_plot.Platform[0]}.pdf')\n",
    "#                 #plt.close(fig)\n",
    "#             break\n",
    "#         break\n",
    "                \n",
    "        \n",
    "\n",
    "#     break\n",
    "    \n",
    "# ##examples\n",
    "# #df_plot.loc[:,['Luminal ER+ t.','FN+ FB']].sort_values(by='FN+ FB',ascending=False)[0:15]\n",
    "# #df_plot.loc[:,['Luminal ER+ t.','Quies. str.','Subtype']].sort_values(by='Quies. str.',ascending=False)[0:15]\n",
    "# #df_plot.loc[:,['Prolif. t.','CD3 T cell']].sort_values(by='CD3 T cell',ascending=False)[0:15]\n",
    "# #df_a[df_a.PID=='Z44']\n",
    "# #df_a[df_a.PID==7]\n",
    "# #df_a[df_a.PID=='Z33']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #pearson correlation by subtype \n",
    "# #scatterplots\n",
    "# hue_order = ['TNBC','ER+', 'HER2+', 'ER+HER2+']\n",
    "# for s_str,s_epi  in d_match.items():\n",
    "#     df = pd.read_csv(f'Results/{s_epi}',index_col=0)\n",
    "#     ls_tum = df.loc[:,((df.dtypes=='float64') & (~df.columns.str.contains('Survival')))].columns\n",
    "#     df2 = pd.read_csv(f'Results/{s_str}',index_col=0)\n",
    "#     if s_str.find('IMC') < 0:\n",
    "#         print('making CD3')\n",
    "#         df2['CD3 T cell'] = df2.loc[:,['CD4 T cell','CD8 T cell']].sum(axis=1)\n",
    "#     ls_str = df2.loc[:,((df2.dtypes=='float64') & (~df2.columns.str.contains('Survival')))].columns\n",
    "#     df_plot = df.merge(df2,left_index=True,right_index=True,suffixes=('','c'))\n",
    "    \n",
    "#     for s_marker in ls_str:\n",
    "#         for s_tum in ls_tum:\n",
    "#             for s_subt in hue_order:\n",
    "#                 df_plot_sub = df_plot[df_plot.Subtype==s_subt]\n",
    "#                 if len(df_plot_sub) > 2:\n",
    "#                     r, pvalue = stats.pearsonr(x=df_plot_sub.loc[:,s_tum], y=df_plot_sub.loc[:,s_marker])\n",
    "#                     if pvalue < 1:\n",
    "#                         fig, ax = plt.subplots(figsize=(2.5,2.6),dpi=200)\n",
    "#                         sns.scatterplot(x=s_tum, y=s_marker, data=df_plot_sub,ax=ax,hue='Subtype',hue_order=hue_order,s=15, legend=False,)\n",
    "#                         #ax.set_title(f'{s_tum} vs {s_marker}')\n",
    "#                         ax.set_ylabel(f'Fraction {s_marker} in Str.')\n",
    "#                         ax.set_xlabel(f'Fraction {s_tum} in Tumor')\n",
    "#                         ax.set_title(f'{s_tum} vs {s_marker}\\n {df_plot_sub.Platform[0]} {s_subt} r = {r:.2f} \\np = {pvalue:.5f}  n={len(df_plot_sub)}',fontsize=12)\n",
    "#                         #ax.legend(bbox_to_anchor=(1,.6))\n",
    "#                         plt.tight_layout()\n",
    "#                         fig.savefig(f'{s_date}/scatterplot_{s_tum}_versus_{s_marker}_in_{df_plot_sub.Platform[0]}_{s_subt}.pdf')\n",
    "#                         plt.close(fig)\n",
    "#                 break\n",
    "#             break\n",
    "#         break\n",
    "#     break\n",
    "                \n",
    "        \n",
    "\n",
    "#     #break\n",
    "    \n",
    "# ##examples\n",
    "# #df_plot.loc[:,['Luminal ER+ t.','FN+ FB']].sort_values(by='FN+ FB',ascending=False)[0:15]\n",
    "# #df_plot.loc[:,['Luminal ER+ t.','Quies. str.','Subtype']].sort_values(by='Quies. str.',ascending=False)[0:15]\n",
    "# #df_plot.loc[:,['Prolif. t.','CD3 T cell']].sort_values(by='CD3 T cell',ascending=False)[0:15]\n",
    "# #df_a[df_a.PID=='Z44']\n",
    "# #df_a[df_a.PID==7]\n",
    "# #df_a[df_a.PID=='Z33']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #pearson correlation stroma (scatterplots)\n",
    "# hue_order = ['TNBC','ER+', 'HER2+', 'ER+HER2+']\n",
    "# for s_str,s_epi  in d_match.items():\n",
    "#     df2 = pd.read_csv(f'Results/{s_str}',index_col=0)\n",
    "#     ls_str = df2.loc[:,((df2.dtypes=='float64') & (~df2.columns.str.contains('Survival')))].columns\n",
    "#     df_plot = df2\n",
    "#     for s_tum, s_marker  in itertools.combinations(ls_str,r=2):\n",
    "#         r, pvalue = stats.pearsonr(x=df_plot.loc[:,s_tum], y=df_plot.loc[:,s_marker])\n",
    "#         if pvalue < 0.05:\n",
    "#             fig, ax = plt.subplots(figsize=(2.5,2.6),dpi=200)\n",
    "#             sns.scatterplot(x=s_tum, y=s_marker, data=df_plot,ax=ax,hue='Subtype',hue_order=hue_order,legend=False,s=15) # \n",
    "#             #ax.set_title(f'{s_tum} vs {s_marker}')\n",
    "#             ax.set_ylabel(f'Fraction {s_marker} in Stroma')\n",
    "#             ax.set_xlabel(f'Fraction {s_tum} in Stroma')\n",
    "#             ax.set_title(f'{s_tum} vs {s_marker}\\n {df_plot.Platform[0]} r = {r:.2f} \\np = {pvalue:.5f}')\n",
    "#             #ax.legend(bbox_to_anchor=(1,.5))\n",
    "#             plt.tight_layout()\n",
    "#             fig.savefig(f'{s_date}/scatterplot_{s_tum}_versus_{s_marker}_in_{df_plot.Platform[0]}.pdf')\n",
    "#             #break\n",
    "#             #plt.close(fig)\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_match = { \n",
    "    'results_subtyping_stromal_LeidenClustering_IMC_h_3.csv' :'results_subtyping_epithelial_LeidenClustering_Both_h_8.csv',\n",
    "   'results_subtyping_stromal_LeidenClustering_cycIF_h_3.csv':'results_subtyping_epithelial_LeidenClustering_Both_h_8.csv',\n",
    "    #'results_subtyping_stromal_LeidenClustering_MIBI_h_6.csv' :'results_subtyping_epithelial_LeidenClustering_Both_h_8.csv',\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Stromal confusion matrix: chi squared\n",
    "s_col = 'Subtype'\n",
    "for s_str,s_epi  in d_match.items():\n",
    "    df = pd.read_csv(f'Results/{s_epi}',index_col=0)\n",
    "    ls_subtypes = ['ER+', 'TNBC'] #sorted(df.loc[:,s_col].unique())\n",
    "    df2 = pd.read_csv(f'Results/{s_str}',index_col=0)\n",
    "    df = df.merge(df2,left_index=True,right_index=True,suffixes=('_e','_s'))#.dropna()\n",
    "    print(len(df))\n",
    "    s_type = s_str.split('_')[2]\n",
    "    s_plat = s_str.split('_')[-3]\n",
    "    print(s_type)\n",
    "    df = df[df.loc[:,f'{s_col}_e'].isin(ls_subtypes)]\n",
    "    confusion_matrix = pd.crosstab(df.leiden_e,df.leiden_s)\n",
    "    confusion_matrix = pd.crosstab(df.loc[:,f'{s_col}_e'],df.leiden_s)\n",
    "    #confusion_matrix = confusion_matrix.loc[:,confusion_matrix.sum() >20]\n",
    "    chi2, pvalue, dof, expected  = stats.chi2_contingency(confusion_matrix)\n",
    "    print(pvalue)\n",
    "    fig,ax = plt.subplots(dpi=400,figsize=(4,2.5))\n",
    "    #old sns.heatmap(confusion_matrix, annot=True,ax=ax,cbar_kws={'label':'No. Patients'},cmap='viridis',vmax=23)\n",
    "    sns.heatmap(confusion_matrix - expected, annot=False,ax=ax,cbar_kws={'label':'Obs. - Exp.'},cmap='bwr',center=0)\n",
    "    ax.set_title(f\"{s_col} vs. {s_type.capitalize()} \\n{s_plat} p = {pvalue:.3f} n={confusion_matrix.sum().sum()}\")\n",
    "    ax.set_ylim(ax.get_ylim()[::-1])\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    #plot pvals\n",
    "    result_val = util.post_hoc(confusion_matrix)\n",
    "    for y_idx, p in enumerate(result_val.index):\n",
    "        for x_idx, s in enumerate(result_val.columns):\n",
    "            pval = result_val.loc[p,s]\n",
    "            plt.text(x=x_idx+.25, y=y_idx, s=pval, color='black',size='small')\n",
    "    fig.savefig(f'{codedir}/{s_date}/confusion__{s_str}_{s_epi}_{s_col}.pdf', bbox_inches='tight')\n",
    "    fig,ax = plt.subplots(dpi=400,figsize=(5,2.7))\n",
    "    sns.heatmap(expected, annot=True,ax=ax,cbar_kws={'label':'Exp. No. Patients'},cmap='viridis',vmax=23)\n",
    "    ax.set_ylim(ax.get_ylim()[::-1])\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(f'{codedir}/{s_date}/expected__{s_subtype}_{s_marker}_{s_tum}.pdf', bbox_inches='tight')\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Epithelial confusion matrix (chi squared)\n",
    "s_col = 'Subtype'\n",
    "for s_epi,s_str  in d_match.items():\n",
    "    df = pd.read_csv(f'Results/{s_epi}',index_col=0)\n",
    "    ls_subtypes = ['ER+', 'TNBC'] #sorted(df.loc[:,s_col].unique())\n",
    "    df2 = pd.read_csv(f'Results/{s_str}',index_col=0)\n",
    "    df = df.merge(df2,left_index=True,right_index=True,suffixes=('_e','_s'))#.dropna()\n",
    "    print(len(df))\n",
    "    s_type = s_str.split('_')[2]\n",
    "    s_plat = s_str.split('_')[-3]\n",
    "    print(s_type)\n",
    "    df = df[df.loc[:,f'{s_col}_e'].isin(ls_subtypes)]\n",
    "    confusion_matrix = pd.crosstab(df.leiden_e,df.leiden_s)\n",
    "    confusion_matrix = pd.crosstab(df.loc[:,f'{s_col}_e'],df.leiden_s)\n",
    "    #confusion_matrix = confusion_matrix.loc[:,confusion_matrix.sum() >20]\n",
    "    chi2, pvalue, dof, expected  = stats.chi2_contingency(confusion_matrix)\n",
    "    print(pvalue)\n",
    "    fig,ax = plt.subplots(dpi=400,figsize=(5,2.5))\n",
    "    #old sns.heatmap(confusion_matrix, annot=True,ax=ax,cbar_kws={'label':'No. Patients'},cmap='viridis',vmax=23)\n",
    "    sns.heatmap(confusion_matrix - expected, annot=False,ax=ax,cbar_kws={'label':'Obs. - Exp.'},cmap='bwr',center=0)\n",
    "    ax.set_title(f\"{s_col} vs. {s_type.capitalize()} \\n(p = {pvalue:.3f})\")\n",
    "    ax.set_ylim(ax.get_ylim()[::-1])\n",
    "    plt.tight_layout()\n",
    "    #plot pvals\n",
    "    result_val = util.post_hoc(confusion_matrix)\n",
    "    for y_idx, p in enumerate(result_val.index):\n",
    "        for x_idx, s in enumerate(result_val.columns):\n",
    "            pval = result_val.loc[p,s]\n",
    "            plt.text(x=x_idx+.25, y=y_idx, s=pval, color='black',size='small')\n",
    "    fig.savefig(f'./{s_date}/Chi_square_group_clustering_{s_type}_{s_col}.pdf')\n",
    "    fig,ax = plt.subplots(dpi=400,figsize=(5,2.7))\n",
    "    sns.heatmap(expected, annot=True,ax=ax,cbar_kws={'label':'Exp. No. Patients'},cmap='viridis',vmax=23)\n",
    "    ax.set_ylim(ax.get_ylim()[::-1])\n",
    "    plt.tight_layout()\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regression <a name=\"st4\"></a>\n",
    "\n",
    "[contents](#contents)\n",
    "\n",
    "\n",
    "- immune, stromal, entropy versus epithelial subtype\n",
    "- TNBC, ER+ high/low versus cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load annotation\n",
    "df_surv = pd.read_csv('data/TMA_Survival_Subtype.csv',index_col=0)\n",
    "df_clin = pd.read_csv('data/TMA_Clinical_Variables.csv',index_col=0)\n",
    "df_surv.loc[df_surv.index.str.contains('JP-TMA2'),'Platform'] = 'cycIF2'\n",
    "df_surv['Neoadjuvant'] = df_surv.Neoadjuvant.replace({True:'Yes',False:'No'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "s_index_ep = 'results_20220420_JP-TMAs_IMC-TMAs_MIBI_LeidenClustering_byPatient_byleidencelltype2_inepithelial_all.csv'\n",
    "s_index_str = 'results_20220420_JP-TMAs_IMC-TMAs_MIBI_LeidenClustering_byPatient_byleidencelltype2_instromal_all.csv'\n",
    "\n",
    "df_e = pd.read_csv(f'Results/{s_index_ep}',index_col=0)\n",
    "df_s = pd.read_csv(f'Results/{s_index_str}',index_col=0)\n",
    "s_denom = s_index_str.split('by')[-1].split('_')[1].replace('in','').split('.')[0]\n",
    "df_s['entropy'] = entropy(df_s.fillna(0),axis=1,base=2)\n",
    "df = df_e.merge(df_s,left_index=True,right_index=True,suffixes=('_e','_s'))\n",
    "df = df.merge(df_surv,left_index=True,right_index=True,suffixes=('_x',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'CD3 T cell'].fillna(df.loc[:,['CD4 T cell','CD8 T cell']].sum(axis=1),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neoadjuvant vs celltypes   <a name=\"neoadj\"></a>\n",
    "\n",
    "[contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df.columns\n",
    "ls_order = ['Yes','No']\n",
    "ls_cell = ['Basal t.', 'CK lo. t.', 'Luminal ER+ t.', 'Luminal t.',\n",
    "       'Myoepithelial', 'Prolif. t.','CD20 B cell',\n",
    "        'CD3 T cell', 'CD4 T cell', 'CD44+ str.', 'CD8 T cell',\n",
    "       'ColI+ FB',  'FB', \n",
    "       'Macrophage',  'Quies. str.',\n",
    "       'Vim+ FB', 'endothelial']\n",
    "dd_correct = {'Neoadjuvant':{'Basal t.': 0.9778486748164886,\n",
    " 'CK lo. t.': 0.10466159792285354,\n",
    " 'Luminal ER+ t.': 0.08462275509291638,\n",
    " 'Luminal t.': 0.14170222195449983,\n",
    " 'Myoepithelial': 0.25642808782182286,\n",
    " 'Prolif. t.': 0.002611785203024054,\n",
    " 'CD20 B cell': 0.9778486748164886,\n",
    " 'CD3 T cell': 1.0,\n",
    " 'CD4 T cell': 0.8384692250552122,\n",
    " 'CD44+ str.': 0.10466159792285354,\n",
    " 'CD8 T cell': 0.6613280244248129,\n",
    " 'ColI+ FB': 0.9778486748164886,\n",
    " 'FB': 0.10466159792285354,\n",
    " 'Macrophage': 0.7495186954483121,\n",
    " 'Quies. str.': 0.25642808782182286,\n",
    " 'Vim+ FB': 0.03200698706086951,\n",
    " 'endothelial': 0.18338909950617152}}\n",
    "s_group = 'Neoadjuvant'\n",
    "d_correct = dd_correct[s_group]\n",
    "ls_pval = []\n",
    "for s_marker in ls_cell:\n",
    "    print(s_marker)\n",
    "    fig, ax = plt.subplots(figsize=(3,3),dpi=200)\n",
    "    sns.boxplot(data=df[df.loc[:,s_group].notna()],x=s_group,y=s_marker,showfliers=False,ax=ax,order=ls_order,hue=s_group,palette='muted',legend=False) #sorted(set(df.leiden))\n",
    "    sns.stripplot(data=df[df.loc[:,s_group].notna()],x=s_group,y=s_marker,palette='dark',ax=ax,order=ls_order,hue=s_group,legend=False)\n",
    "    statistic, pvalue = util.group_median_diff(df[df.loc[:,s_group].notna()],s_group=s_group,s_marker=s_marker)\n",
    "    ax.set_ylim(ax.get_ylim()[0],ax.get_ylim()[1]*1.4)\n",
    "    ls_pval.append(pvalue)\n",
    "    if pvalue > 0.05:\n",
    "        plt.close()\n",
    "    else:\n",
    "        ax.set_title(f'{s_group} versus {s_marker}\\np={pvalue:.3f} n={len(df[df.loc[:,s_group].notna()])} FDR={d_correct[s_marker]:.3f}')\n",
    "        plt.tight_layout\n",
    "        fig.savefig(f'{codedir}/{s_date}/boxplot__{s_group}_{s_marker}.pdf', bbox_inches='tight')\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##calculate d_correct\n",
    "# print(s_subtype)\n",
    "# reject, corrected, __, __ = statsmodels.stats.multitest.multipletests(ls_pval,method='fdr_bh')\n",
    "# dict(zip(ls_cell,corrected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#neoad by subtype\n",
    "dd_correct = {'TNBC':{'Basal t.': 0.6691775611578519,\n",
    " 'CK lo. t.': 0.12062733973476908,\n",
    " 'Luminal ER+ t.': 0.9088934594126076,\n",
    " 'Luminal t.': 0.12062733973476908,\n",
    " 'Myoepithelial': 0.5090631298871607,\n",
    " 'Prolif. t.': 0.12062733973476908,\n",
    " 'CD20 B cell': 0.9992545841344672,\n",
    " 'CD3 T cell': 1.0,\n",
    " 'CD4 T cell': 0.9992545841344672,\n",
    " 'CD44+ str.': 0.5090631298871607,\n",
    " 'CD8 T cell': 0.9088934594126076,\n",
    " 'ColI+ FB': 0.9992545841344672,\n",
    " 'FB': 0.48899807679737756,\n",
    " 'Macrophage': 0.6691775611578519,\n",
    " 'Quies. str.': 0.5090631298871607,\n",
    " 'Vim+ FB': 0.12062733973476908,\n",
    " 'endothelial': 0.5536269528008347}, 'ER+':{'Basal t.': 0.856321042567461,\n",
    " 'CK lo. t.': 0.958974358974359,\n",
    " 'Luminal ER+ t.': 0.8705737116465233,\n",
    " 'Luminal t.': 0.856321042567461,\n",
    " 'Myoepithelial': 0.9444444444444443,\n",
    " 'Prolif. t.': 0.9868544760131012,\n",
    " 'CD20 B cell': 0.856321042567461,\n",
    " 'CD3 T cell': 1.0,\n",
    " 'CD4 T cell': 0.856321042567461,\n",
    " 'CD44+ str.': 0.856321042567461,\n",
    " 'CD8 T cell': 1.0,\n",
    " 'ColI+ FB': 0.856321042567461,\n",
    " 'FB': 0.856321042567461,\n",
    " 'Macrophage': 1.0,\n",
    " 'Quies. str.': 0.856321042567461,\n",
    " 'Vim+ FB': 0.856321042567461,\n",
    " 'endothelial': 0.856321042567461},}\n",
    "for s_subtype in ['ER+','TNBC', ]:\n",
    "    ls_pval = []\n",
    "    d_correct = dd_correct[s_subtype]\n",
    "    for s_marker in ls_cell:\n",
    "        #print(s_marker)\n",
    "        fig, ax = plt.subplots(figsize=(3,3),dpi=300)\n",
    "        df_plot = df[(df.loc[:,s_group].notna()) & (df.subtype==s_subtype)]\n",
    "        sns.boxplot(data=df_plot,x=s_group,y=s_marker,showfliers=False,ax=ax,order=ls_order,hue=s_group,palette='muted',legend=False) #sorted(set(df.leiden))\n",
    "        sns.stripplot(data=df_plot,x=s_group,y=s_marker,palette='dark',ax=ax,order=ls_order,hue=s_group,legend=False)\n",
    "        statistic, pvalue = util.group_median_diff(df_plot,s_group=s_group,s_marker=s_marker)\n",
    "        ax.set_ylim(ax.get_ylim()[0],ax.get_ylim()[1]*1.4)\n",
    "        ls_pval.append(pvalue)\n",
    "        if pvalue > 0.05:\n",
    "            plt.close()\n",
    "        # elif d_correct[s_marker] > 0.05:\n",
    "        #     plt.close()\n",
    "        else:\n",
    "            ax.set_title(f'{s_group} vs. {s_marker}\\n{s_subtype} n={len(df_plot)}\\np={pvalue:.3f} FDR={d_correct[s_marker]:.3f}')\n",
    "            plt.tight_layout()\n",
    "            fig.savefig(f'{codedir}/{s_date}/scatterplots__{s_subtype}_{s_marker}_{s_group}.pdf', bbox_inches='tight')\n",
    "    #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ER+ subtype vs endothelial figure <a name=\"slide15\"></a>\n",
    "\n",
    "\n",
    "\n",
    "[contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "s_index = 'results_20220420_JP-TMAs_IMC-TMAs_MIBI_GatedCellTypes_byPatient_byleidencelltype5_all.csv'\n",
    "s_index = 'results_20220420_JP-TMAs_IMC-TMAs_MIBI_LeidenClustering_byPatient_byleidencelltype2_instromal_all.csv'\n",
    "#s_index = 'results_20220420_JP-TMAs_IMC-TMAs_MIBI_LeidenClustering_byPatient_bycelltype1_inall_all.csv'\n",
    "#df_e = pd.read_csv(f'20220412/results_subtyping_epithelial_LeidenClustering_Both_h_8.csv',index_col=0)\n",
    "df_e = pd.read_csv(f'Results/results_subtyping_epithelial_LeidenClustering_Both_6_0.2.csv',index_col=0)\n",
    "df_s = pd.read_csv(f'{codedir}/Results/{s_index}',index_col=0)\n",
    "s_denom = s_index.split('by')[-1].split('_')[1].replace('in','').split('.')[0]\n",
    "df_s['entropy'] = entropy(df_s.fillna(0),axis=1,base=2)\n",
    "df = df_e.merge(df_s,left_index=True,right_index=True,suffixes=('_e','_s'))\n",
    "df = df.merge(df_surv,left_index=True,right_index=True,suffixes=('_x',''))\n",
    "#df['Subtype'] = df.subtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "for s_subtype in ['ER+','TNBC']: #,'HER2+'\n",
    "    fig, ax = plt.subplots(figsize=(5,3),dpi=300)\n",
    "    s_marker = 'endothelial'#'FN+ FB'#'Vim+ FB'#'CD3 T cell'#'fibroblast'#'immune'#'stromal'#'epithelial'#\n",
    "    # perform multiple pairwise comparison (Tukey HSD)\n",
    "    m_comp = pairwise_tukeyhsd(endog=df.loc[df.Subtype==s_subtype,s_marker].fillna(0), groups=df.loc[df.Subtype==s_subtype,'leiden'], alpha=0.1)\n",
    "    df_test, ls_order = util.df_from_mcomp(m_comp)\n",
    "    sns.boxplot(data=df[df.Subtype==s_subtype],x='leiden',y=s_marker,showfliers=False,ax=ax,order=ls_order,hue='leiden',palette='muted',legend=False) #sorted(set(df.leiden))\n",
    "    sns.stripplot(data=df[df.Subtype==s_subtype],x='leiden',y=s_marker,palette='dark',ax=ax,order=ls_order,hue='leiden',legend=False,s=2)\n",
    "    statistic, pvalue = util.group_median_diff(df[df.Subtype==s_subtype],s_group='leiden',s_marker=s_marker)\n",
    "    ax.set_ylim(ax.get_ylim()[0],ax.get_ylim()[1]*1.4)\n",
    "    util.plt_sig(df_test,ax,10)\n",
    "    ax.set_title(f'Epithelial subtype versus {s_marker}\\n {s_subtype} p={pvalue:.4f} n={len(df[df.Subtype==s_subtype])}')\n",
    "    ax.set_ylabel(f'Fraction {s_marker} in {s_denom}')\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(f'{codedir}/{s_date}/plots__{s_subtype}_{s_marker}_{s_denom}.pdf', bbox_inches='tight')\n",
    "    #model = ols('immune ~  C(leiden)', data=df)\n",
    "    #fitted_model = model.fit()\n",
    "    #fitted_model.summary()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "fig, ax = plt.subplots(figsize=(5,3),dpi=300)\n",
    "s_marker = 'entropy'\n",
    "m_comp = pairwise_tukeyhsd(endog=df[s_marker].fillna(0), groups=df['leiden'], alpha=0.05)\n",
    "df_test, ls_order = util.df_from_mcomp(m_comp)\n",
    "sns.boxplot(data=df,x='leiden',y=s_marker,showfliers=False,ax=ax,order=ls_order,hue='leiden',palette='muted',legend=False)\n",
    "sns.stripplot(data=df,x='leiden',y=s_marker,palette='dark',ax=ax,order = ls_order,hue='leiden',legend=False)\n",
    "statistic, pvalue = util.group_median_diff(df,s_group='leiden',s_marker=s_marker)\n",
    "ax.set_ylim(ax.get_ylim()[0],ax.get_ylim()[1]*1.4)\n",
    "util.plt_sig(df_test,ax,9)\n",
    "ax.set_title(f'Epithelial {s_marker} versus Subtype\\np={pvalue:.3f} n={len(df)}')\n",
    "plt.tight_layout()\n",
    "fig.savefig(f'{codedir}/{s_date}/boxplot_Epithelial {s_marker} versus leiden.pdf', bbox_inches='tight')\n",
    "#print(m_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TNBC, ER+ high low prolif vs cell types <a name=\"byimmune\"></a>\n",
    "\n",
    "\n",
    "categorical regression\n",
    "\n",
    "\n",
    "[contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_prolif = pd.read_csv(f'data/ProlifTum_Tcell_high_low.csv',index_col=0)\n",
    "df_all_prolif['Subtype_prolif'] = df_all_prolif.subtype + '_' + df_all_prolif.loc[:,'Prolif. t. abundance']\n",
    "df_all_prolif.index = df_all_prolif.index.astype('str')\n",
    "df.index = df.index.astype('str')\n",
    "#\n",
    "df = df.merge(df_all_prolif.loc[:,['Prolif. t. abundance', 'CD3 T cell abundance', 'ProlifTum_Tcell',\n",
    "       'Subtype_prolif']],left_index=True,right_index=True)\n",
    "# making CD3\n",
    "df.loc[df.Platform!='IMC','CD3 T cell'] = df.loc[df.Platform!='IMC',['CD4 T cell','CD8 T cell']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Tcell_to_Macrophage'] = np.log((df.loc[:,'CD3 T cell']/df.loc[:,'Macrophage']).fillna(0) + 1)\n",
    "df['Tcell_to_endothelial'] = np.log((df.loc[:,'CD3 T cell']/df.loc[:,'endothelial']).fillna(0) + 1)\n",
    "df['ProlifTum_to_Tcell'] = np.log((df.loc[:, 'Prolif. t.']/df.loc[:,'CD3 T cell']).fillna(0) + 1)\n",
    "\n",
    "ls_marker = [#'Basal t.', 'CK lo. t.',  'Luminal ER+ t.', 'Luminal t.',##'HER2+ ER+ t.',\n",
    "        #'Prolif. t.', #'Myoepithelial','CD20 B cell', ##'CD209+ imm.',\n",
    "       #'CD3 T cell','Macrophage',\n",
    "     'Tcell_to_Macrophage',##'CD4 T cell', 'CD44+ str.', 'CD8 T cell', 'ColI+ FB',\n",
    "       'Tcell_to_endothelial', ##'Dendritic cell', 'FB', 'FN+ FB', 'FoxP3 Treg',  'NK cell',\n",
    "       'ProlifTum_to_Tcell',##'Neutrophil', 'Pericyte SMA+FB', \n",
    "        'Quies. str.', 'Vim+ FB','endothelial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotting\n",
    "s_group = 'Subtype_prolif'\n",
    "alpha = 0.05\n",
    "for s_marker in ls_marker:\n",
    "    print(s_marker)\n",
    "    #s_marker = 'endothelial'#'FN+ FB'#'Vim+ FB'#'CD3 T cell'#'fibroblast'#'immune'#'stromal'#'epithelial'#\n",
    "    statistic, pvalue = plotting.group_median_diff(df,s_group=s_group,s_marker=s_marker)\n",
    "    if pvalue < alpha:\n",
    "        fig, ax = plt.subplots(figsize=(4,3),dpi=200)\n",
    "        # perform multiple pairwise comparison (Tukey HSD)\n",
    "        m_comp = pairwise_tukeyhsd(endog=df.loc[df.loc[:,s_marker]!=np.inf,s_marker].fillna(0), groups=df.loc[df.loc[:,s_marker]!=np.inf,s_group], alpha=0.1)\n",
    "        df_test, ls_order = plotting.df_from_mcomp(m_comp)\n",
    "        sns.boxplot(data=df,x=s_group,y=s_marker,showfliers=False,ax=ax,order=ls_order,hue=s_group,legend=False) \n",
    "        sns.stripplot(data=df,x=s_group,y=s_marker,palette='dark',ax=ax,order=ls_order,s=2,hue=s_group,legend=False)\n",
    "\n",
    "        ax.set_ylim(ax.get_ylim()[0],ax.get_ylim()[1]*1.4)\n",
    "        plotting.plt_sig2(df_test,ax)\n",
    "        ax.set_title(f'{s_group} versus {s_marker}\\n p={pvalue:.4f} n={len(df)}')\n",
    "        ax.set_ylabel(f'Fraction {s_marker}') # in {s_denom}\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(f'{codedir}/{s_date}/boxplot_Fraction_{s_group}_{s_marker}.pdf', bbox_inches='tight')\n",
    "        #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixing score vs survival <a name=\"n1\"></a>\n",
    "\n",
    "\n",
    "number of immune-tumor interactions divided by the number of immune inter-actions\n",
    "\n",
    "[contents](#contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load combined\n",
    "#'''\n",
    "s_sample = '20220420_JP-TMAs_IMC-TMAs_MIBI' #'20220409_JP-TMAs_IMC-TMAs'\n",
    "s_type = 'all'\n",
    "df_lei_both = pd.read_csv(f'{codedir}/data/{s_sample}_CombinedCelltypes_{s_type}.csv',index_col=0)\n",
    "df_lei_both['celltype1'] = 'all'\n",
    "df_lei_both['countme'] = True\n",
    "df_lei_both['leidencelltype2_tofill'] = df_lei_both.leidencelltype3.replace({'tumor':'epithelial','endothelial':'stromal',\n",
    "                                                            'immune':'stromal','imm.':'stromal','str.':'stromal'})\n",
    "df_lei_both['leidencelltype2'] = df_lei_both.leidencelltype2.fillna(df_lei_both.leidencelltype2_tofill)\n",
    "\n",
    "df_lei_both.Patient = df_lei_both.Patient.astype('str')\n",
    "df_lei_both.leiden = df_lei_both.leiden.astype('str')#'''\n",
    "\n",
    "\n",
    "#load annotation\n",
    "df_surv = pd.read_csv(f'{codedir}/data/TMA_Survival_Subtype.csv',index_col=0)\n",
    "df_surv.index = df_surv.index.astype('str')\n",
    "df_clin = pd.read_csv(f'{codedir}/data/TMA_Clinical_Variables.csv',index_col=0)\n",
    "df_surv.loc[df_surv.index.str.contains('JP-TMA2'),'Platform'] = 'cycIF2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load neighborhoods\n",
    "s_celltype = 'leidencelltype5'#'gatedcelltype5' #\n",
    "nbr_r = 25 #15\n",
    "#s_plat = 'cycIF'\n",
    "s_sample = '20220420_JP-TMAs_IMC-TMAs_MIBI'\n",
    "s_class = f'NeighborhoodCounts_r{nbr_r}'\n",
    "counts_df = pd.read_csv(f'{codedir}/data/{s_sample}_{s_celltype}_{s_class}.csv',index_col=0)\n",
    "ls_annot = ['leiden',s_celltype,'subtype','Patient','Platform']\n",
    "df = counts_df.merge(df_lei_both.loc[:,ls_annot],left_index=True,right_index=True)\n",
    "df_immune = df.groupby('Patient').leidencelltype5.value_counts(normalize=True).unstack()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_drop = df_immune[df_immune.immune < 0.01].index #drop 88 pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mixing score\n",
    "\n",
    "#number of immune-tumor interactions divided by the number of immune interactions\n",
    "df['immune_tumor'] = np.nan\n",
    "df.loc[df.loc[:,s_celltype]=='epithelial','immune_tumor'] = df.loc[df.loc[:,s_celltype]=='epithelial','immune']\n",
    "df['immune_tumor'] = df['immune_tumor'].fillna(0)\n",
    "\n",
    "df['immune_immune'] = np.nan\n",
    "df.loc[df.loc[:,s_celltype]=='immune','immune_immune'] = df.loc[df.loc[:,s_celltype]=='immune','immune']\n",
    "df['immune_immune'] = df['immune_immune'].fillna(0)\n",
    "df_mix = df.groupby('Patient').sum()\n",
    "df_mix['mixing_score'] = df_mix.immune_tumor/df_mix.immune_immune\n",
    "df_mix = df_mix[~df_mix.index.isin(ls_drop)]\n",
    "df_mix.loc[df_mix.mixing_score==np.inf,'mixing_score'] = np.nan\n",
    "df_mix = df_mix.dropna()\n",
    "df_mix.index = df_mix.index.astype('str')\n",
    "df_mix = df_mix.merge(df_surv,suffixes=('_x',''),left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test = df.loc[:,['Patient','immune_tumor','immune_immune']].groupby('Patient').sum().sort_values(by='immune_tumor')#[-30::]\n",
    "df_test['mix'] = df_test.immune_tumor/df_test.immune_immune\n",
    "df_test[df_test.index.str.contains('JP')].sort_values(by='immune_immune')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mixing\n",
    "importlib.reload(util)\n",
    "dd_discover = {}\n",
    "alpha = 0.5\n",
    "lls_time = [('Survival_time', 'Survival'), \n",
    "            #('Recurrence_time', 'Recurrence')\n",
    "           ]\n",
    "s_group = 'Subtype_prolif'\n",
    "df_both_all = pd.DataFrame()\n",
    "cut_p = 0.66\n",
    "\n",
    "d_discovery = {'Discovery':['MIBI'],\n",
    "               'Validation':['cycIF','IMC','cycIF2'], \n",
    "               'Clinical':['IMC','MIBI','cycIF2','cycIF']}\n",
    "s_median = 'Subtype_prolif'\n",
    "d_validate = {'TNBC':['mixing_score'],\n",
    "              'ER+':['mixing_score']}\n",
    "ls_agg = ['mixing_score']\n",
    "\n",
    "for s_discovery, ls_plat in d_discovery.items():\n",
    "    for s_time, s_censor in lls_time:\n",
    "        for s_subtype in ['ER+','TNBC']:\n",
    "            if not s_discovery=='Discovery':\n",
    "                ls_agg = d_validate[s_subtype]\n",
    "            ls_pval = []\n",
    "            d_data = {}\n",
    "            for s_center in ls_agg:\n",
    "                    d_mean = {}\n",
    "                    for s_plat in ls_plat:\n",
    "                        df_mean = df_mix[df_mix.Platform==s_plat]\n",
    "                        d_mean.update({s_plat:df_mean})\n",
    "                    df_both=pd.DataFrame()\n",
    "                    for s_plat in ls_plat:\n",
    "                        df_sub = d_mean[s_plat][d_mean[s_plat].subtype==s_subtype]\n",
    "                        #df_sub = df_sub.merge(df_surv,left_index=True,right_index=True)\n",
    "                        #df_sub['Platform'] = s_plat\n",
    "                        #df_sub.rename({'countme':'Spatial'},axis=1,inplace=True)\n",
    "                        #df_sub.Spatial = df_sub.Spatial.fillna(0)\n",
    "                        df_p = util.single_km(df_sub,'',s_subtype,s_plat,s_center,savedir = f'{s_date}',alpha=0.00001,\n",
    "                                cutp=cut_p,s_time=s_time,s_censor=s_censor,s_propo='')\n",
    "                        df_both=pd.concat([df_both,df_p])\n",
    "                    df_both['level1'] = s_center #level1 is ripleys l  cell type\n",
    "                    df_both_all = pd.concat([df_both_all,df_both])\n",
    "                    #log rank\n",
    "                    try:\n",
    "                        results = multivariate_logrank_test(event_durations=df_both.loc[:,s_time],\n",
    "                                                        groups=df_both.abundance, event_observed=df_both.loc[:,s_censor])\n",
    "                        ls_pval.append(results.summary.p[0])\n",
    "                    except:\n",
    "                        ls_pval.append(1)\n",
    "                    d_data.update({f'{s_center}':df_both})\n",
    "            #run multiple test correction\n",
    "            reject, corrected, __, __ = statsmodels.stats.multitest.multipletests(ls_pval,method='fdr_bh')# #'fdr_bh'\n",
    "            d_correct = dict(zip(d_data.keys(),corrected))\n",
    "            d_orig = dict(zip(d_data.keys(),ls_pval))\n",
    "            ls_pval_cph = []\n",
    "            ls_cph_markers = []\n",
    "            for s_center, p_correct in d_correct.items():\n",
    "                pvalue = d_orig[s_center]\n",
    "                if s_discovery == 'Discovery':\n",
    "                    p_correct_used=None\n",
    "                else:\n",
    "                    p_correct_used=None#p_correct\n",
    "                if pvalue < alpha:\n",
    "                    df_both_surv = d_data[s_center]\n",
    "                    #cool plotting function for all platforms\n",
    "                    if s_discovery == 'Discovery':\n",
    "                        s_title1 = f'{s_subtype} {s_censor} {s_discovery} {s_plat}'\n",
    "                    else:\n",
    "                        s_title1 = f'{s_subtype} {s_censor} {s_discovery}'\n",
    "                    s_title2 = f'{s_center} r={nbr_r}'\n",
    "                    fig1, fig2, pval_cph, __ = util.km_cph_all(df_both_surv,df_clin,s_title1,s_title2,s_center,alpha=alpha,s_time=s_time, s_censor=s_censor,\n",
    "                           s_groups='abundance',s_cph_model='high',ls_clin=['age','tumor_size','Stage'],p_correct=p_correct_used)\n",
    "                    if not fig1 is None:\n",
    "                        #continue\n",
    "                        fig1.savefig(f\"{codedir}/{s_date}/Survival_Plots/KM_{s_title1.replace(' ','_')}_{s_title2.replace(' ','_')}_{cut_p}.pdf\",dpi=300)\n",
    "                    if not fig2 is None:\n",
    "                        #continue\n",
    "                        fig2.savefig(f\"{codedir}/{s_date}/Survival_Plots/CPH_{s_title1.replace(' ','_')}_{s_title2.replace(' ','_')}_{cut_p}.pdf\")\n",
    "                    ls_pval_cph.append(pval_cph)\n",
    "                    ls_cph_markers.append(s_center)\n",
    "            try:\n",
    "                reject2, corrected2, __, __ = statsmodels.stats.multitest.multipletests(ls_pval_cph,alpha=0.1,method='fdr_bh')\n",
    "                print(f'{s_discovery} {s_subtype}')\n",
    "                [print(f'{ls_cph_markers[idx]} {corrected2[idx]}') for idx,item in enumerate(reject2) if item]\n",
    "            except:\n",
    "                print('')\n",
    "                df_both_all = pd.concat([df_both_all,(df_both.rename({s_center:'mean_neighbors'},axis=1))]) #save to d_spatial: d_spatial.update({'mixing_score':df_both_all})\n",
    "            dd_discover.update({f'{s_subtype}_{s_censor}':d_orig})\n",
    "            #break #subtype\n",
    "        #break #surv/recur\n",
    "    #break #discovery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start the dictionary\n",
    "d_spatial = {}\n",
    "d_spatial.update({'mixing_score':df_both_all.rename({'mixing_score':'value'},axis=1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### jump to more immune-tumor biomarkers\n",
    "\n",
    "[jump](#imm_sp)\n",
    "\n",
    "[contents](#contents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tumor phenotype vs Neighborhoods: Boxplots <a name=\"leidneigh\"></a>\n",
    "\n",
    "- Figure 5: Immune-proliferating tumor proximity predicts recurrence in TNBC\n",
    "\n",
    "-  tumor phenotype versus # of neighbors\n",
    "- immune neighbors versus expression\n",
    "- immune tertile versus expression\n",
    "\n",
    "\n",
    "[contents](#contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #20220124_spatial_pipeline.py\n",
    "\n",
    "# #load data\n",
    "# s_sample = '20220410_JP-TMAs_IMC-TMAs_MIBI'\n",
    "# s_sample = '20220413_JP-TMAs_IMC-TMAs_MIBI' # #'20220207_JP-TMAs_IMC-TMAs'\n",
    "# s_sample = '20220420_JP-TMAs_IMC-TMAs_MIBI'\n",
    "# df_gate = pd.read_csv(f'./data/{s_sample}_CombinedCelltypes_all.csv',index_col=0)\n",
    "# print(f'{s_sample} dataframe loaded')\n",
    "\n",
    "# #grid\n",
    "# '''\n",
    "# df_gate['slide'] = [item.split('_')[0] for item in df_gate.slide_scene]\n",
    "# df_gate['scene'] = [item.split('_')[1] for item in df_gate.slide_scene]\n",
    "# i_grid = 100\n",
    "# df_rois = spatial.cell_grid(df_gate,i_grid=i_grid)\n",
    "# df_rois.to_csv(f'{s_sample}_{i_grid}grid-result.csv')\n",
    "# '''\n",
    "# #neighborhood\n",
    "\n",
    "# #generate boolean data\n",
    "# s_celltype = 'leiden' #'leidencelltype5'# 'gatedcelltype5' #\n",
    "# print(f'{len(df_gate.loc[:,s_celltype].unique())} cell types')\n",
    "# df_gate['slide'] = [item.split('_cell')[0] for item in df_gate.index]\n",
    "# df_dummy = pd.get_dummies(df_gate.loc[:,s_celltype],dtype='bool')\n",
    "# df_dummy[['slide','CentroidX','CentroidY']] = df_gate.loc[:,['slide','DAPI_X','DAPI_Y']]\n",
    "\n",
    "# #generate neighbor counts\n",
    "# print('counting neighbors')\n",
    "# nbr_r=20 #/.325\n",
    "# print(nbr_r)\n",
    "# counter = NeighborsCounter(nbr_r)\n",
    "# counts_df = df_dummy.groupby('slide').apply(counter.run)\n",
    "\n",
    "# #save\n",
    "# counts_df.to_csv(f'./data/{s_sample}_{s_celltype}_NeighborhoodCounts_r{nbr_r}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_tumor = ['Basal t.', \n",
    "        'CD44+ t.', 'CD63+ t.', \n",
    "       'CK lo. t.',  'EGFR+ Basal t.', 'EGFR+ t.',\n",
    "        'HER2+ ER+ PR+ t.', 'HER2+ ER+ t.',\n",
    "       'HER2+ Ki67+ t.', 'HER2++ t.', 'IDO+ Basal t.', 'Luminal ER+ t.',\n",
    "       'Luminal t.', \n",
    "       'PD-L1+ Basal t.', 'Prolif. t.']\n",
    "ls_marker = ['Basal t.', 'CD20 B cell', 'CD209+ imm.', 'CD3 T cell',\n",
    "       'CD4 T cell', 'CD44+ str.', 'CD44+ t.', 'CD63+ t.', 'CD8 T cell',\n",
    "       'CK lo. t.', 'ColI+ FB', 'Dendritic cell', 'EGFR+ Basal t.', 'EGFR+ t.',\n",
    "       'FB', 'FN+ FB', 'FoxP3 Treg', 'HER2+ ER+ PR+ t.', 'HER2+ ER+ t.',\n",
    "       'HER2+ Ki67+ t.', 'HER2++ t.', 'IDO+ Basal t.', 'Luminal ER+ t.',\n",
    "       'Luminal t.', 'Macrophage', 'Myoepithelial', 'NK cell', 'Neutrophil',\n",
    "       'PD-L1+ Basal t.', 'Pericyte SMA+FB', 'Prolif. t.', 'Quies. str.',\n",
    "       'Vim+ FB', 'endothelial']\n",
    "ls_stroma = ['CD20 B cell',\n",
    " 'CD209+ imm.',\n",
    " 'CD3 T cell',\n",
    " 'CD4 T cell',\n",
    " 'CD44+ str.',\n",
    " 'CD8 T cell',\n",
    " 'ColI+ FB',\n",
    " 'Dendritic cell',\n",
    " 'FB',\n",
    " 'FN+ FB',\n",
    " 'FoxP3 Treg',\n",
    " 'Macrophage',\n",
    " 'Myoepithelial',\n",
    " 'NK cell',\n",
    " 'Neutrophil',\n",
    " 'Pericyte SMA+FB',\n",
    " 'Quies. str.',\n",
    " 'Vim+ FB',\n",
    " 'endothelial']\n",
    "ls_center = ['CD20 B cell',  'CD3 T cell', 'CD4 T cell', 'CD8 T cell',\n",
    "            'FN+ FB','Macrophage','Quies. str.',\n",
    "       'Vim+ FB', 'endothelial' ]\n",
    "d_tum = {'ER+':['Luminal ER+ t.','Prolif. t.','CK lo. t.','Luminal t.'],\n",
    "        'TNBC':['Basal t.','Prolif. t.','CK lo. t.','Luminal t.'],\n",
    "        #'HER2+':[ 'HER2+ ER+ t.','HER2+ Ki67+ t.', 'HER2++ t.','CK lo. t.','Luminal t.']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_sample ='20220420_JP-TMAs_IMC-TMAs_MIBI'\n",
    "nbr_r = 100 #15\n",
    "df_neigh_counts = pd.read_csv(f'{codedir}/data/{s_sample}_leiden_NeighborhoodCounts_r{nbr_r}.csv',index_col=0)\n",
    "df_lei_both = pd.read_csv(f'{codedir}/data/{s_sample}_CombinedCelltypes_all.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_neigh = df_neigh_counts.merge(df_lei_both.loc[:,['leiden','DAPI_Y', 'DAPI_X', 'slide_scene',\n",
    "       'subtype', 'core', 'Patient', 'Platform','leidencelltype2','leidencelltype5']],left_index=True,right_index=True)\n",
    "df_neigh.loc[df_neigh.Platform!='IMC','CD3 T cell'] = df_neigh.loc[df_neigh.Platform!='IMC',['CD4 T cell','CD8 T cell']].sum(axis=1)\n",
    "df_neigh['tumor'] = df_neigh.loc[:,ls_tumor].sum(axis=1)\n",
    "df_neigh['stromal'] = df_neigh.loc[:,df_neigh.columns.isin(set(ls_marker)-set(ls_tumor))].sum(axis=1)\n",
    "df_neigh['one'] = 1.0\n",
    "df_neigh['leiden2'] = 'stromal'\n",
    "df_neigh.loc[df_neigh.leiden.isin(set(ls_tumor) - set(['Prolif. t.'])),'leiden2'] = 'non-Prolif. t.'\n",
    "df_neigh['leidencelltype2'] = df_neigh.leidencelltype5.replace({'fibroblast':'stromal',  'immune':'stromal', 'endothelial':'stromal'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans cluster neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples\n",
    "# add annotation\n",
    "ls_annot = ['leiden','leidencelltype5','subtype','Patient', 'Platform']\n",
    "#make adata, select epithelial cells only\n",
    "for s_plat in df_neigh.Platform.unique():\n",
    "    df_sample = df_neigh.loc[((df_neigh.loc[:,'leidencelltype5']=='epithelial') & (df_neigh.Platform==s_plat)),:]#.sample(frac=0.5, replace=False, random_state=123)\n",
    "    for s_sub in df_sample.subtype.unique():\n",
    "        b_cols = df_sample.loc[df_sample.subtype==s_sub,ls_stroma].sum()>0\n",
    "        adata = sc.AnnData(df_sample.loc[df_sample.subtype==s_sub,ls_stroma].loc[:,b_cols]) #.iloc[:,0:36]\n",
    "        sc.tl.pca(adata, svd_solver='auto')\n",
    "        sc.pp.scale(adata, zero_center=False, max_value=20)\n",
    "        adata.obs = df_sample.loc[adata.obs.index,ls_annot]\n",
    "        adata.obs.Patient = adata.obs.Patient.astype('str')\n",
    "        # extract pca coordinates\n",
    "        X_pca = adata.obsm['X_pca'] \n",
    "        for k in [8,9,10]:\n",
    "            print(f'{s_plat} {s_sub}')\n",
    "            print(k)\n",
    "            kmeans = KMeans(n_clusters=k, random_state=0).fit(X_pca) \n",
    "            adata.obs[f'kmeans{k}'] = kmeans.labels_.astype(str)\n",
    "            break\n",
    "            #silhouette = silhouette_samples(X_pca, labels=kmeans.labels_.astype(str), metric='euclidean')\n",
    "            #adata.obs[f'kmeans{k}_sil'] = silhouette\n",
    "        clustering_list = ['kmeans8'] #'kmeans5','kmeans6','kmeans7',,'kmeans9','kmeans10'\n",
    "        for idx, clust in enumerate(clustering_list):\n",
    "            #order markers with clustermap\n",
    "            df = adata.to_df()\n",
    "            df[clust] = adata.obs[clust]\n",
    "            g = sns.clustermap(df.groupby(clust).mean())\n",
    "            plt.close(g.fig)\n",
    "            marker_list = df.groupby(clust).mean().iloc[:,g.dendrogram_col.reordered_ind].columns.tolist()\n",
    "            #matrixplot\n",
    "            sc.pl.matrixplot(adata, var_names=marker_list, groupby=clust,dendrogram=True,\n",
    "                             save=f'{s_plat}_{s_sub}_neighborhoods_r={nbr_r}_k={clust.replace(\"kmeans\",\"\")}.pdf',\n",
    "                            title=f'{s_plat} {s_sub} neighborhoods r={nbr_r} k={clust.replace(\"kmeans\",\"\")}')\n",
    "        for idx, clust in enumerate(clustering_list):\n",
    "            sc.pl.pca(adata, color=clust)\n",
    "        adata.write_h5ad(f'./data/{s_sample}_{s_plat}_{s_sub}_scanpy_leiden_neighborhoods{nbr_r}_kmeans.h5ad')\n",
    "        #break\n",
    "    #break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "########################################### survival ################\n",
    "nbr_r = 100\n",
    "s_sample = '20220420_JP-TMAs_IMC-TMAs_MIBI'\n",
    "s_clust = 'kmeans8'\n",
    "alpha = 1#0.05\n",
    "cutp = 0.5\n",
    "s_time = 'Survival_time'\n",
    "s_cdfensor = 'Survival'\n",
    "for s_platform in ['cycIF','IMC','MIBI']:\n",
    "    for s_subtype in ['TNBC','ER+']:\n",
    "        try:\n",
    "            adata = sc.read_h5ad(f'./data/{s_sample}_{s_platform}_{s_subtype}_scanpy_leiden_neighborhoods{nbr_r}_kmeans.h5ad')\n",
    "        except:\n",
    "            continue\n",
    "        df = adata.to_df().merge(adata.obs,left_index=True, right_index=True)\n",
    "        df_neigh_surv = (df.groupby([f'{clust}','Patient']).count().endothelial/df.groupby(['Patient']).count().endothelial).reset_index()\n",
    "        df_neigh_surv['subtype'] = df_neigh_surv.Patient.map(dict(zip(df.Patient,df.subtype)))\n",
    "        df_neigh_surv['Platform'] = df_neigh_surv.Patient.map(dict(zip(df.Patient,df.Platform)))\n",
    "        df_neigh_surv[s_time] = df_neigh_surv.Patient.map(dict(zip(df_surv.index.astype('str'),df_surv.loc[:,s_time])))\n",
    "        df_neigh_surv[s_censor] = df_neigh_surv.Patient.map(dict(zip(df_surv.index.astype('str'),df_surv.loc[:,s_censor])))\n",
    "        s_col = 'endothelial'\n",
    "        for s_k in df.loc[:,f'{clust}'].unique():\n",
    "            s_k = '0'\n",
    "            if s_platform == 'MIBI':\n",
    "                s_k = '6'\n",
    "            dff = df_neigh_surv[df_neigh_surv.loc[:,f'{clust}']==s_k]\n",
    "            dff=dff.dropna()\n",
    "            b_low = dff.loc[:,s_col] <= dff.loc[:,s_col].median()\n",
    "            if len(dff) == 0:\n",
    "                print('skipping')\n",
    "                continue\n",
    "            if dff.loc[:,s_col].median() == 0:\n",
    "                b_low = dff.loc[:,s_col] == 0\n",
    "            dff.loc[b_low,'abundance'] = 'low'\n",
    "            dff.loc[~b_low,'abundance'] = 'high'\n",
    "            kmf = KaplanMeierFitter()\n",
    "            results = multivariate_logrank_test(event_durations=dff.Survival_time,\n",
    "                                                groups=dff.abundance, event_observed=dff.Survival)\n",
    "            if results.p_value < alpha:\n",
    "                fig, ax = plt.subplots(figsize=(3,3),dpi=300)\n",
    "                for s_group in ['high','low']:\n",
    "                    df_abun = dff[dff.abundance==s_group]\n",
    "                    durations = df_abun.Survival_time\n",
    "                    event_observed = df_abun.Survival\n",
    "                    kmf.fit(durations, event_observed,label=s_group)\n",
    "                    kmf.plot(ax=ax,ci_show=False,show_censors=True)\n",
    "                s_title1 = f'{s_subtype} {s_platform}'\n",
    "                s_title2 = f'{clust} neighborhood {s_k}'\n",
    "                ax.set_title(f'{s_title1}\\n{s_title2}\\np={results.summary.p[0]:.2} n={len(dff)}',fontsize=10)\n",
    "                ax.legend(loc='upper right')\n",
    "                plt.tight_layout()\n",
    "                fig.savefig(f\"{codedir}/{s_date}/Survival_Plots/KM_neighborhood_kmeans{s_k}_{s_celltype}_{s_title1.replace(' ','_')}_{s_title2.replace(' ','_')}.pdf\",dpi=300)\n",
    "            break\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[(df.Platform==s_platform)& (df.subtype==s_subtype)]\n",
    "df = pd.read_csv('Results/results_TNBCcycIF_SpatialLDA_byPatient_bymean_k8.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pairwise neighbor counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#proximity of stroma differences between tumor cells\n",
    "alpha = 1\n",
    "d_markers = {#'one':['tumor','stromal'],\n",
    "            'stromal':[  'CD20 B cell',  \n",
    "             'CD4 T cell', 'CD8 T cell',\n",
    "            'CD3 T cell',\n",
    "            'FN+ FB',\n",
    "            'endothelial','Quies. str.',\n",
    "            'Vim+ FB', #'Macrophage\n",
    "            ]}\n",
    "\n",
    "i_rescale = 1\n",
    "for s_norm, ls_marker in d_markers.items():\n",
    "    for s_plat in df_neigh.Platform.unique():\n",
    "        for s_subtype, ls_tum in d_tum.items():\n",
    "            df_mean = df_neigh.loc[((df_neigh.leiden.isin(ls_tum)) & (df_neigh.Platform==s_plat)&(df_neigh.subtype==s_subtype))].copy()#.groupby(['leiden','Patient']).mean()\n",
    "            df_mean.loc[:,ls_marker] = df_mean.loc[:,ls_marker].divide(df_mean.loc[:,s_norm],axis=0)\n",
    "            df_mean = df_mean.groupby(['leiden','Patient']).mean(numeric_only=True)\n",
    "\n",
    "            for s_marker in ls_marker:\n",
    "                try:\n",
    "                    df_plot = df_mean.loc[:,s_marker]\n",
    "                except:\n",
    "                    continue\n",
    "                # perform multiple pairwise comparison (Tukey HSD)\n",
    "                df = df_plot.unstack().T.melt().rename({'leiden':'Center_Cell','value':s_marker},axis=1)\n",
    "                df = df.dropna()\n",
    "                #shoud i exclude zero? i want to drop no tum, not no marker\n",
    "                df = df.loc[(df.loc[:,s_marker] < 30) & (df.loc[:,s_marker] > 0)]\n",
    "                try:\n",
    "                    statistic, pvalue = util.group_median_diff(df,s_group='Center_Cell',s_marker=s_marker)\n",
    "                    if pvalue is None:\n",
    "                        pvalue = 1\n",
    "                except:\n",
    "                    continue\n",
    "                if pvalue < alpha:\n",
    "                    fig, ax = plt.subplots(figsize=(3,2.2),dpi=200)\n",
    "                    m_comp = util.pairwise_tukeyhsd(endog=df.loc[:,s_marker], groups=df.loc[:,'Center_Cell'], alpha=0.05)\n",
    "                    df_test, ls_order = util.df_from_mcomp(m_comp)\n",
    "                    sns.boxplot(data=df,y='Center_Cell',x=s_marker,showfliers=False,ax=ax,order=ls_order,orient='h',hue='Center_Cell',legend=False) #\n",
    "                    sns.stripplot(data=df,y='Center_Cell',x=s_marker,palette='dark',ax=ax,order=ls_order,orient='h',s=2,hue='Center_Cell',legend=False)\n",
    "                    ax.set_ylim(ax.get_ylim()[0],ax.get_ylim()[1]*i_rescale)\n",
    "                    #plt_sig(df_test,ax,2)\n",
    "                    ax.set_title(f'{s_marker} Neighbors \\n {s_subtype} {s_plat} p={pvalue:.5f} n={df.groupby(\"Center_Cell\").count().max().iloc[0]}')\n",
    "                    ax.set_xlabel(f'No. {s_marker} neigh (r={str(nbr_r)})')\n",
    "                    if s_norm =='stromal':\n",
    "                        ax.set_xlabel(f'Frac. {s_marker} neigh (r={str(nbr_r)})')\n",
    "                    ax.set_ylabel(f'')\n",
    "                    plt.tight_layout()\n",
    "                    fig.savefig(f'{codedir}/{s_date}/neighbors_boxplot_Tumor_vs_{s_marker}_{s_subtype}_{s_plat}_{nbr_r}.pdf')\n",
    "                    if pvalue > 0.05:\n",
    "                        plt.close(fig)\n",
    "                    #fig, ax = plt.subplots()\n",
    "                    #fig = m_comp.plot_simultaneous(ax=ax,xlabel=f'{s_marker} {s_subtype} {s_plat} {nbr_r}')\n",
    "                    #break\n",
    "            #break\n",
    "        #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survival versus neighbors  <a name=\"leidneighsurv\"></a>\n",
    "\n",
    "for example, proliferating tumor to T cell\n",
    "\n",
    "[contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_tum = {#'ER+':['Prolif. t.','Luminal ER+ t.','CK lo. t.','Luminal t.'],\n",
    "        'TNBC':['Prolif. t.','Basal t.','CK lo. t.','Luminal t.'],\n",
    "        #'HER2+':[ 'HER2+ ER+ t.','HER2+ Ki67+ t.', 'HER2++ t.','CK lo. t.','Luminal t.']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#platform separate'''\n",
    "df_surv.index = df_surv.index.astype('str')\n",
    "savedir = f'{codedir}/{s_date}'\n",
    "#some error in the IMC patients\n",
    "\n",
    "ls_center = [#'CD20 B cell',\n",
    "             'CD3 T cell', \n",
    "             #'CD4 T cell', 'CD8 T cell',\n",
    "            #'Macrophage',#'Quies. str.','FN+ FB','Vim+ FB',\n",
    "            #'endothelial'\n",
    "            ]\n",
    "s_norm='stromal'\n",
    "\n",
    "s_time='Survival_time'\n",
    "s_censor='Survival'\n",
    "s_grouper = 'leiden'\n",
    "s_grouper = 'leiden2'\n",
    "#s_grouper = 'leidencelltype5'\n",
    "\n",
    "lls_time = [('Survival_time','Survival'),('Recurrence_time','Recurrence')]\n",
    "for s_time,s_censor in lls_time:\n",
    "    for s_subtype, ls_tum in d_tum.items():\n",
    "        if s_grouper=='leiden2':\n",
    "            ls_tum = ['non-Prolif. t.']\n",
    "        elif s_grouper=='leidencelltype2':\n",
    "            ls_tum = ['epithelial','stromal']\n",
    "        else:\n",
    "            ls_tum = ['Prolif. t.']\n",
    "        for s_plat in ['IMC','cycIF','MIBI']:\n",
    "            df_mean = df_neigh.loc[((df_neigh.Platform==s_plat)&(df_neigh.subtype==s_subtype))].copy()\n",
    "            df_mean.loc[:,ls_center] = df_mean.loc[:,ls_center].divide(df_mean.loc[:,s_norm],axis=0)\n",
    "            df_mean = df_mean.groupby([s_grouper,'Patient']).mean(numeric_only=True)\n",
    "            for s_marker in ls_center:\n",
    "                for s_tum in ls_tum:\n",
    "                    try:\n",
    "                        df_plot = df_mean.loc[s_tum].loc[:,s_marker]\n",
    "                    except:\n",
    "                        continue\n",
    "\n",
    "                    df_nn = df_mean.loc[s_tum].loc[:,s_marker]\n",
    "                    df_nn.index = df_nn.index.astype('str')\n",
    "                    df_nn = pd.DataFrame(df_nn).merge(df_surv,left_index=True,right_index=True)\n",
    "                    df_p = util.single_km(df_nn,s_tum,s_subtype,s_plat,s_marker,savedir=savedir,\n",
    "                                     alpha=0.2,cutp=0.5,s_time=s_time,s_censor=s_censor,s_propo='neighbors of')\n",
    "                    #break\n",
    "                #break\n",
    "            #break\n",
    "        #break#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #CPH multi/ both plat\n",
    "# #not used ...\n",
    "# #normalized to number of stromal neighbors\n",
    "# d_tum = {'ER+':['Luminal ER+ t.','Prolif. t.','CK lo. t.','Luminal t.'],\n",
    "#         'TNBC':['Basal t.','Prolif. t.','CK lo. t.','Luminal t.'],\n",
    "#         #'HER2+':[ 'HER2+ ER+ t.','HER2+ Ki67+ t.', 'HER2++ t.','CK lo. t.','Luminal t.']\n",
    "#         }\n",
    "# alpha = .1\n",
    "# ls_center = [#'CD20 B cell',\n",
    "#              'CD3 T cell', #'CD4 T cell', 'CD8 T cell',\n",
    "#             #'Macrophage',#'Quies. str.','FN+ FB','Vim+ FB',\n",
    "#             #'endothelial'\n",
    "#             ]\n",
    "# s_norm='one'#'stromal'\n",
    "# #s_time='Survival_time' #'Recurrence_time'#\n",
    "# #s_censor='Survival' #'Recurrence'#\n",
    "# cutp=0.5\n",
    "\n",
    "# lls_time = [('Survival_time','Survival'),('Recurrence_time','Recurrence')]\n",
    "# for s_time,s_censor in lls_time:\n",
    "#     for s_grouper in ['leidencelltype5','leiden2','leiden']:\n",
    "#         for s_subtype, ls_tum in d_tum.items():\n",
    "#             ls_tum = ['Prolif. t.']\n",
    "#             if s_grouper == 'leiden2':\n",
    "#                 ls_tum = ['non-Prolif. t.']\n",
    "#             elif s_grouper == 'leidencelltype2':\n",
    "#                 ls_tum = ['epithelial','stromal']\n",
    "#             elif s_grouper == 'leidencelltype5':\n",
    "#                 ls_tum = ['epithelial','stromal','immune','fibroblast','endothelial']\n",
    "#             for s_marker in ls_center:\n",
    "#                 for s_tum in ls_tum:\n",
    "#                     df_both = pd.DataFrame()\n",
    "#                     ls_plat = ['cycIF','IMC','MIBI']\n",
    "#                     if s_subtype == 'ER+':\n",
    "#                         ls_plat = ['cycIF','IMC']\n",
    "#                     for s_plat in ls_plat: #\n",
    "#                         df_mean = df_neigh.loc[((df_neigh.loc[:,s_grouper].isin(ls_tum)) & (df_neigh.Platform==s_plat)&(df_neigh.subtype==s_subtype))].copy()\n",
    "#                         df_mean.loc[:,ls_center] = df_mean.loc[:,ls_center].divide(df_mean.loc[:,s_norm],axis=0)\n",
    "#                         df_mean = df_mean.groupby([s_grouper,'Patient']).mean(numeric_only=True)\n",
    "#                         #\n",
    "#                         df_nn = df_mean.loc[s_tum].loc[:,s_marker]\n",
    "#                         df_nn.index = df_nn.index.astype('str')\n",
    "#                         df_nn = pd.DataFrame(df_nn).merge(df_surv,left_index=True,right_index=True)\n",
    "#                         df_p = util.single_km(df_nn,s_tum,s_subtype,s_plat,s_marker,savedir,alpha=0.001,\n",
    "#                                          cutp=0.5,s_time=s_time,s_censor=s_censor,s_propo='neighbors of')\n",
    "#                         df_both = pd.concat([df_both,df_p])\n",
    "#                     s_plat = 'All'\n",
    "#                     #KM\n",
    "#                     #log rank\n",
    "#                     if len(df_both) > 0:\n",
    "#                         results = multivariate_logrank_test(event_durations=df_both.loc[:,s_time],\n",
    "#                                                         groups=df_both.abundance, event_observed=df_both.loc[:,s_censor])\n",
    "#                     #kaplan meier plotting\n",
    "#                     if results.summary.p[0] < alpha:\n",
    "#                         kmf = KaplanMeierFitter()\n",
    "#                         fig, ax = plt.subplots(figsize=(3,3),dpi=300)\n",
    "#                         for s_group in ['high','low']:\n",
    "#                             df_abun = df_both[df_both.abundance==s_group]\n",
    "#                             durations = df_abun.loc[:,s_time]\n",
    "#                             event_observed = df_abun.loc[:,s_censor]\n",
    "#                             try:\n",
    "#                                 kmf.fit(durations, event_observed,label=s_group)\n",
    "#                                 kmf.plot(ax=ax,ci_show=False,show_censors=True)\n",
    "#                             except:\n",
    "#                                 results.summary.p[0] = 1\n",
    "#                         pvalue = results.summary.p[0]\n",
    "#                         s_title1 = f'{s_subtype} {s_censor} {s_plat}\\n{s_marker} neighbors of {s_tum}'\n",
    "#                         s_title2 = f'p={pvalue:.2} n={len(df_both)} rad={nbr_r}'\n",
    "#                         ax.set_title(f'{s_title1}\\n {s_title2}')\n",
    "#                         ax.legend(loc='upper right',frameon=False)#,title=f'{cutp}'\n",
    "#                         ax.set_xlabel(s_time)\n",
    "#                         plt.tight_layout()\n",
    "#                         fig.savefig(f\"{codedir}/{s_date}/Survival_Plots/KM_{s_title1.replace(' ','_')}_{s_title2.replace(' ','_')}_{cutp}.pdf\",dpi=300)\n",
    "\n",
    "\n",
    "#                     #CPH\n",
    "#                     cph = CoxPHFitter() #penalizer=0.1\n",
    "#                     try:\n",
    "#                         df_dummy = pd.get_dummies(df_both).loc[:,[s_time,s_censor,'abundance_high']]\n",
    "#                     except:\n",
    "#                         continue\n",
    "#                     df_dummy = df_dummy.rename({'abundance_high':s_marker},axis=1)\n",
    "#                     df_dummy.index = df_dummy.index.astype('str')\n",
    "#                     df_marker = df_dummy.merge(df_clin,left_index=True,right_index=True).loc[:,[s_time,s_censor,s_marker,'age','tumor_size','Stage']]\n",
    "#                     df_marker = df_marker.dropna()\n",
    "#                     with warnings.catch_warnings():\n",
    "#                         warnings.simplefilter('ignore')\n",
    "#                         try:\n",
    "#                         #multi\n",
    "#                             cph.fit(df_marker, s_time, event_col=s_censor) \n",
    "#                             pvalue = cph.summary.loc[s_marker,'p']\n",
    "#                         except:\n",
    "#                             pvalue = 1\n",
    "#                         #print(pvalue)\n",
    "#                         if pvalue < alpha:\n",
    "#                             fig, ax = plt.subplots(figsize=(3,2),dpi=200)\n",
    "#                             cph.plot(ax=ax)\n",
    "#                             ax.set_title(f'{s_subtype} {s_censor}\\n{s_tum} Neighbors\\n{s_plat} p={pvalue:.2} n={len(df_marker)}')\n",
    "#                             fig.savefig(f\"{codedir}/{s_date}/Survival_Plots/cph_{s_title1.replace(' ','_')}_{s_title2.replace(' ','_')}_{cutp}.pdf\",dpi=300)\n",
    "#                             plt.tight_layout()\n",
    "#                         #except:\n",
    "#                         #    continue\n",
    "#                         #break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Immune phenotype <a name=\"imph\"></a>\n",
    "\n",
    "Ki67, CD44, PD1, FoxP3, GRNZB\n",
    "\n",
    "versus\n",
    "\n",
    "- proliferation\n",
    "- subtype\n",
    "- proliferation and subtype\n",
    "\n",
    "\n",
    "[contents](#contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# platforms together, all and by subtype\n",
    "print(s_date)\n",
    "#df_e = pd.read_csv(f'20220412/results_subtyping_epithelial_LeidenClustering_Both_h_8.csv',index_col=0)\n",
    "df_e = pd.read_csv(f'Results/results_subtyping_epithelial_LeidenClustering_Both_6_0.2.csv',index_col=0)\n",
    "df_e.index = df_e.index.astype('str')\n",
    "\n",
    "#df_prolif = pd.read_csv(f'20220826/Prolif._t._high_low.csv',index_col=0)\n",
    "df_prolif = pd.read_csv(f'data/ProlifTum_Tcell_high_low.csv',index_col=0)\n",
    "df_prolif.index = df_prolif.index.astype('str')\n",
    "df_prolif['Subtype_prolif'] = df_prolif.subtype + '_' + df_prolif.loc[:,'Prolif. t. abundance']\n",
    "df_prolif.rename({'Prolif. t. abundance':'abundance'},axis=1,inplace=True)\n",
    "d_prolif = dict(zip(df_prolif.index,df_prolif.abundance))\n",
    "#read dataframe with more cell types\n",
    "s_index ='results_20220420_JP-TMAs_IMC-TMAs_MIBI_LeidenClustering_byPatient_bycelltype1_inall_all.csv'\n",
    "df_all_pts=pd.read_csv(f'results/{s_index}',index_col=0)\n",
    "df_all_pts.index = df_all_pts.index.astype('str')\n",
    "df = df_all_pts.merge(df_surv,left_index=True,right_index=True).merge(df_e.loc[:,['leiden']],left_index=True,right_index=True)\n",
    "df.loc[df.Platform!='IMC','CD3 T cell'] = df.loc[df.Platform!='IMC',['CD4 T cell','CD8 T cell']].sum(axis=1)\n",
    "df['prolif'] = df.index.map(d_prolif)\n",
    "df.index = df.index.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_sample = '20220418_JP-TMAs_IMC-TMAs_MIBI'\n",
    "df_norm = pd.read_csv(f'{codedir}/data/{s_sample}_MeanIntensity_83markers.csv',index_col=0,low_memory=False)\n",
    "ls_marker = df_norm.columns\n",
    "s_sample ='20220420_JP-TMAs_IMC-TMAs_MIBI'#'20220413_JP-TMAs_IMC-TMAs_MIBI'\n",
    "\n",
    "df_lei_both = pd.read_csv(f'{codedir}/data/{s_sample}_CombinedCelltypes_all.csv',index_col=0,low_memory=False)\n",
    "df_lei_both['leiden_CD3'] = df_lei_both.leiden.replace({'CD4 T cell': 'CD3 T cell','CD8 T cell': 'CD3 T cell'})\n",
    "df_lei_both['leidencelltype2'] = df_lei_both.leidencelltype5.replace({'fibroblast':'stromal', 'immune':'stromal', 'endothelial':'stromal'})\n",
    "df_lei_both['leidencelltype3'] = df_lei_both.leidencelltype5.replace({'fibroblast':'stromal', 'endothelial':'stromal'})\n",
    "\n",
    "ls_merge= ['leidencelltype3','leidencelltype2','leidencelltype5', 'DAPI_Y', 'DAPI_X', 'slide_scene',\n",
    "           'subtype', 'core', 'Patient', 'Platform','leiden','leiden_CD3']\n",
    "df_all = df_norm.merge(df_lei_both.loc[:,ls_merge],left_index=True,right_index=True)\n",
    "df_all.Patient = df_all.Patient.astype('str')\n",
    "\n",
    "#add 4 categories\n",
    "d_pt_tcell = dict(zip(df_prolif.index,df_prolif.ProlifTum_Tcell))\n",
    "df_all['ProlifTum_Tcell'] = df_all.Patient.map(d_pt_tcell)\n",
    "d_sub_prolif = dict(zip(df_prolif.index,df_prolif.Subtype_prolif))\n",
    "df_all['Subtype_prolif'] = df_all.Patient.map(d_sub_prolif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import zscore\n",
    "# #df.apply(zscore)\n",
    "# df_all.loc[:,s_col]\n",
    "# df_all.loc[((df_all.loc[:,s_col] == s_cell) & (df_all.Platform==s_plat)),ls_immune+[s_grouper]].groupby(s_grouper).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TNBC/ER and High/low proliferation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tumor versus stromal versus immune in ER+/TNBC/high/low prolif\n",
    "d_immune = {#'stromal':['CD31','Vim','ColI','SMA','FN','ColIV','PDGFRa', 'PDPN'],\n",
    "    #'epithelial':[#'ER','HIF1a','Glut1','CAIX','CD44','Twist', 'Vim', 'Slug', 'S6','EGFR','CK5','CK6','CK17','CK14',\n",
    "     #                    'HLA-Class-1','PD-L1','IDO',\n",
    "     #                    'Beta-catenin-n','bCatenin', 'cMyc','AR','CoxIV','CK8','CK19','CK7','BMP2','panCK','GATA3',\n",
    "     #                     'Ecad','PCNA','PgR','eccentricity'],\n",
    "            'CD3 T cell':['CD44','Ki67','HLA-DR', 'IDO','Lag3', 'MPO', 'PD-L1', 'PD1',\n",
    "                          #'Vim','CD11b','CD11c', 'CD16', 'CD209','CD63','CD138', 'CD45RO','CD56',\n",
    "            #               'FoxP3', 'GRNZB'\n",
    "                         ]\n",
    "            }\n",
    "\n",
    "s_col = 'leiden_CD3'#'leidencelltype3'#\n",
    "s_grouper = 'Patient'\n",
    "ls_order = ['ER+_high','ER+_low', 'TNBC_high', 'TNBC_low']#['TNBC','ER+']\n",
    "alpha = 0.2 #1# 0.2\n",
    "s_median = 'Subtype_prolif'#'ProlifTum_Tcell'#'subtype'\n",
    "\n",
    "\n",
    "\n",
    "ls_plat = ['cycIF','MIBI','IMC']\n",
    "for s_cell, ls_immune in d_immune.items():\n",
    "        for s_plat in ls_plat:\n",
    "            figsize=(4,3)\n",
    "            if s_plat == 'MIBI':\n",
    "                figsize=(2.5,3)\n",
    "            df_mean = df_all.loc[((df_all.loc[:,s_col] == s_cell) & (df_all.Platform==s_plat)),ls_immune+[s_grouper]].groupby(s_grouper).mean()\n",
    "            df_mean.index = df_mean.index.astype('str')\n",
    "            #df_mean = df_mean.apply(zscore)\n",
    "            df_mean[s_median] = df_mean.index.map(dict(zip(df_all.loc[:,s_grouper],df_all.loc[:,s_median])))\n",
    "            df_mean = df_mean[~df_mean.loc[:,s_median].isna()]\n",
    "            print(len(df_mean))\n",
    "            for s_marker in ls_immune:\n",
    "                if not df_mean.loc[:,s_marker].isna().all():\n",
    "                    statistic, pvalue = plotting.group_median_diff(df_mean,s_group=s_median,s_marker=s_marker)\n",
    "                    if pvalue < alpha:   \n",
    "                        # perform multiple pairwise comparison (Tukey HSD)\n",
    "                        m_comp = pairwise_tukeyhsd(endog=df_mean.loc[:,s_marker].fillna(0), groups=df_mean.loc[:,s_median], alpha=0.1)\n",
    "                        df_test, ls_order = plotting.df_from_mcomp(m_comp)\n",
    "                        fig, ax=plt.subplots(dpi=300,figsize=figsize)\n",
    "                        sns.boxplot(data=df_mean, x=s_median,y=s_marker,showfliers=False,ax=ax,order=ls_order,hue=s_median,legend=False)\n",
    "                        sns.stripplot(data=df_mean, x=s_median,y=s_marker,palette='dark',ax=ax,order=ls_order,s=3,hue=s_median,legend=False)\n",
    "                        ax.set_ylim(ax.get_ylim()[0],ax.get_ylim()[1]*1.4)\n",
    "                        if not s_plat == 'MIBI':\n",
    "                            plotting.plt_sig2(df_test,ax)\n",
    "                        ax.ticklabel_format(axis='y',style='sci',scilimits=(0,0),useMathText=True)\n",
    "                        ax.set_title(f'{s_marker}\\n {s_plat}\\n        p={pvalue:.2} n={len(df_mean)}')\n",
    "                        ax.set_ylabel(f'Mean int. in {s_cell}')\n",
    "                        plt.tight_layout()\n",
    "                        fig.savefig(f'{s_date}/boxplot_{s_cell}_expression_{s_median}_{s_plat}_{s_marker}.pdf')\n",
    "                        #break\n",
    "                #break\n",
    "            #break\n",
    "        #break\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #tumor versus stromal versus immune in low/high prolif (not used)\n",
    "# d_immune = {#'stromal':['CD31','Vim','ColI','SMA','FN','ColIV','PDGFRa', 'PDPN'],\n",
    "#     #'epithelial':['ER','HIF1a','Glut1','CAIX','CD44','Twist', 'Vim', 'Slug', 'S6','EGFR','CK5','CK6','CK17','CK14',\n",
    "#      #                     'HLA-Class-1','PD-L1','IDO',\n",
    "#      #                    'Beta-catenin-n','bCatenin', 'cMyc','AR','CoxIV','CK8','CK19','CK7','BMP2','panCK','GATA3',\n",
    "#      #                     'Ecad','PCNA','PgR','eccentricity'],\n",
    "#             'immune':['CD44','Ki67','Vim','CD11b','CD11c', 'CD16', 'CD209','CD63','CD138',\n",
    "#              'CD45RO','CD56',  'FoxP3', 'HLA-DR', 'IDO','Lag3', 'MPO', 'PD-L1', 'PD1','GRNZB']\n",
    "#             }\n",
    "\n",
    "# s_col = 'leidencelltype3'\n",
    "# s_grouper = 'Patient'\n",
    "\n",
    "# alpha = 0.05 #1# 0.2\n",
    "# s_median = 'Prolif. t.'\n",
    "\n",
    "\n",
    "# for s_subtype in ['ER+','TNBC']:\n",
    "#     if s_subtype=='ER+':\n",
    "#         ls_plat = ['IMC','cycIF']\n",
    "#     else:\n",
    "#         ls_plat = ['IMC','cycIF','MIBI']\n",
    "#     for s_cell, ls_immune in d_immune.items():\n",
    "#         for s_plat in ls_plat:\n",
    "#             df_mean = df_all.loc[((df_all.loc[:,s_col] == s_cell) & (df_all.subtype==s_subtype)& (df_all.Platform==s_plat)),ls_immune+[s_grouper]].groupby(s_grouper).mean()\n",
    "#             df_mean.index = df_mean.index.astype('str')\n",
    "#             df_mean.loc[df_mean.index,s_median] = pd.qcut(x=df.loc[df_mean.index,s_median], q=2, labels=['low','high'])\n",
    "#             for s_marker in ls_immune:\n",
    "#                 if not df_mean.loc[:,s_marker].isna().all():\n",
    "#                     statistic, pvalue = scipy.stats.mannwhitneyu(x=df_mean.loc[df_mean.loc[:,s_median]=='high',s_marker], y=df_mean.loc[df_mean.loc[:,s_median]=='low',s_marker])\n",
    "#                     if pvalue < alpha:   \n",
    "#                         fig, ax=plt.subplots(dpi=300,figsize=(2.4,2.5))\n",
    "#                         sns.boxplot(data=df_mean, x=s_median,y=s_marker,showfliers=False,ax=ax,order=['high','low'],hue=s_median,legend=False)\n",
    "#                         sns.stripplot(data=df_mean, x=s_median,y=s_marker,palette='dark',ax=ax,order=['high','low'],hue=s_median,legend=False)\n",
    "#                         ax.set_title(f'{s_marker}\\n {s_subtype} {s_plat}\\n        p={pvalue:.3} n={len(df_mean)}')\n",
    "#                         ax.set_ylabel(f'Mean int. in {s_cell}')\n",
    "#                         ax.ticklabel_format(axis='y',style='sci',scilimits=(0,0),useMathText=True)\n",
    "#                         plt.tight_layout()\n",
    "#                         fig.savefig(f'{s_date}/boxplot_{s_cell}_expression_{s_subtype}_{s_plat}_{s_marker}.pdf')\n",
    "#                         break\n",
    "#                 break\n",
    "#             break\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TNBC versus ER+ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #tumor versus stromal versus immune in ER+/TNBC (not used)\n",
    "# d_immune = {#'stromal':['CD31','Vim','ColI','SMA','FN','ColIV','PDGFRa', 'PDPN'],\n",
    "#     #'epithelial':['ER','HIF1a','Glut1','CAIX','CD44','Twist', 'Vim', 'Slug', 'S6','EGFR','CK5','CK6','CK17','CK14',\n",
    "#      #                     'HLA-Class-1','PD-L1','IDO',\n",
    "#      #                    'Beta-catenin-n','bCatenin', 'cMyc','AR','CoxIV','CK8','CK19','CK7','BMP2','panCK','GATA3',\n",
    "#      #                     'Ecad','PCNA','PgR','eccentricity'],\n",
    "#             'immune':['CD44','Ki67','Vim','CD11b','CD11c', 'CD16', 'CD209','CD63','CD138',\n",
    "#              'CD45RO','CD56',  'FoxP3', 'HLA-DR', 'IDO','Lag3', 'MPO', 'PD-L1', 'PD1','GRNZB']\n",
    "#             }\n",
    "\n",
    "# s_col = 'leidencelltype3'\n",
    "# s_grouper = 'Patient'\n",
    "# ls_order = ['TNBC','ER+']\n",
    "# alpha = 0.055 #1# 0.2\n",
    "# s_median = 'subtype'\n",
    "\n",
    "\n",
    "\n",
    "# ls_plat = ['IMC','cycIF']\n",
    "# for s_cell, ls_immune in d_immune.items():\n",
    "#         for s_plat in ls_plat:\n",
    "#             df_mean = df_all.loc[((df_all.loc[:,s_col] == s_cell) & (df_all.Platform==s_plat)),ls_immune+[s_grouper]].groupby(s_grouper).mean()\n",
    "#             df_mean.index = df_mean.index.astype('str')\n",
    "#             df_mean[s_median] = df_mean.index.map(dict(zip(df_all.loc[:,s_grouper],df_all.loc[:,s_median])))\n",
    "#             for s_marker in ls_immune:\n",
    "#                 if not df_mean.loc[:,s_marker].isna().all():\n",
    "#                     statistic, pvalue = scipy.stats.mannwhitneyu(x=df_mean.loc[df_mean.loc[:,s_median]==ls_order[0],s_marker],\n",
    "#                                                                  y=df_mean.loc[df_mean.loc[:,s_median]==ls_order[1],s_marker])\n",
    "#                     if pvalue < alpha:   \n",
    "#                         fig, ax=plt.subplots(dpi=300,figsize=(2.4,2.5))\n",
    "#                         sns.boxplot(data=df_mean, x=s_median,y=s_marker,showfliers=False,ax=ax,order=ls_order,hue=s_median,legend=False)\n",
    "#                         sns.stripplot(data=df_mean, x=s_median,y=s_marker,palette='dark',ax=ax,order=ls_order,hue=s_median,legend=False)\n",
    "#                         ax.set_title(f'{s_marker}\\n {s_plat}\\n        p={pvalue:.3}')\n",
    "#                         ax.set_ylabel(f'Mean int. in {s_cell}')\n",
    "#                         ax.ticklabel_format(axis='y',style='sci',scilimits=(0,0),useMathText=True)\n",
    "#                         plt.tight_layout()\n",
    "#                         fig.savefig(f'{s_date}/boxplot_{s_cell}_expression_{\".\".join(ls_order)}_{s_plat}_{s_marker}.pdf')\n",
    "#                         break\n",
    "#                 break\n",
    "#             break\n",
    "#         break\n",
    "#     #break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# immune low/high within prolif low/high\n",
    "\n",
    "not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #tumor versus stromal (not used)\n",
    "# d_immune = {#'epithelial':['ER','HIF1a','Glut1','CAIX','CD44','Twist', 'Vim', 'Slug', 'S6','EGFR','CK5','CK6','CK17','CK14',\n",
    "#             #              'HLA-Class-1','PD-L1','IDO',\n",
    "#             #             'Beta-catenin-n','bCatenin', 'cMyc','AR','CoxIV','CK8','CK19','CK7','BMP2','panCK','GATA3',\n",
    "#             #              'Ecad','PCNA','PgR','eccentricity'],\n",
    "#             #'stromal':['CD31','Vim','ColI','SMA','FN','ColIV','PDGFRa', 'PDPN'],\n",
    "#            'immune':['CD44','Ki67','Vim','CD11b','CD11c', 'CD16', 'CD209','CD63','CD138',\n",
    "#              'CD45RO','CD56',  'FoxP3', 'HLA-DR', 'IDO','Lag3', 'MPO', 'PD-L1', 'PD1','GRNZB']}\n",
    "\n",
    "# s_col = 'leidencelltype3'\n",
    "# s_grouper = 'Patient'\n",
    "\n",
    "# alpha = 0.05\n",
    "# s_median = 'Prolif. t.'\n",
    "# s_median2 = 'CD3 T cell'\n",
    "\n",
    "# for s_subtype in ['ER+','TNBC']:\n",
    "#     if s_subtype=='ER+':\n",
    "#         ls_plat = ['IMC','cycIF']\n",
    "#     else:\n",
    "#         ls_plat = ['IMC','cycIF','MIBI']\n",
    "#     for s_cell, ls_immune in d_immune.items():\n",
    "#         for s_plat in ls_plat:\n",
    "#             df_mean = df_all.loc[((df_all.loc[:,s_col] == s_cell) & (df_all.subtype==s_subtype)& (df_all.Platform==s_plat)),ls_immune+[s_grouper]].groupby(s_grouper).mean()\n",
    "#             df_mean.index = df_mean.index.astype('str')\n",
    "#             df_mean.loc[df_mean.index,s_median] = pd.qcut(x=df.loc[df_mean.index,s_median], q=2, labels=['low','high'])\n",
    "#             df_mean3 = pd.DataFrame()\n",
    "#             # prolif low high\n",
    "#             for s_level in ['high','low']:\n",
    "#                 df_mean2 = df_mean.loc[df_mean.loc[:,s_median]==s_level].copy()\n",
    "#                 df_mean2.loc[df_mean2.index,s_median2] = pd.qcut(x=df.loc[df_mean2.index,s_median2], q=2, labels=['low','high'])\n",
    "#                 df_mean3=df_mean3.append(df_mean2)\n",
    "#                 for s_marker in ls_immune:\n",
    "#                     if not df_mean2.loc[:,s_marker].isna().all():\n",
    "#                         statistic, pvalue = scipy.stats.mannwhitneyu(x=df_mean2.loc[df_mean2.loc[:,s_median2]=='high',s_marker], y=df_mean2.loc[df_mean2.loc[:,s_median2]=='low',s_marker])\n",
    "#                         if pvalue < alpha:   \n",
    "#                             fig, ax=plt.subplots(dpi=300,figsize=(2.4,2.5))\n",
    "#                             sns.boxplot(data=df_mean2, x=s_median2,y=s_marker,showfliers=False,ax=ax,order=['high','low'])\n",
    "#                             sns.stripplot(data=df_mean2, x=s_median2,y=s_marker,palette='dark',ax=ax,order=['high','low'])\n",
    "#                             ax.set_title(f'{s_marker} in {s_subtype} {s_plat}\\n{s_level} {s_median}\\n        p={pvalue:.3}')\n",
    "#                             ax.set_ylabel(f'Mean int. in {s_cell}')\n",
    "#                             ax.ticklabel_format(axis='y',style='sci',scilimits=(0,0),useMathText=True)\n",
    "#                             plt.tight_layout()\n",
    "#                             fig.savefig(f'{s_date}/boxplot_{s_cell}_expression_{s_subtype}_{s_plat}_{s_marker}_{s_level}_{s_median}.pdf')\n",
    "#                             plt.close(fig)\n",
    "#             # t cell low high\n",
    "#             #for s_level in ['high','low']:\n",
    "#             #    s_select = 'CD3 T cell'\n",
    "#             #    df_mean4 = df_mean3[df_mean3.loc[:,s_select]==s_level]\n",
    "#             df_mean3['group'] = [df_mean3.loc[item,s_median] + '_' + df_mean3.loc[item,s_median2]  for item in df_mean3.index]\n",
    "#             for s_marker in ls_immune:\n",
    "#                     if not df_mean3.loc[:,s_marker].isna().all():\n",
    "#                         df_mean3['int'] = df_mean3.loc[:,s_marker] \n",
    "#                         mod = ols('int ~ group', data=df_mean3).fit()\n",
    "#                         aov_table = sm.stats.anova_lm(mod, typ=2)\n",
    "#                         pvalue = aov_table.loc['group','PR(>F)']\n",
    "#                         if pvalue < alpha:   \n",
    "#                             fig, ax=plt.subplots(dpi=200,figsize=(2.6,2.5))\n",
    "#                             sns.boxplot(data=df_mean3, x=s_median,y=s_marker,hue=s_median2,showfliers=False,ax=ax,order=['high','low'],hue_order=['high','low'])\n",
    "#                             #sns.stripplot(data=df_mean3, x=s_median,y=s_marker,hue=s_median2,palette='dark',ax=ax,order=['high','low'])\n",
    "#                             ax.set_title(f'{s_marker} in {s_subtype} {s_plat}\\n        p={pvalue:.3}')\n",
    "#                             ax.set_ylabel(f'Mean int. in {s_cell}')\n",
    "#                             ax.ticklabel_format(axis='y',style='sci',scilimits=(0,0),useMathText=True)\n",
    "#                             ax.legend(loc='upper right',title=s_median2)\n",
    "#                             #ax.get_legend().remove()\n",
    "#                             plt.tight_layout()\n",
    "#                             fig.savefig(f'{s_date}/boxplot_{s_cell}_expression_{s_subtype}_{s_plat}_{s_marker}_4way.pdf')\n",
    "#                             break\n",
    "#                 #break\n",
    "#             break\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CD44 in subtype 6  <a name=\"imphCD44\"></a>\n",
    "\n",
    "\n",
    "[contents](#contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#immune cell expression an dT cell expression\n",
    "ls_immune = ['CD44','Vim','EGFR','eccentricity']\n",
    "s_cell = 'epithelial'\n",
    "s_col = 'leidencelltype5'\n",
    "s_grouper = 'Patient'\n",
    "s_subtype = 'ER+'\n",
    "s_sub_num = 6\n",
    "alpha = 1.5\n",
    "\n",
    "ls_plat = ['cycIF','MIBI']\n",
    "if s_subtype=='ER+':\n",
    "    ls_plat = ['Both'] #'cycIF','IMC',\n",
    "ls_pval = []\n",
    "for s_plat in ls_plat:\n",
    "    s_median = 'leiden'#'Luminal ER+ t.'\n",
    "    if s_plat == 'Both':\n",
    "        df_mean = df_all.loc[((df_all.loc[:,s_col] == s_cell) & (df_all.subtype==s_subtype)),ls_immune+[s_grouper]].groupby(s_grouper).mean()\n",
    "    else:\n",
    "        df_mean = df_all.loc[((df_all.loc[:,s_col] == s_cell) & (df_all.subtype==s_subtype)& (df_all.Platform==s_plat)),ls_immune+[s_grouper]].groupby(s_grouper).mean()\n",
    "    df_mean.index = df_mean.index.astype('str')\n",
    "    if s_median == 'leiden':\n",
    "        df_e.loc[df_mean.index,s_median]\n",
    "        df_mean.loc[df_mean.index,s_sub_num] = df_e.loc[df_mean.index,s_median] == s_sub_num\n",
    "        df_mean.loc[df_mean.index,s_sub_num] = df_mean.loc[df_mean.index,s_sub_num].replace({True:'high',False:'low'})\n",
    "        s_median = s_sub_num\n",
    "    else:\n",
    "        df_mean.loc[df_mean.index,s_median] = pd.qcut(x=df.loc[df_mean.index,s_median], q=2, labels=['low','high'])\n",
    "    for s_marker in ls_immune:\n",
    "        if not df_mean.loc[:,s_marker].isna().all():\n",
    "            #statistic, pvalue = scipy.stats.mannwhitneyu(x=df_mean.loc[df_mean.loc[:,s_median]=='high',s_marker], y=df_mean.loc[df_mean.loc[:,s_median]=='low',s_marker])\n",
    "            statistic, pvalue = scipy.stats.ttest_ind(df_mean.loc[df_mean.loc[:,s_median]=='high',s_marker], df_mean.loc[df_mean.loc[:,s_median]=='low',s_marker])\n",
    "            ls_pval.append(pvalue)\n",
    "    reject, corrected, __, __ = statsmodels.stats.multitest.multipletests(ls_pval,method='fdr_bh')# #'fdr_bh'\n",
    "    d_correct = dict(zip(ls_immune,corrected))\n",
    "    for s_marker, pvalue in d_correct.items():\n",
    "            if pvalue < alpha:   \n",
    "                fig, ax=plt.subplots(dpi=300,figsize=(2.4,2.5))\n",
    "                sns.boxplot(data=df_mean, x=s_median,y=s_marker,showfliers=False,ax=ax,order=['high','low'],hue=s_median,legend=False)\n",
    "                sns.stripplot(data=df_mean, x=s_median,y=s_marker,palette='dark',ax=ax,order=['high','low'],s=2,hue=s_median,legend=False,alpha=0.8)\n",
    "                ax.set_title(f'{s_marker} in {s_subtype}, {s_plat} Platforms\\n p_corrected={pvalue:.1} n={len(df_mean)}',pad=15)\n",
    "                ax.set_ylabel(f'Mean int. in {s_cell}')\n",
    "                if s_marker == 'eccentricity':\n",
    "                    ax.set_ylabel(f'Mean in {s_cell}')\n",
    "                ax.ticklabel_format(axis='y',style='sci',scilimits=(0,0),useMathText=True)\n",
    "                plt.tight_layout()\n",
    "                fig.savefig(f'{s_date}/boxplot_{s_cell}_expression_{s_subtype}_{s_plat}_{s_marker}.pdf')\n",
    "                #break\n",
    "        #break\n",
    "    #break#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reject, corrected, __, __ = statsmodels.stats.multitest.multipletests(ls_pval,method='holm-sidak')# #'fdr_bh'\n",
    "d_correct = dict(zip(ls_immune,corrected))\n",
    "d_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pandas dataframe table having atleast gene IDs, log fold change, P-values or adjusted P-values columns\n",
    "#log2(mean(post)/mean(pre))\n",
    "#df = analys.get_data('volcano').data\n",
    "#df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#visuz.GeneExpression.volcano(df=df, lfc='log2FC', pv='p-value', lfc_thr=(1, 2), pv_thr=(0.05, 0.01), \n",
    "#    color=(\"#00239CFF\", \"grey\", \"#E10600FF\"), plotlegend=True, legendpos='upper right', show=True,\n",
    "#    legendanchor=(1.46,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Immune spatial distribution <a name=\"imm_sp\"></a>\n",
    "\n",
    "- compare subtype/proliferation and survival to immune spatial distribution\n",
    "- looked at neighborhood counts, spatial aggregates and ripleys K\n",
    "- how do they all correlate with each other?\n",
    "\n",
    "-  after adjusting for intensity,a typical point in the clustered pattern has more close neighbours than a typical point in the completely random pattern, which in turn has more close neighbours than a typical point in the regular pattern.\n",
    "\n",
    "-  dont' say high K function ‘indicates’ clustering, but that it is ‘consistient' with clustering\n",
    "\n",
    "- L-func = sqrt(K-func/pi)\n",
    "\n",
    "[contents](#contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load annotation\n",
    "df_surv = pd.read_csv('data/TMA_Survival_Subtype.csv',index_col=0)\n",
    "df_clin = pd.read_csv('data/TMA_Clinical_Variables.csv',index_col=0)\n",
    "df_surv.loc[df_surv.index.str.contains('JP-TMA2'),'Platform'] = 'cycIF2'\n",
    "\n",
    "#load proliferating\n",
    "df_prolif = pd.read_csv(f'data/ProlifTum_Tcell_high_low.csv',index_col=0)\n",
    "df_prolif.index = df_prolif.index.astype('str')\n",
    "df_prolif['Subtype_prolif'] = df_prolif.subtype + '_' + df_prolif.loc[:,'Prolif. t. abundance']\n",
    "\n",
    "d_sub_prolif = dict(zip(df_prolif.index,df_prolif.Subtype_prolif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_prolif[df_prolif.index.str.contains('JP-TMA2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load combined\n",
    "s_sample = '20220420_JP-TMAs_IMC-TMAs_MIBI' #'20220409_JP-TMAs_IMC-TMAs'\n",
    "s_type = 'all'\n",
    "df_lei_both = pd.read_csv(f'{codedir}/data/{s_sample}_CombinedCelltypes_{s_type}.csv',index_col=0,low_memory=False)\n",
    "df_lei_both['celltype1'] = 'all'\n",
    "df_lei_both['countme'] = True\n",
    "df_lei_both['leidencelltype2_tofill'] = df_lei_both.leidencelltype3.replace({'tumor':'epithelial','endothelial':'stromal',\n",
    "                                                            'immune':'stromal','imm.':'stromal','str.':'stromal'})\n",
    "df_lei_both['leidencelltype2'] = df_lei_both.leidencelltype2.fillna(df_lei_both.leidencelltype2_tofill)\n",
    "\n",
    "df_lei_both.Patient = df_lei_both.Patient.astype('str')\n",
    "df_lei_both.leiden = df_lei_both.leiden.astype('str')#'''\n",
    "df_surv.index = df_surv.index.astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighborhoods <a name=\"nbrhood\"></a>\n",
    "\n",
    "[contents](#contents)\n",
    "\n",
    "40 micron\n",
    "\n",
    "\n",
    " Cell neighborhood statistics were computed for each tumor as the average number of adjacent homo- or heterotypic neighbors per cell, adjusted for the number of neighbors. Homotypic neighborhood statistics were computed as the average number of cell neighbors that were of the same cell phenotype, and heterotypic neighborhood statistics were computed as the average number of cell neighbors that were of a different phenotype\n",
    " \n",
    "   Both  homo-  and  heterotypic  neighborhoods  showed  prognostic  associations  similar  to  those  for  the  corresponding  cell  proportion  predictor.  An  exception  to  this  trend  was  the  het-erotypic  neighborhood  of  myofibroblasts  of  phenotype  12  that  was  significantly  associated  with  poor  outcome; \n",
    "   \n",
    "   also macrophages Vim+ heterotypic = bad\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s_file in os.listdir('data'):\n",
    "    if s_file.find('NeighborhoodCounts') > -1:\n",
    "        print(s_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load neighborhoods\n",
    "s_celltype = 'leidencelltype5'#'leiden' #\n",
    "nbr_r = 40 #15\n",
    "#s_plat = 'cycIF'\n",
    "s_sample = '20220420_JP-TMAs_IMC-TMAs_MIBI'\n",
    "s_class = f'NeighborhoodCounts_r{nbr_r}'\n",
    "counts_df = pd.read_csv(f'{codedir}/data/{s_sample}_{s_celltype}_{s_class}.csv',index_col=0)\n",
    "ls_annot = ['leiden',s_celltype,'subtype','Patient','Platform']\n",
    "df = counts_df.merge(df_lei_both.loc[:,ls_annot],left_index=True,right_index=True)\n",
    "df_immune = df.groupby('Patient').leidencelltype5.value_counts(normalize=True).unstack()\n",
    "d_sub_prolif = dict(zip(df_prolif.index,df_prolif.Subtype_prolif))\n",
    "df['Subtype_prolif'] = df.Patient.map(d_sub_prolif)\n",
    "\n",
    "df.loc[df.index.str.contains('JP-TMA2'),'Platform'] = 'cycIF2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #plot  spatially \n",
    "# ls_plot = ['DAPI_X','DAPI_Y','slide_scene']\n",
    "# df_plot = df.merge(df_lei_both.loc[:,ls_plot],left_index=True,right_index=True)\n",
    "# k = 'leidencelltype5'\n",
    "# ls_color = ['epithelial']\n",
    "# s_neigh = 'epithelial'\n",
    "# import matplotlib as mpl\n",
    "# from matplotlib import cm\n",
    "# for s_slide in df_plot.slide_scene.unique()[45:55]:\n",
    "#     s_slide = 'JP-TMA1-1_scene034' #s_slide = 'JP-TMA1-1_scene044'#\n",
    "#     print(s_slide)\n",
    "#     fig,ax = plt.subplots(figsize=(5,3.8),dpi=200)\n",
    "#     #plot negative cells\n",
    "#     df_scene = df_plot[(df_plot.slide_scene==s_slide)]\n",
    "#     im = ax.scatter(x=df_scene.DAPI_X.astype('float'),y=df_scene.DAPI_Y.astype('float'),c=df_scene.loc[:,s_neigh],\n",
    "#                cmap='inferno',s=5,label=f'_{s_neigh} neighbors')\n",
    "#     for idxs, s_color in enumerate(ls_color):#((df_plot.loc[:,f'{k}'].unique())):\n",
    "#         ls_index = df_scene[df_scene.loc[:,f'{k}'] == s_color].index\n",
    "#         if len(df_scene[df_scene.index.isin(ls_index)])>=30:\n",
    "#             df_color = df_scene[df_scene.index.isin(ls_index)]\n",
    "#             ax.scatter(x=df_color.DAPI_X.astype('float'),y=df_color.DAPI_Y.astype('float'),\n",
    "#                             label=f'{s_color}',s=0.2,color=mpl.cm.tab10.colors[idxs])\n",
    "        \n",
    "#     ax.set_title(f\"{s_slide}\", fontsize=16)\n",
    "#     ax.axis('equal')\n",
    "#     ax.set_ylim(ax.get_ylim()[::-1])\n",
    "#     ax.get_xaxis().set_visible(False)\n",
    "#     ax.get_yaxis().set_visible(False)\n",
    "#     for spines in ['left','right','top','bottom']:\n",
    "#         ax.spines[spines].set_visible(False)\n",
    "#     plt.legend(markerscale=10,framealpha=.1,bbox_to_anchor=(.1,.1),title=f\"\") \n",
    "#     fig.colorbar(im, ax=ax,label=f\"{s_neigh} Neighbors\")\n",
    "#     plt.tight_layout()\n",
    "#     #fig.savefig(f'{datadir}/{s_date}/scatterplot_spatial_lda_{s_slide}_kmeans{k}.pdf')\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cell lineage neigbors\n",
    "alpha = 0.2\n",
    "lls_time = [('Survival_time', 'Survival'), ('Recurrence_time', 'Recurrence')]\n",
    "s_group = 'Subtype_prolif'\n",
    "df_both_all = pd.DataFrame()\n",
    "dd_discover = {}\n",
    "d_validate = {'TNBC':['immune_immune_0.33',\n",
    "                      #'immune_epithelial_0.33',\n",
    "                     ],\n",
    "              'ER+':['stromal_epithelial_0.5',\n",
    "                     #'immune_epithelial_0.66'\n",
    "                    ]}\n",
    "importlib.reload(util)\n",
    "ls_all = []        \n",
    "for s_center in ['epithelial','immune',]:\n",
    "    for s_col in ['epithelial','immune','endothelial',  'fibroblast',  'stromal']:\n",
    "        ls_all.append(f'{s_col}_{s_center}')\n",
    "d_discovery = {'Discovery':['cycIF'],\n",
    "               'Validation':['IMC','MIBI','cycIF2'], \n",
    "               'Clinical':['IMC','MIBI','cycIF2','cycIF'],\n",
    "               'Correlation Discovery':['IMC','MIBI','cycIF2','cycIF']\n",
    "              }\n",
    "for s_discovery, ls_plat in d_discovery.items():\n",
    "    for s_time, s_censor in lls_time:\n",
    "        for s_subtype in ['ER+','TNBC']:\n",
    "            if s_discovery == 'Discovery':\n",
    "                ls_cut =[0.33,0.5,0.66]\n",
    "            elif s_discovery == 'Correlation Discovery':\n",
    "                ls_cut =[0.5]\n",
    "            else:\n",
    "                ls_all = d_validate[s_subtype]\n",
    "                ls_cut = [1]\n",
    "            for cut_p in ls_cut: ##added\n",
    "                d_data = {}\n",
    "                ls_pval = []\n",
    "                for s_col_center in ls_all:\n",
    "                    s_col = s_col_center.split('_')[0]\n",
    "                    s_center = s_col_center.split('_')[1]\n",
    "                    try:\n",
    "                        cut_p = float(s_col_center.split('_')[2])\n",
    "                    except:\n",
    "                        pass\n",
    "                    df_both=pd.DataFrame()\n",
    "                    for s_plat in ls_plat:\n",
    "                        df_sub = util.make_mean(df,s_plat,s_center,s_subtype,s_col,s_center_column='leidencelltype5')\n",
    "                        df_sub = df_sub.merge(df_surv,left_index=True,right_index=True)\n",
    "                        df_p = util.single_km(df_sub,s_center,s_subtype,s_plat,s_col,savedir = f'{s_date}',alpha=0.000001,\n",
    "                                cutp=cut_p,s_time=s_time,s_censor=s_censor,s_propo='neighbors of')\n",
    "                        df_both=pd.concat([df_both,df_p])\n",
    "                    df_both['level1'] = s_center #level1 is center\n",
    "                    df_both['level2'] = s_col #level2 is target\n",
    "                    df_both['level3'] = cut_p #level3 quantile\n",
    "                    #log rank\n",
    "                    try:\n",
    "                        results = multivariate_logrank_test(event_durations=df_both.loc[:,s_time],\n",
    "                                                        groups=df_both.abundance, event_observed=df_both.loc[:,s_censor])\n",
    "                        ls_pval.append(results.summary.p[0])\n",
    "                    except:\n",
    "                        ls_pval.append(1)\n",
    "                    d_data.update({f'{s_col}_{s_center}_{cut_p}':df_both})\n",
    "                    if s_discovery == 'Correlation Discovery':\n",
    "                        df_both_all = pd.concat([df_both_all,(df_both.rename({s_col:'mean_neighbors'},axis=1))])\n",
    "                #run multiple test correction\n",
    "                d_orig,d_correct,d_result = util.run_multi_test(d_data,df_clin,ls_pval,s_discovery,s_subtype,s_censor,s_time,alpha,s_propo='neighbors of',\n",
    "                   s_center_column='leiden',savedir=f'{codedir}/{s_date}/Survival_Plots')\n",
    "                dd_discover.update({f'{s_subtype}_{s_censor}_{cut_p}':d_orig})\n",
    "                #cut_p\n",
    "            #break #subtype\n",
    "        #break #surv/recur\n",
    "    #break #discovery\n",
    "    \n",
    "# for key, d_item in dd_discover.items():\n",
    "#     for key2, item in d_item.items():\n",
    "#         if item < alpha:\n",
    "#             print(f'{key} {key2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    d_spatial\n",
    "except:\n",
    "    d_spatial = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if s_discovery == 'Correlation Discovery':\n",
    "    d_spatial.update({'leidencelltype5_neighbors':df_both_all.rename({'mean_neighbors':'value'},axis=1)})\n",
    "\n",
    "d_spatial.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## leiden celltype neighbors\n",
    "\n",
    "calculate homotypic and heterotypic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load neighborhoods, leiden celltypes\n",
    "s_celltype ='leiden' #'leidencelltype5'#\n",
    "nbr_r = 40 #\n",
    "s_sample = '20220420_JP-TMAs_IMC-TMAs_MIBI'\n",
    "s_class = f'NeighborhoodCounts_r{nbr_r}'\n",
    "counts_df = pd.read_csv(f'{codedir}/data/{s_sample}_{s_celltype}_{s_class}.csv',index_col=0)\n",
    "ls_annot = ['leidencelltype5',s_celltype,'subtype','Patient','Platform']\n",
    "df = counts_df.merge(df_lei_both.loc[:,ls_annot],left_index=True,right_index=True)\n",
    "#df_immune = df.groupby('Patient').leidencelltype5.value_counts(normalize=True).unstack()\n",
    "d_sub_prolif = dict(zip(df_prolif.index,df_prolif.Subtype_prolif))\n",
    "df['Subtype_prolif'] = df.Patient.map(d_sub_prolif)\n",
    "df['leiden_CD3'] = df.leiden.replace({'CD4 T cell': 'CD3 T cell','CD8 T cell': 'CD3 T cell'})\n",
    "df['leiden_CD3_tum'] = df['leiden_CD3']\n",
    "df.loc[((df.leiden!='Prolif. t.') & (df.leidencelltype5=='epithelial')),'leiden_CD3_tum'] = 'Non-prolif. t.'\n",
    "df.loc[((df.leidencelltype5=='epithelial')),'leiden_CD3_tum'] = 'Tumor'\n",
    "df.loc[df.index.str.contains('JP-TMA2'),'Platform'] = 'cycIF2'\n",
    "\n",
    "# add CD3 neigh\n",
    "ls_index = df[df.Platform!='IMC'].index\n",
    "df.loc[ls_index,'CD3 T cell'] = df.loc[ls_index,['CD4 T cell','CD8 T cell']].sum(axis=1)\n",
    "\n",
    "#add tumor neighbors?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add heterotypic neighbors\n",
    "es_cell = set(df.leiden_CD3.unique())\n",
    "for s_cell in df.leiden_CD3.unique():\n",
    "    es_hetero = es_cell - set([s_cell])\n",
    "    df.loc[df.leiden_CD3==s_cell,'heterotyp'] = df.loc[df.leiden_CD3==s_cell,list(es_hetero)].sum(axis=1)\n",
    "    df.loc[df.leiden_CD3==s_cell,'homotyp'] = df.loc[df.leiden_CD3==s_cell,s_cell]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tcell neighbors of T cell\n",
    "\n",
    "hig/low prolif, ER+, TNBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tumor versus stromal versus immune in ER+/TNBC/high/low prolif\n",
    "d_immune = {#'stromal':['CD31','Vim','ColI','SMA','FN','ColIV','PDGFRa', 'PDPN'],\n",
    "    #'epithelial':[#'ER','HIF1a','Glut1','CAIX','CD44','Twist', 'Vim', 'Slug', 'S6','EGFR','CK5','CK6','CK17','CK14',\n",
    "     #                    'HLA-Class-1','PD-L1','IDO',\n",
    "     #                    'Beta-catenin-n','bCatenin', 'cMyc','AR','CoxIV','CK8','CK19','CK7','BMP2','panCK','GATA3',\n",
    "     #                     'Ecad','PCNA','PgR','eccentricity'],\n",
    "            'CD3 T cell':['CD3 T cell',\n",
    "                          #'Vim','CD11b','CD11c', 'CD16', 'CD209','CD63','CD138', 'CD45RO','CD56',\n",
    "            #               'FoxP3', 'GRNZB'\n",
    "                         ]\n",
    "            }\n",
    "\n",
    "s_col = 'leiden_CD3'#'leidencelltype3'#\n",
    "s_grouper = 'Patient'\n",
    "ls_order = ['ER+_high','ER+_low', 'TNBC_high', 'TNBC_low']#['TNBC','ER+']\n",
    "alpha = 0.2 #1# 0.2\n",
    "s_median = 'Subtype_prolif'#'ProlifTum_Tcell'#'subtype'\n",
    "\n",
    "\n",
    "\n",
    "ls_plat = ['IMC','cycIF','MIBI',]\n",
    "for s_cell, ls_immune in d_immune.items():\n",
    "        for s_plat in ls_plat:\n",
    "            figsize=(4,3)\n",
    "            if s_plat == 'MIBI':\n",
    "                figsize=(2.5,3)\n",
    "            df_mean = df.loc[((df.loc[:,s_col] == s_cell) & (df.Platform==s_plat)),ls_immune+[s_grouper]].groupby(s_grouper).mean()\n",
    "            df_mean.index = df_mean.index.astype('str')\n",
    "            #df_mean = df_mean.apply(zscore)\n",
    "            df_mean[s_median] = df_mean.index.map(dict(zip(df.loc[:,s_grouper],df.loc[:,s_median])))\n",
    "            df_mean = df_mean[~df_mean.loc[:,s_median].isna()]\n",
    "            print(len(df_mean))\n",
    "            for s_marker in ls_immune:\n",
    "                if not df_mean.loc[:,s_marker].isna().all():\n",
    "                    statistic, pvalue = plotting.group_median_diff(df_mean,s_group=s_median,s_marker=s_marker)\n",
    "                    if pvalue < alpha:   \n",
    "                        # perform multiple pairwise comparison (Tukey HSD)\n",
    "                        m_comp = pairwise_tukeyhsd(endog=df_mean.loc[:,s_marker].fillna(0), groups=df_mean.loc[:,s_median], alpha=0.1)\n",
    "                        df_test, ls_order = plotting.df_from_mcomp(m_comp)\n",
    "                        fig, ax=plt.subplots(dpi=300,figsize=figsize)\n",
    "                        sns.boxplot(data=df_mean, x=s_median,y=s_marker,showfliers=False,ax=ax,order=ls_order,hue=s_median,legend=False,palette='muted')\n",
    "                        sns.stripplot(data=df_mean, x=s_median,y=s_marker,palette='dark',ax=ax,order=ls_order,s=3,hue=s_median,legend=False)\n",
    "                        ax.set_ylim(ax.get_ylim()[0],ax.get_ylim()[1]*1.4)\n",
    "                        if not s_plat == 'MIBI':\n",
    "                            plotting.plt_sig2(df_test,ax)\n",
    "                        ax.ticklabel_format(axis='y',style='sci',scilimits=(0,0),useMathText=True)\n",
    "                        ax.set_title(f'{s_marker}\\n {s_plat}\\n        p={pvalue:.2} n={len(df_mean)}')\n",
    "                        ax.set_ylabel(f'{s_cell} Neighbors')\n",
    "                        plt.tight_layout()\n",
    "                        fig.savefig(f'{s_date}/boxplot_{s_cell}_neighbore_{s_median}_{s_plat}_{s_marker}.pdf')\n",
    "                        #break\n",
    "                #break\n",
    "            #break\n",
    "        #break\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#plot  spatially \n",
    "ls_plot = ['DAPI_X','DAPI_Y','slide_scene']\n",
    "df_plot = df.merge(df_lei_both.loc[:,ls_plot],left_index=True,right_index=True)\n",
    "df_plot['tumor'] = df_plot.leiden_CD3.replace({'Non-prolif. t.':'Tumor','Prolif. t.':'Tumor'})\n",
    "k = 'tumor'#'leiden_CD3'\n",
    "ls_color = ['Tumor']#,\n",
    "s_neigh = 'CD3 T cell'\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "for s_slide in df_plot.slide_scene.unique()[45:55]:\n",
    "    s_slide = 'JP-TMA2-1_scene35'#s_slide = 'JP-TMA1-1_scene034' #\n",
    "    print(s_slide)\n",
    "    fig,ax = plt.subplots(figsize=(5,3.8),dpi=200)\n",
    "    #plot negative cells\n",
    "    df_scene = df_plot[(df_plot.slide_scene==s_slide)]\n",
    "    im = ax.scatter(x=df_scene.DAPI_X.astype('float'),y=df_scene.DAPI_Y.astype('float'),c=df_scene.loc[:,s_neigh],\n",
    "               cmap='viridis',s=4,label=f'_{s_neigh} neighbors')\n",
    "    for idxs, s_color in enumerate(ls_color):#((df_plot.loc[:,f'{k}'].unique())):\n",
    "        ls_index = df_scene[df_scene.loc[:,f'{k}'] == s_color].index\n",
    "        if len(df_scene[df_scene.index.isin(ls_index)])>=0:\n",
    "            df_color = df_scene[df_scene.index.isin(ls_index)]\n",
    "            ax.scatter(x=df_color.DAPI_X.astype('float'),y=df_color.DAPI_Y.astype('float'),\n",
    "                            label=f'{s_color}',s=1,color=mpl.cm.Dark2.colors[idxs+1],alpha=0.75)\n",
    "        \n",
    "    ax.set_title(f\"{s_slide}\", fontsize=16)\n",
    "    ax.axis('equal')\n",
    "    ax.set_ylim(ax.get_ylim()[::-1])\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    for spines in ['left','right','top','bottom']:\n",
    "        ax.spines[spines].set_visible(False)\n",
    "    plt.legend(markerscale=4,framealpha=.1,bbox_to_anchor=(.2,.2),title=f\"\",frameon=False) \n",
    "    fig.colorbar(im, ax=ax,label=f\"{s_neigh} Neighbors\",shrink=0.8)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(f'{codedir}/{s_date}/scatterplot_spatial_lda_{s_slide}_kmeans{k}.pdf')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #plot  spatially \n",
    "# ls_plot = ['DAPI_X','DAPI_Y','slide_scene']\n",
    "# df_plot = df.merge(df_lei_both.loc[:,ls_plot],left_index=True,right_index=True)\n",
    "# df_plot['tumor'] = df_plot.leiden_CD3.replace({'Non-prolif. t.':'Tumor','Prolif. t.':'Tumor'})\n",
    "# k = 'tumor'#'leiden_CD3'\n",
    "# ls_color = ['Prolif. t.','Macrophage','Non-prolif. t.']\n",
    "# ls_color = ['Prolif. t.','Macrophage','Tumor']\n",
    "# s_neigh = 'Macrophage'\n",
    "# import matplotlib as mpl\n",
    "# from matplotlib import cm\n",
    "# for s_slide in ['JP-TMA1-1_scene034','JP-TMA2-1_scene18','JP-TMA2-1_scene10','JP-TMA2-1_scene05']:\n",
    "#     print(s_slide)\n",
    "#     fig,ax = plt.subplots(figsize=(5,3.8),dpi=200)\n",
    "#     #plot negative cells\n",
    "#     df_scene = df_plot[(df_plot.slide_scene==s_slide)]\n",
    "#     im = ax.scatter(x=df_scene.DAPI_X.astype('float'),y=df_scene.DAPI_Y.astype('float'),#c=df_scene.loc[:,s_neigh],\n",
    "#                color='lightgray',#cmap='viridis',\n",
    "#                 s=2,label=f'_{s_neigh} neighbors')\n",
    "#     for idxs, s_color in enumerate(ls_color):#((df_plot.loc[:,f'{k}'].unique())):\n",
    "#         ls_index = df_scene[df_scene.loc[:,f'{k}'] == s_color].index\n",
    "#         if len(df_scene[df_scene.index.isin(ls_index)])>=0:\n",
    "#             df_color = df_scene[df_scene.index.isin(ls_index)]\n",
    "#             ax.scatter(x=df_color.DAPI_X.astype('float'),y=df_color.DAPI_Y.astype('float'),\n",
    "#                             label=f'{s_color}',s=1,color=mpl.cm.Dark2.colors[idxs])\n",
    "        \n",
    "#     ax.set_title(f\"{s_slide}\", fontsize=16)\n",
    "#     ax.axis('equal')\n",
    "#     ax.set_ylim(ax.get_ylim()[::-1])\n",
    "#     ax.get_xaxis().set_visible(False)\n",
    "#     ax.get_yaxis().set_visible(False)\n",
    "#     for spines in ['left','right','top','bottom']:\n",
    "#         ax.spines[spines].set_visible(False)\n",
    "#     plt.legend(markerscale=4,framealpha=.1,bbox_to_anchor=(.1,.1),title=f\"\") \n",
    "#     #fig.colorbar(im, ax=ax,label=f\"{s_neigh} Neighbors\")\n",
    "#     plt.tight_layout()\n",
    "#     #fig.savefig(f'{datadir}/{s_date}/scatterplot_spatial_lda_{s_slide}_kmeans{k}.pdf')\n",
    "#     #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# leiden cell type neigbors\n",
    "alpha = 0.1\n",
    "lls_time = [('Recurrence_time', 'Recurrence'),('Survival_time', 'Survival'),\n",
    "            ]\n",
    "s_group = 'Subtype_prolif'\n",
    "df_both_all = pd.DataFrame()\n",
    "dd_discover = {}\n",
    "d_validate = {'TNBC':['CD3 T cell_Tumor_0.33',\n",
    "                      'CD3 T cell_CD3 T cell_0.33',\n",
    "                      'Macrophage_Tumor_0.66',\n",
    "                      'CD20 B cell_CD3 T cell_0.33',\n",
    "                      'endothelial_CD20 B cell_0.66',\n",
    "                     ],\n",
    "              'ER+':['Macrophage_CD3 T cell_0.33',\n",
    "                     'Quies. str._Tumor_0.33'\n",
    "                    ]}\n",
    "\n",
    "ls_all = []        \n",
    "for s_center in ['Tumor','CD3 T cell', 'CD20 B cell']:\n",
    "    for s_col in [ 'Quies. str.', 'Vim+ FB','Macrophage', 'endothelial', 'CD3 T cell', 'CD20 B cell']:\n",
    "        ls_all.append(f'{s_col}_{s_center}')\n",
    "d_discovery = {'Discovery':['cycIF'],\n",
    "               'Validation':['IMC','MIBI','cycIF2'], \n",
    "               'Clinical':['IMC','MIBI','cycIF2','cycIF'],\n",
    "    'Correlation Discovery':['IMC','MIBI','cycIF2','cycIF']\n",
    "              }\n",
    "for s_discovery, ls_plat in d_discovery.items():\n",
    "    for s_time, s_censor in lls_time:\n",
    "        for s_subtype in ['ER+','TNBC']:\n",
    "            if s_discovery == 'Discovery':\n",
    "                ls_cut =[0.33,0.5,0.66]\n",
    "            elif s_discovery == 'Correlation Discovery':\n",
    "                ls_cut = [0.5]\n",
    "            else:\n",
    "                ls_all = d_validate[s_subtype]\n",
    "                ls_cut = [1]\n",
    "            for cut_p in ls_cut: ##added\n",
    "                d_data = {}\n",
    "                ls_pval = []\n",
    "                for s_col_center in ls_all:\n",
    "                    #print(s_col_center)\n",
    "                    s_col = s_col_center.split('_')[0]\n",
    "                    s_center = s_col_center.split('_')[1]\n",
    "                    try:\n",
    "                        cut_p = float(s_col_center.split('_')[2])\n",
    "                    except:\n",
    "                        pass\n",
    "                    df_both=pd.DataFrame()\n",
    "                    for s_plat in ls_plat:\n",
    "                        df_sub = util.make_mean(df,s_plat,s_center,s_subtype,s_col,s_center_column='leiden_CD3_tum')\n",
    "                        df_sub = df_sub.merge(df_surv,left_index=True,right_index=True)\n",
    "                        df_p = util.single_km(df_sub,s_center,s_subtype,s_plat,s_col,savedir = f'{s_date}',alpha=0.000001,\n",
    "                                cutp=cut_p,s_time=s_time,s_censor=s_censor,s_propo='neighbors of')\n",
    "                        df_both=pd.concat([df_both,df_p])\n",
    "                    df_both['level1'] = s_center #level1 is center\n",
    "                    df_both['level2'] = s_col #level2 is target\n",
    "                    df_both['level3'] = cut_p #level3 quantile\n",
    "                    #log rank\n",
    "                    try:\n",
    "                        results = multivariate_logrank_test(event_durations=df_both.loc[:,s_time],\n",
    "                                                        groups=df_both.abundance, event_observed=df_both.loc[:,s_censor])\n",
    "                        ls_pval.append(results.summary.p[0])\n",
    "                    except:\n",
    "                        ls_pval.append(1)\n",
    "                    d_data.update({f'{s_col}_{s_center}_{cut_p}':df_both})\n",
    "                    if s_discovery == 'Correlation Discovery':\n",
    "                        df_both_all = pd.concat([df_both_all,(df_both.rename({s_col:'mean_neighbors'},axis=1))])\n",
    "                #run multiple test correction\n",
    "                d_orig,d_correct,d_result = util.run_multi_test(d_data,df_clin,ls_pval,s_discovery,s_subtype,s_censor,s_time,alpha,s_propo='neighbors of',\n",
    "                   s_center_column='leiden',savedir=f'{codedir}/{s_date}/Survival_Plots')\n",
    "                dd_discover.update({f'{s_subtype}_{s_censor}_{cut_p}':d_orig})\n",
    "                #cut_p\n",
    "            #break #subtype\n",
    "        #break #surv/recur\n",
    "    #break #discovery\n",
    "    \n",
    "for key, d_item in dd_discover.items():\n",
    "    for key2, item in d_item.items():\n",
    "        if item < alpha:\n",
    "            print(f'{key} {key2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if s_discovery == 'Correlation Discovery':\n",
    "    d_spatial.update({'leiden_neighbors':df_both_all.rename({'mean_neighbors':'value'},axis=1)})\n",
    "d_spatial.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ER+_Survival_0.33 heterotyp_Basal t._0.33\n",
    "# ER+_Survival_0.33 homotyp_Luminal ER+ t._0.33\n",
    "# ER+_Survival_0.5 heterotyp_Basal t._0.5\n",
    "# ER+_Survival_0.5 homotyp_Basal t._0.5\n",
    "# ER+_Survival_0.5 homotyp_CD3 T cell_0.5\n",
    "# ER+_Survival_0.66 heterotyp_Basal t._0.66\n",
    "# ER+_Survival_0.66 homotyp_Basal t._0.66\n",
    "# TNBC_Survival_0.33 homotyp_CD20 B cell_0.33\n",
    "# TNBC_Survival_0.5 homotyp_Vim+ FB_0.5\n",
    "# TNBC_Survival_0.5 homotyp_CD3 T cell_0.5\n",
    "# ER+_Recurrence_0.33 homotyp_Pericyte SMA+FB_0.33\n",
    "# ER+_Recurrence_0.5 homotyp_Quies. str._0.5\n",
    "# ER+_Recurrence_0.5 heterotyp_Basal t._0.5\n",
    "# ER+_Recurrence_0.5 homotyp_CD3 T cell_0.5\n",
    "# ER+_Recurrence_0.66 heterotyp_Basal t._0.66\n",
    "# ER+_Recurrence_0.66 homotyp_Basal t._0.66\n",
    "# TNBC_Recurrence_0.33 homotyp_CD20 B cell_0.33\n",
    "# TNBC_Recurrence_0.5 homotyp_Vim+ FB_0.5\n",
    "# TNBC_Recurrence_0.5 homotyp_CD3 T cell_0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# leiden cell type neigbors\n",
    "# we did not reproduce the findings from Ali et al\n",
    "\n",
    "alpha = 1.05\n",
    "lls_time = [('Survival_time', 'Survival'), ('Recurrence_time', 'Recurrence')]\n",
    "s_group = 'Subtype_prolif'\n",
    "df_both_all = pd.DataFrame()\n",
    "dd_discover = {}\n",
    "d_validate = {'All':['homotyp_CK lo. t._0.33',\n",
    "                     'heterotyp_Vim+ FB_0.33'\n",
    "                    ]}\n",
    "\n",
    "ls_all = []        \n",
    "ls_center = ['Vim+ FB', 'Macrophage','FN+ FB','CK lo. t.',\n",
    "       #  'Prolif. t.','Luminal ER+ t.', #'Quies. str.','Luminal t.', 'Basal t.', \n",
    "       #'endothelial', 'CD3 T cell',  'CD20 B cell','Pericyte SMA+FB', \n",
    "       ]\n",
    "for s_center in ls_center:\n",
    "    for s_col in ['heterotyp']: #,'homotyp'\n",
    "        ls_all.append(f'{s_col}_{s_center}')\n",
    "        \n",
    "d_discovery = {'Discovery':['IMC'],\n",
    "               'Validation':['cycIF','MIBI','cycIF2'], \n",
    "               'Clinical':['IMC','MIBI','cycIF2','cycIF'],\n",
    "               'Correlation Discovery':['IMC','MIBI','cycIF2','cycIF']\n",
    "              }\n",
    "for s_discovery, ls_plat in d_discovery.items():\n",
    "    for s_time, s_censor in lls_time:\n",
    "        for s_subtype in ['All']: #,'ER+','TNBC'\n",
    "            df_ali = df.copy()\n",
    "            if s_subtype == 'All':\n",
    "                df_ali['subtype'] = 'All'\n",
    "            if s_discovery == 'Discovery':\n",
    "                ls_cut =[0.33,0.5,0.66]\n",
    "            elif s_discovery == 'Correlation Discovery': \n",
    "                ls_cut =[0.5]\n",
    "            else:\n",
    "                ls_all = d_validate[s_subtype]\n",
    "                ls_cut = [1]\n",
    "            for cut_p in ls_cut: ##added\n",
    "                d_data = {}\n",
    "                ls_pval = []\n",
    "                for s_col_center in ls_all:\n",
    "                    #print(s_col_center)\n",
    "                    s_col = s_col_center.split('_')[0]\n",
    "                    s_center = s_col_center.split('_')[1]\n",
    "                    try:\n",
    "                        cut_p = float(s_col_center.split('_')[2])\n",
    "                    except:\n",
    "                        pass\n",
    "                    df_both=pd.DataFrame()\n",
    "                    for s_plat in ls_plat:\n",
    "                        df_sub = util.make_mean(df_ali,s_plat,s_center,s_subtype,s_col,s_center_column='leiden_CD3')\n",
    "                        df_sub = df_sub.merge(df_surv,left_index=True,right_index=True)\n",
    "                        if s_subtype == 'All':\n",
    "                            df_sub['subtype'] = 'All'\n",
    "                        df_p = util.single_km(df_sub,s_center,s_subtype,s_plat,s_col,savedir = f'{s_date}',alpha=0.000001,\n",
    "                                cutp=cut_p,s_time=s_time,s_censor=s_censor,s_propo='neighbors of')\n",
    "                        df_both=pd.concat([df_both,df_p])\n",
    "                    df_both['level1'] = s_center #level1 is center\n",
    "                    df_both['level2'] = s_col #level2 is target\n",
    "                    df_both['level3'] = cut_p #level3 quantile\n",
    "                    #log rank\n",
    "                    try:\n",
    "                        results = multivariate_logrank_test(event_durations=df_both.loc[:,s_time],\n",
    "                                                        groups=df_both.abundance, event_observed=df_both.loc[:,s_censor])\n",
    "                        ls_pval.append(results.summary.p[0])\n",
    "                    except:\n",
    "                        ls_pval.append(1)\n",
    "                    d_data.update({f'{s_col}_{s_center}_{cut_p}':df_both})\n",
    "                    if s_discovery == 'Correlation Discovery':\n",
    "                        df_both_all = pd.concat([df_both_all,(df_both.rename({s_col:'mean_neighbors'},axis=1))])\n",
    "                #run multiple test correction\n",
    "                d_orig,d_correct,d_result = util.run_multi_test(d_data,df_clin,ls_pval,s_discovery,s_subtype,s_censor,s_time,alpha,s_propo='neighbors of',\n",
    "                   s_center_column='leiden',savedir=f'{codedir}/{s_date}/Survival_Plots')\n",
    "                dd_discover.update({f'{s_subtype}_{s_censor}_{cut_p}':d_orig})\n",
    "                #cut_p\n",
    "            #break #subtype\n",
    "        break #surv/recur\n",
    "    #break #discovery\n",
    "    \n",
    "for key, d_item in dd_discover.items():\n",
    "    for key2, item in d_item.items():\n",
    "        if item < alpha:\n",
    "            print(f'{key} {key2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if s_discovery == 'Correlation Discovery':\n",
    "    d_spatial.update({'hh_neighbors':df_both_all.rename({'mean_neighbors':'value'},axis=1)})\n",
    "\n",
    "d_spatial.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lymphocyte clusters <a name=\"agg\"></a>\n",
    "\n",
    "**from Wortman et al. npj Breast Cancer 2021:**\n",
    "\n",
    " LCs are identified as containing at least five lymphocytes (T and/or B cells) within a circle with a diameter of 40 μm\n",
    " \n",
    " The **density of isolated lymphocytes (p = 0.006)**, as well as **isolated CD20+ B (p = 0.02) and CD3+ T cells (p = 0.007), infiltrating cancer cell islands** is significantly higher in good outcome (n = 24) vs. poor outcome (n = 12) (Fig. 4a–e). (Density is defined as the ratio of the number of cells in cancer cell islands and the ROI area.)  \"Density of B and T cells within cancer cell islands is clinically significant.\"\n",
    " \n",
    " **Spatial dispersion** of isolated CD20+ B and CD3+ T cells within cancer cell islands, as measured by occupancy AUC (B cells: p = 0.004; CD3+ T cells: p = 7 × 10−5) and FD difference (B cells: p = 0.007; CD3+ T cells: p = 0.0003), is significantly larger in good outcome (Fig. 4f–i).\n",
    "\n",
    "\n",
    "CD20+ B and CD3+ T cells within cancer islands, regardless of whether or not they are isolated or clustered, exhibit significantly greater spatial dispersion in good (n = 24) vs. poor (n = 12) outcome as indicated by occupancy AUC as well as FD difference (Fig. 4j–m). Associated RFS plots in Fig. 4n, o show the clinical significance of CD20+ B cell occupancy AUC and FD difference.\n",
    "\n",
    "\n",
    "[contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We developed statistical techniques (fractal dimension differences and a box-counting method ‘occupancy’) to analyze the spatial distribution of tumor-infiltrating lymphocytes (TILs) in human triple-negative breast cancer (TNBC). Our results indicate that B cells in good outcome tumors (no recurrence within 5 years) are spatially dispersed, while B cells in poor outcome tumors (recurrence within 3 years) are more confined. While most TILs are located within the stroma, increased numbers of spatially dispersed lymphocytes within cancer cell islands are associated with a good prognosis. B cells and T cells often form lymphocyte clusters (LCs) identified via density-based clustering. LCs consist either of T cells only or heterotypic mixtures of B and T cells. Pure B cell LCs were negligible in number. Compared to tertiary lymphoid structures (TLS), LCs have fewer lymphocytes at lower densities. Both types of LCs are more abundant and more spatially dispersed in good outcomes compared to poor outcome tumors. Heterotypic LCs in good outcome tumors are smaller and more numerous compared to poor outcome. Heterotypic LCs are also closer to cancer islands in a good outcome, with LC size decreasing as they get closer to cancer cell islands. These results illuminate the significance of the spatial distribution of B cells and LCs within tumors. \n",
    "\n",
    "The density of isolated lymphocytes (p = 0.006), as well as isolated CD20+ B (p = 0.02) and CD3+ T cells (p = 0.007), infiltrating cancer cell islands is significantly higher in good outcome (n = 24) vs. poor outcome (n = 12) (Fig. 4a–e). (Density is defined as the ratio of the number of cells in cancer cell islands and the ROI area.) Spatial dispersion of isolated CD20+ B and CD3+ T cells within cancer cell islands, as measured by occupancy AUC (B cells: p = 0.004; CD3+ T cells: p = 7 × 10−5) and FD difference (B cells: p = 0.007; CD3+ T cells: p = 0.0003), is significantly larger in good outcome (Fig. 4f–i).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load neighborhoods, leiden celltypes\n",
    "s_celltype ='leiden' #'leidencelltype5'#\n",
    "nbr_r = 20 \n",
    "s_sample = '20220420_JP-TMAs_IMC-TMAs_MIBI'\n",
    "s_class = f'NeighborhoodCounts_r{nbr_r}'\n",
    "counts_df = pd.read_csv(f'{codedir}/data/{s_sample}_{s_celltype}_{s_class}.csv',index_col=0)\n",
    "ls_annot = ['leidencelltype5',s_celltype,'subtype','Patient','Platform']\n",
    "df = counts_df.merge(df_lei_both.loc[:,ls_annot],left_index=True,right_index=True)\n",
    "\n",
    "d_sub_prolif = dict(zip(df_prolif.index,df_prolif.Subtype_prolif))\n",
    "df['Subtype_prolif'] = df.Patient.map(d_sub_prolif)\n",
    "df['leiden_CD3'] = df.leiden.replace({'CD4 T cell': 'CD3 T cell','CD8 T cell': 'CD3 T cell'})\n",
    "df['leiden_CD3_tum'] = df['leiden_CD3']\n",
    "df.loc[((df.leiden!='Prolif. t.') & (df.leidencelltype5=='epithelial')),'leiden_CD3_tum'] = 'Non-prolif. t.'\n",
    "df.loc[((df.leidencelltype5=='epithelial')),'leiden_CD3_tum'] = 'Tumor'\n",
    "df.loc[df.index.str.contains('JP-TMA2'),'Platform'] = 'cycIF2'\n",
    "\n",
    "# add CD3 neigh\n",
    "ls_index = df[df.Platform!='IMC'].index\n",
    "df.loc[ls_index,'CD3 T cell'] = df.loc[ls_index,['CD4 T cell','CD8 T cell']].sum(axis=1)\n",
    "df['lymphocyte'] = df.loc[:,['CD3 T cell','CD20 B cell']].sum(axis=1) #count T and B cells\n",
    "df['LC']=(df['lymphocyte'] > 5).replace({True:'Clustered',False:'Isolated'})\n",
    "df.loc[df['lymphocyte']==0,'LC']=pd.NA\n",
    "df['LC']=df['LC'].fillna('Non-Lymphocyte')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ls_tumor = ['Basal t.','CD44+ t.', 'CD63+ t.','CK lo. t.','EGFR+ Basal t.', 'EGFR+ t.',\n",
    " 'HER2+ ER+ PR+ t.', 'HER2+ ER+ t.','HER2+ Ki67+ t.', 'HER2++ t.', 'IDO+ Basal t.', 'Luminal ER+ t.',\n",
    " 'Luminal t.', 'Myoepithelial','PD-L1+ Basal t.','Prolif. t.',]\n",
    "df['Tumor_Island'] = df.loc[:,ls_tumor].sum(axis=1) > 0\n",
    "df['Lymphocyte_Type'] = df.leiden_CD3 + '_' + df.LC\n",
    "df['platform'] = df.Platform.replace({'cycIF2':'cycIF'})\n",
    "ls_cell_types = ['CD20 B cell_Isolated', 'CD20 B cell_Clustered',\n",
    "                  'CD3 T cell_Clustered','CD3 T cell_Isolated',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacked bar\n",
    "df_bar = df.loc[((df['Lymphocyte_Type'].isin(ls_cell_types))),['Lymphocyte_Type','platform']].groupby('platform').value_counts(normalize=True)\n",
    "df_bar = df_bar.unstack()\n",
    "fig, ax = plt.subplots(figsize=(3.5,2),dpi=300)\n",
    "df_bar.plot(kind='bar',stacked=True,ax=ax)\n",
    "ax.legend(bbox_to_anchor=(1,.8),fontsize='small')\n",
    "plt.tight_layout()\n",
    "ax.set_title('All Lymphocytes')\n",
    "fig.savefig(f'{s_date}/Lymphocytes_all_cluster.pdf')\n",
    "#plt.close()\n",
    "print(df_bar.loc[:,df_bar.columns.str.contains('Isolated')].mean().sum())\n",
    "print(df_bar.loc[~df_bar.index.str.contains('MIBI'),df_bar.columns.str.contains('Isolated')].mean().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stacked bar\n",
    "df_bar = df.loc[((df['Lymphocyte_Type'].isin(ls_cell_types))) & (df.Tumor_Island),['Lymphocyte_Type','platform']].groupby('platform').value_counts(normalize=True)\n",
    "df_bar = df_bar.unstack()\n",
    "fig, ax = plt.subplots(figsize=(3.5,2),dpi=300)\n",
    "df_bar.plot(kind='bar',stacked=True,ax=ax)\n",
    "ax.legend(bbox_to_anchor=(1,.8),fontsize='small')\n",
    "plt.tight_layout()\n",
    "ax.set_title('Near Tumor')\n",
    "fig.savefig(f'{s_date}/Lymphocytes_near_tumor_cluster.pdf')\n",
    "#plt.close()\n",
    "print(df_bar.loc[:,df_bar.columns.str.contains('Isolated')].mean().sum())\n",
    "print(df_bar.loc[~df_bar.index.str.contains('MIBI'),df_bar.columns.str.contains('Isolated')].mean().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls_cell_types = ['CD20 B cell_Isolated', 'CD20 B cell_Clustered',\n",
    "#                  'CD3 T cell_Clustered','CD3 T cell_Isolated',]\n",
    "# #df_test = df[(df.Tumor_Island)&((df['Lymphocyte_Type'].isin(ls_cell_types)))]\n",
    "# df_test.merge(df_lei_both.loc[:,['DAPI_X','DAPI_Y','slide_scene']],left_index=True,right_index=True).to_csv(f'cells_in_20_microns_of_tumor.csv')\n",
    "#visualize\n",
    "# df_test = df[df.Patient.str.contains('JP')].loc[:,['Patient','LC']].groupby('Patient').value_counts().reset_index()\n",
    "# df_test.sort_values(by=(['Patient','LC']))[-30::]\n",
    "# os.listdir('data')\n",
    "# df_xy = pd.read_csv(f'data/20220420_JP-TMAs_IMC-TMAs_MIBI_CombinedCelltypes_all.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('..')\n",
    "# from mplex_image import analyze\n",
    "# os.chdir(codedir)\n",
    "# df_data = df.merge(df_xy.loc[:,['DAPI_X', 'DAPI_Y']],left_index=True,right_index=True,how='left')\n",
    "# colors = mpl.cm.tab10.colors + mpl.cm.tab20c.colors\n",
    "# df_pos = analyze.celltype_to_bool(df,'LC')\n",
    "# df_pos.columns = [str(item) for item in df_pos.columns]\n",
    "# #plot all groups spatially - leiden \n",
    "# %matplotlib inline\n",
    "# for s_slide in sorted(set(df.Patient)):\n",
    "#     s_slide = 'JP-TMA2-1_scene35'#JP-TMA1-1_scene055'#'JP-TMA1-1_scene068'#'JP-TMA1-1_scene039'#'JP-TMA1-1_scene055'#'JP-TMA1-1_scene041'#'JP-TMA1-1_scene036'#'JP-TMA1-1_scene048'#'JP-TMA1-1_scene034'#'JP-TMA1-1_scene029'#'JP-TMA1-1_scene007'#'JP-TMA1-1_scene021'\n",
    "#     #s_slide = 'JP-TMA2-1_scene24' #'JP-TMA1-1_scene099'#'JP-TMA1-1_scene082'#'JP-TMA2-1_scene24'\n",
    "#     fig,ax = plt.subplots(figsize=(5,4.5),dpi=200)\n",
    "#     #plot negative cells\n",
    "#     df_scene = df_data[df_data.index.str.contains(s_slide)]\n",
    "#     ax.scatter(data=df_scene,x='DAPI_X',y='DAPI_Y',color='silver',s=0.1,label=f'')\n",
    "#     #for idxs, s_color_int in enumerate(range(len(df_pos.columns))):\n",
    "#     for idxs, s_color in enumerate(df_pos.columns):\n",
    "#         s_color = str(s_color)\n",
    "#         if len(df_data[(df_data.index.str.contains(s_slide)) & (df_pos.loc[:,s_color])])>=1:\n",
    "#             #plot positive cells\n",
    "#             ls_index = df_data[(df_data.index.str.contains(s_slide)) & (df_pos.loc[:,s_color])].index\n",
    "#             ax.scatter(data=df_data.loc[ls_index],x='DAPI_X',y='DAPI_Y',label=f'{s_color}',s=0.1,color=colors[idxs])\n",
    "#         #break\n",
    "#     ax.set_title(f\"{s_slide}\", fontsize=16) # \\n {d_a[s_slide]}\n",
    "#     ax.axis('equal')\n",
    "#     ax.set_ylim(ax.get_ylim()[::-1])\n",
    "#     ax.get_xaxis().set_visible(False)\n",
    "#     ax.get_yaxis().set_visible(False)\n",
    "#     for spines in ['left','right','top','bottom']:\n",
    "#         ax.spines[spines].set_visible(False)\n",
    "#     plt.legend(markerscale=10,framealpha=.5) \n",
    "#     fig.savefig(f'{codedir}/{s_date}/{s_slide}__scatterplot.pdf')\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lymphocyte clusters versus isolated versus all, in cancer\n",
    "import importlib\n",
    "importlib.reload(util)\n",
    "\n",
    "alpha = 1.05\n",
    "lls_time = [('Survival_time', 'Survival'),('Recurrence_time', 'Recurrence'),\n",
    "            ]\n",
    "df_both_all = pd.DataFrame()\n",
    "dd_discover = {}\n",
    "d_validate = {'TNBC': ['Lymphocytes_Isolated_0.33',#'CD20 B cell_Clustered_0.33','CD3 T cell_Clustered_0.33',\n",
    "                       'CD3 T cell_Isolated_0.33','CD20 B cell_Isolated_0.33'],#'CD20 B cell_Clustered_0.33','CD3 T cell_Clustered_0.33',],\n",
    "             'ER+':['Lymphocytes_Isolated_0.33','CD3 T cell_Isolated_0.33','CD20 B cell_Isolated_0.33',#'CD3 T cell_Clustered_0.33','CD20 B cell_Clustered_0.33'\n",
    "                   ]}\n",
    "\n",
    "ls_all = []        \n",
    "for s_center in ['Clustered','Isolated','All']:\n",
    "    for s_col in ['CD3 T cell', 'CD20 B cell']:\n",
    "        ls_all.append(f'{s_col}_{s_center}')\n",
    "        \n",
    "d_discovery = {'Discovery':['cycIF'], #\n",
    "               'Validation':['IMC','MIBI','cycIF2'], \n",
    "              'Clinical':['IMC','MIBI','cycIF2','cycIF'],\n",
    "   'Correlation Discovery':['IMC','MIBI','cycIF2','cycIF']\n",
    "              }\n",
    "\n",
    "for s_discovery, ls_plat in d_discovery.items():\n",
    "    for s_time, s_censor in lls_time:\n",
    "        for s_subtype in ['TNBC','ER+',]: #,\n",
    "            if s_discovery == 'Discovery':\n",
    "                ls_cut =[0.33,0.5,0.66]\n",
    "            elif s_discovery == 'Correlation Discovery': \n",
    "                ls_cut =[0.5]\n",
    "            else:\n",
    "                ls_all = d_validate[s_subtype]\n",
    "                ls_cut = [1]\n",
    "            print(ls_all)\n",
    "            for cut_p in ls_cut: ##added\n",
    "                d_data = {}\n",
    "                ls_pval = []\n",
    "                for s_col_center in ls_all:\n",
    "                    #print(s_col_center)\n",
    "                    s_col = s_col_center.split('_')[0]\n",
    "                    s_center = s_col_center.split('_')[1]\n",
    "                    ls_center = [s_center]\n",
    "                    ls_col = [s_col]\n",
    "                    if s_center == 'All':\n",
    "                        ls_center=['Isolated', 'Clustered']\n",
    "                        ls_col = []\n",
    "                    if s_col == 'Lymphocytes':\n",
    "                        ls_col = ['CD3 T cell','CD20 B cell']\n",
    "                    try:\n",
    "                        cut_p = float(s_col_center.split('_')[2])\n",
    "                    except:\n",
    "                        pass\n",
    "                    df_both=pd.DataFrame()\n",
    "                    for s_plat in ls_plat:\n",
    "                        #not tumor islands  #in tumor islands! &(df.Tumor_Island)\n",
    "                        df_count = df.loc[((df.leiden_CD3.isin(ls_col))&(df.Tumor_Island) & (df.Platform==s_plat) & (df.LC.isin(ls_center))),['Patient','subtype']].groupby('Patient').count()\n",
    "                        df_div = df.loc[((df.Platform==s_plat)),['Patient','subtype']].groupby('Patient').count()\n",
    "                        df_mean = (df_count/df_div).rename({'subtype':s_col},axis=1)\n",
    "                        df_mean.index = df_mean.index.astype('str')\n",
    "                        df_mean = df_mean.fillna(0) #zero isolated or clustered is lower than some\n",
    "                        df_sub = df_mean.merge(df_surv,left_index=True,right_index=True,suffixes=('_c',''))\n",
    "                        if s_subtype == 'All':\n",
    "                            df_sub['subtype'] = 'All'\n",
    "                        df_p = util.single_km(df_sub,s_center,s_subtype,s_plat,s_col,savedir = f'{s_date}',alpha=0.00005,\n",
    "                                cutp=cut_p,s_time=s_time,s_censor=s_censor,s_propo='')\n",
    "                        # if pvalue < alpha:\n",
    "                        #     foo\n",
    "                        df_both=pd.concat([df_both,df_p])\n",
    "                    df_both['level1'] = s_center #level1 is center\n",
    "                    df_both['level2'] = s_col #level2 is target\n",
    "                    df_both['level3'] = cut_p #level3 quantile\n",
    "                    print(cut_p)\n",
    "                    #log rank\n",
    "                    try:\n",
    "                        results = multivariate_logrank_test(event_durations=df_both.loc[:,s_time],\n",
    "                                                        groups=df_both.abundance, event_observed=df_both.loc[:,s_censor])\n",
    "                        ls_pval.append(results.summary.p[0])\n",
    "                    except:\n",
    "                        ls_pval.append(1)\n",
    "                    d_data.update({f'{s_col}_{s_center}_{cut_p}':df_both})\n",
    "                    if s_discovery == 'Correlation Discovery':\n",
    "                        df_both_all = pd.concat([df_both_all,(df_both.rename({s_col:'mean_neighbors'},axis=1))])\n",
    "                #run multiple test correction\n",
    "                d_orig,d_correct,d_result = util.run_multi_test(d_data,df_clin,ls_pval,s_discovery,s_subtype,s_censor,s_time,alpha,s_propo='',\n",
    "                   s_center_column=s_col_center,savedir=f'{codedir}/{s_date}/Survival_Plots')\n",
    "                dd_discover.update({f'{s_subtype}_{s_censor}_{cut_p}':d_orig})\n",
    "                #cut_p\n",
    "            #break #subtype\n",
    "        #break #surv/recur\n",
    "    #break #discovery\n",
    "    \n",
    "for key, d_item in dd_discover.items():\n",
    "    for key2, item in d_item.items():\n",
    "        if item < alpha:\n",
    "            print(f'{key} {key2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if s_discovery == 'Correlation Discovery':\n",
    "    print('updating')\n",
    "    d_spatial.update({'LC':df_both_all.rename({'mean_neighbors':'value'},axis=1)})\n",
    "d_spatial.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#plot  spatially \n",
    "import matplotlib as mpl\n",
    "k = 'spatial_aggregate'\n",
    "for s_slide in ls_slide:\n",
    "    s_slide = 'JP-TMA1-1_scene034' #s_slide = 'JP-TMA1-1_scene044'#\n",
    "    print(s_slide)\n",
    "    fig,ax = plt.subplots(figsize=(5,3.8),dpi=200)\n",
    "    #plot negative cells\n",
    "    df_scene = adata_lda.obs[adata_lda.obs.imageid==s_slide]\n",
    "    ax.scatter(x=df_scene.X_centroid.astype('float'),y=df_scene.Y_centroid.astype('float'),color='lightgray',s=0.2,label=f'_ ')\n",
    "    for idxs, s_color in enumerate((df_scene.loc[:,f'{k}'].unique())):\n",
    "        if not s_color == '__non-significant':\n",
    "            ls_index = df_scene[df_scene.loc[:,f'{k}'] == s_color].index\n",
    "            if len(df_scene[df_scene.index.isin(ls_index)])>=300:\n",
    "                df_color = df_scene[df_scene.index.isin(ls_index)]\n",
    "                ax.scatter(x=df_color.X_centroid.astype('float'),y=df_color.Y_centroid.astype('float'),\n",
    "                            label=f'{s_color}',s=0.2,color=mpl.cm.tab10.colors[idxs])\n",
    "        \n",
    "    ax.set_title(f\"{s_slide}\", fontsize=16)\n",
    "    ax.axis('equal')\n",
    "    ax.set_ylim(ax.get_ylim()[::-1])\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wortman et al Occupancy <a name=\"nolan\"></a>\n",
    "\n",
    "\n",
    " As a way of introducing FD, note that the number of tiles, each with area L2, needed to cover a floor is proportional to 1/L2, where the exponent “2” is due to the floor being two-dimensional. Now consider a 2D image covered with a grid of squares (each with area L2) as described above, with 1’s and 0’s corresponding to the answers to a binary question. The number n(L) of squares with ‘1’ will be proportional to (1/Lδ) where the exponent δ is one type of FD and is ≤217. If the system is self-similar and fractal over a range of length scales L, n(L) will follow a power law: n(L) = A/(Lδ), and the exponent δ will remain constant as L varies. The constant of proportionality, A, depends on the size of the tissue that dictates the number of boxes covering the tissue. To avoid this, we define the FD as follows. In a plot of log [n(L)] versus log[A/L], where A is a constant, the FD is the slope s of a line fit through the points using linear regression with a least-squares fit, i.e., s(L) = −d[log n(L)]/d[log L]. (Note that unlike the more common definition of the box-counting FD, the limit L→0 is not taken because of our interest in the distribution of individual cells at different length scales.) The FD over a range of values of L is determined for each patient and then averaged over all patients with a given clinical outcome.\n",
    "\n",
    "\n",
    " So the difference in fractal dimension between large and small length scales will be larger for the spatially dispersed blue points than for the clustered red points.\n",
    "[contents](#contents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function\n",
    "from scipy.stats import linregress\n",
    "def getDimRangeFromSlope(boxCounts, BoxSizes=range(10,310,10)):\n",
    "  # Overall constant to scale the x-axis.\n",
    "  LongSide = 7000\n",
    "  colnames = [\"Small\", \"Overall\", \"Large\"]\n",
    "  if len(boxCounts) != len(BoxSizes):\n",
    "    print(len(boxCounts))\n",
    "    print(len(BoxSizes))\n",
    "    print(\"Vector lengths do not match\")  \n",
    "  if (boxCounts<=1).astype('int').sum() > 2:\n",
    "      data=pd.DataFrame(columns=colnames,data=[0]*len(colnames))\n",
    "      return(data)\n",
    "  #x0 = 1/BoxSizes\n",
    "  x = np.log(LongSide/pd.Series([item for item in BoxSizes]))\n",
    "  y = np.log(boxCounts[0:len(BoxSizes)])\n",
    "  \n",
    "  if sum(np.isinf(y)) > 0:\n",
    "    print(\"Inf replaced with 0\")\n",
    "    y[np.isinf(y)] = 0\n",
    "  # X = x.reset_index().values\n",
    "  # Y = y.reset_index().drop('square_len',axis=1).values#y.reset_index().drop('square_len',axis=1).reset_index().values\n",
    "\n",
    "  #np.linalg.lstsq(a, b, rcond=None)\n",
    "  OverallSlope = linregress(x, y)\n",
    "  SmallSlope =  linregress(x[0:4], y[0:4])#np.linalg.lstsq(X[0:2],Y[0:2],rcond=-1)[0] # 10 to 40\n",
    "  LargeSlope  =  linregress(x[9::], y[9::])#np.linalg.lstsq(X[20::],Y[20::],rcond=-1)[0]## 200 to 300\n",
    "  data = [SmallSlope.slope, OverallSlope.slope, LargeSlope.slope] #Slope_50_100, Slope_50_200,Slope_20_80, Slope_10_80, Slope_10_40\n",
    "  return(data)\n",
    "\n",
    "#data = getDimRangeFromSlope(boxCounts=df_count.Occupancy.values, BoxSizes=df_count.index.tolist())\n",
    "#FD = data[2] - data[0]\n",
    "'''\n",
    "df_rip = pd.DataFrame()\n",
    "s_foler = 'OccCancer'\n",
    "for s_file in sorted(os.listdir(f'data/{s_foler}/')):\n",
    "    if s_file.find('.csv') >-1:\n",
    "        df_rip2 = pd.read_csv(f'{codedir}/data/{s_foler}/{s_file}')\n",
    "        df_rip = pd.concat([df_rip,df_rip2])\n",
    "df_rip.rename({'unlist.result_table.':'Occ','Unnamed: 0':'cellnum'},axis=1,inplace=True)\n",
    "df_rip['cell'] = [item.split('_')[0] for item in df_rip.cellnum]\n",
    "df_rip['cluster'] = [item.split('_')[1] for item in df_rip.cellnum]\n",
    "df_rip['num'] = [item.split('_')[-1] for item in df_rip.cellnum]\n",
    "df_rip['Occupancy'] = df_rip.Occ > 0\n",
    "df_rip['Patient'] = df_rip.slide_scene.map(dict(zip(df_lei_both.slide_scene,df_lei_both.Patient)))\n",
    "#'''\n",
    "'''\n",
    "df_result = pd.DataFrame(columns=['celltype','AUC'])\n",
    "df_result = df_result.astype(dtype = {'celltype':'object','AUC':'float'})\n",
    "\n",
    "for s_cell in ['CD20 B cell','CD3 T cell']:\n",
    "    for s_clust in ['Isolated', 'Clustered','All']:\n",
    "        df_test = df_rip.loc[(df_rip.cell==s_cell) & (df_rip.cluster==s_clust),['Patient','square_len','Occupancy']].groupby(['Patient','square_len']).mean()\n",
    "        if s_clust == 'All':\n",
    "            df_test = df_rip.loc[(df_rip.cell==s_cell),['Patient','square_len','Occupancy']].groupby(['Patient','square_len']).mean()\n",
    "        df_test = df_test.reset_index()\n",
    "        for s_patient in sorted(df_test.Patient.unique()):\n",
    "            df_pt_occ = df_test[df_test.Patient==s_patient]\n",
    "            if len(df_pt_occ) > 2:\n",
    "                roc_auc = sklearn.metrics.auc(df_pt_occ.square_len/df_pt_occ.square_len.max(),\n",
    "                                              df_pt_occ.Occupancy)\n",
    "            else:\n",
    "                roc_auc = pd.NA\n",
    "            df_result.loc[f'{s_patient}_{s_cell}_{s_clust}',['celltype','AUC']] = [f'{s_cell}_{s_clust}',roc_auc]\n",
    "    #     break\n",
    "    # break\n",
    "\n",
    "s_out = f'Results/results_occupancy_AUC_{s_foler}.csv'\n",
    "if not os.path.exists(s_out):\n",
    "    print('saving')\n",
    "    df_result.to_csv(s_out)\n",
    "#df_result = pd.read_csv('Results/results_occupancy_AUC.csv',index_col=0)\n",
    "#df_result#'''\n",
    "#Fractal dimension determined from slope of the log-log plot of the number of squares with at \n",
    "#least one stromal CD20+ B cell vs. the inverse box size (Logarithms are base e). \n",
    "#The fractal dimension is larger for good clinical outcome vs. poor outcome at large length scales,\n",
    "#but this trend is reversed at small length scales. At long length scales (200–600 μm on the left side of the plot), \n",
    "#mean fractal dimension s (slope) is 1.3 for good outcome (blue), 1.11 for poor outcome (red), 0.92 for normal tissue (gray), and 2.08 for Poisson (black).\n",
    "#The p value for good vs. poor outcome is 0.08 at long length scales. \n",
    "#At short length scales (10–40 μm on the right side of the plot), the mean fractal dimension \n",
    "#is 0.58 for good outcome, 0.65 for poor outcome, 0.30 for normal tissue, and 0.15 for Poisson.\n",
    "'''\n",
    "df_result = pd.DataFrame(columns=['celltype','FD'])\n",
    "df_result = df_result.astype(dtype = {'celltype':'object','FD':'float'})\n",
    "for s_cell in ['CD3 T cell','CD20 B cell']:\n",
    "    for s_clust in ['All','Isolated', 'Clustered']:\n",
    "        for s_patient in sorted(df_test.Patient.unique()):\n",
    "            if s_clust == 'All':\n",
    "                df_frac = df_rip.loc[(df_rip.cell==s_cell) & (df_rip.Patient==s_patient),['square_len','Occupancy']]\n",
    "            else:\n",
    "                df_frac = df_rip.loc[(df_rip.cluster==s_clust) &(df_rip.cell==s_cell) & (df_rip.Patient==s_patient),['square_len','Occupancy']]    \n",
    "            df_count = df_frac.groupby('square_len').count()\n",
    "            if len(df_count) > 1: \n",
    "                try:\n",
    "                    data = getDimRangeFromSlope(boxCounts=df_count.Occupancy.values, BoxSizes=df_count.index.tolist())\n",
    "                    FD = data[2] - data[0]\n",
    "                    df_result.loc[f'{s_patient}_{s_cell}_{s_clust}',['celltype','FD']] = [s_cell,FD]\n",
    "                    #break\n",
    "                except:\n",
    "                    print(f'skipping {s_cell} {s_patient}')   \n",
    "            else:\n",
    "                print(f'skipping {s_cell} {s_patient}')\n",
    "            \n",
    "    #     break\n",
    "    # break\n",
    "\n",
    "#df_result.to_csv('Results/results_occupancy_FD_.csv')\n",
    "s_out = f'Results/results_occupancy_FD_{s_foler}.csv'\n",
    "if not os.path.exists(s_out):\n",
    "    df_result.to_csv(s_out)#'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_result.to_csv('Results/results_occupancy_FD.csv')\n",
    "#df_result.to_csv('Results/results_occupancy_AUC.csv')\n",
    "s_occ ='FD_OccCancer'# 'AUC'#\n",
    "df_result = pd.read_csv(f'Results/results_occupancy_{s_occ}.csv',index_col=0)\n",
    "\n",
    "print(len(df_result))\n",
    "df_result['Patient']=[item.split('_')[0] for item in df_result.index]\n",
    "df_result['Platform'] = df_result.Patient.map(dict(zip(df_lei_both.Patient,df_lei_both.Platform)))\n",
    "df_result['subtype'] = df_result.Patient.map(dict(zip(df_lei_both.Patient,df_lei_both.subtype)))\n",
    "df_surv_to_merge = df_surv.loc[:,['Survival','Survival_time','Recurrence','Recurrence_time']].reset_index().rename({'index':'Patient'},axis=1)\n",
    "df_result['celltype'] = [item.split('_')[-2] + '-' + item.split('_')[-1] for item in df_result.index]\n",
    "#calculate occupancy per cell type per patient\n",
    "df_mean = df_result#df_rip.groupby(['Patient','cell']).Occupancy.value_counts(normalize=True).unstack().loc[:,True].unstack()\n",
    "#df_mean = df_mean.fillna(0) #careful, some cells not present in all cohorts. B and T cells are. Don't run step if analyzing other cell types\n",
    "df_mean = df_mean.merge(df_surv_to_merge,on='Patient',how='right',suffixes=('','_x')) #include the \n",
    "df_mean.set_index('Patient',inplace=True)\n",
    "print(len(df_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# occupancy\n",
    "\n",
    "alpha = 1.2\n",
    "lls_time = [('Survival_time', 'Survival'),('Recurrence_time', 'Recurrence'),\n",
    "            ]\n",
    "s_group = 'Subtype_prolif'\n",
    "d_validate = {'TNBC':[#'CD3 T cell-Isolated_Occupancy_0.33',\n",
    "                      #'CD20 B cell-Isolated_Occupancy_0.33',\n",
    "                     'CD3 T cell-All_Occupancy_0.33',\n",
    "    'CD20 B cell-All_Occupancy_0.33'\n",
    "                     ],\n",
    "              'ER+':[#'CD3 T cell-Isolated_Occupancy_0.33',\n",
    "                      #'CD20 B cell-Isolated_Occupancy_0.33',\n",
    "                     'CD3 T cell-All_Occupancy_0.33',\n",
    "    'CD20 B cell-All_Occupancy_0.33']\n",
    "             }\n",
    "ls_all = []    \n",
    "for s_center in ['CD3 T cell-All','CD20 B cell-All' ]:\n",
    "    ls_all.append(f'{s_center}_Occupancy')\n",
    "d_discovery = {'Discovery':['cycIF'],\n",
    "               'Validation':['IMC','MIBI','cycIF2'], \n",
    "               'Clinical':['IMC','MIBI','cycIF2','cycIF'],\n",
    "    'Correlation Discovery':['IMC','MIBI','cycIF2','cycIF']\n",
    "              }\n",
    "    \n",
    "\n",
    "for s_occ in ['AUC_OccCancer','FD_OccCancer']:\n",
    "    df_result = pd.read_csv(f'Results/results_occupancy_{s_occ}.csv',index_col=0)\n",
    "    print(len(df_result))\n",
    "    df_result['Patient']=[item.split('_')[0] for item in df_result.index]\n",
    "    df_result['Platform'] = df_result.Patient.map(dict(zip(df_lei_both.Patient,df_lei_both.Platform)))\n",
    "    df_result['subtype'] = df_result.Patient.map(dict(zip(df_lei_both.Patient,df_lei_both.subtype)))\n",
    "    df_surv_to_merge = df_surv.loc[:,['Survival','Survival_time','Recurrence','Recurrence_time']].reset_index().rename({'index':'Patient'},axis=1)\n",
    "    df_result['celltype'] = [item.split('_')[-2] + '-' + item.split('_')[-1] for item in df_result.index]\n",
    "    #calculate occupancy per cell type per patient\n",
    "    df_mean = df_result#df_rip.groupby(['Patient','cell']).Occupancy.value_counts(normalize=True).unstack().loc[:,True].unstack()\n",
    "    #df_mean = df_mean.fillna(0) #careful, some cells not present in all cohorts. B and T cells are. Don't run step if analyzing other cell types\n",
    "    df_mean = df_mean.merge(df_surv_to_merge,on='Patient',how='right',suffixes=('','_x')) #include the \n",
    "    df_mean.set_index('Patient',inplace=True)\n",
    "    print(len(df_mean))    \n",
    "    df_both_all = pd.DataFrame()\n",
    "    dd_discover = {}  \n",
    "    for s_discovery, ls_plat in d_discovery.items():\n",
    "        print(s_discovery)\n",
    "        for s_time, s_censor in lls_time:\n",
    "            for s_subtype in ['TNBC','ER+',]:\n",
    "                if s_discovery == 'Discovery':\n",
    "                    ls_cut =[0.33,0.5,0.66]\n",
    "                elif s_discovery == 'Correlation Discovery': \n",
    "                    ls_cut =[0.33]\n",
    "                else:\n",
    "                    ls_all = d_validate[s_subtype]\n",
    "                    ls_cut = [1]\n",
    "                for cut_p in ls_cut: ##added\n",
    "                    d_data = {}\n",
    "                    ls_pval = []\n",
    "                    for s_col_center in ls_all:\n",
    "                        print(s_col_center)\n",
    "                        s_col = s_occ.split('_')[0]#'AUC'#s_col_center.split('_')[0]\n",
    "                        s_center = s_col_center.split('_')[0]\n",
    "                        try:\n",
    "                            cut_p = float(s_col_center.split('_')[2])\n",
    "                        except:\n",
    "                            pass\n",
    "                        df_both=pd.DataFrame()\n",
    "                        for s_plat in ls_plat:\n",
    "                            df_sub_surv = df_surv[(df_surv.subtype==s_subtype) & (df_surv.Platform==s_plat)]\n",
    "                            print(df_sub_surv.index.nunique())\n",
    "                            df_sub = df_result[(df_result.celltype==s_center)]\n",
    "                            df_sub = df_sub.set_index('Patient').merge(df_sub_surv,left_index=True,right_index=True,how='right',suffixes=('','_x'))\n",
    "                            df_sub['Platform'] = s_plat\n",
    "                            df_sub['subtype'] = s_subtype\n",
    "                            \n",
    "                            if s_col == 'AUC':\n",
    "                                print(df_sub.AUC.min())\n",
    "                                df_sub[s_col] = df_sub[s_col].fillna(0)\n",
    "                            print(len(df_sub))\n",
    "                            print(df_sub.Survival_time.notna().sum())\n",
    "                            df_p = util.single_km(df_sub,s_center,s_subtype,s_plat,s_col,savedir = f'{s_date}',alpha=0.0000005,\n",
    "                                    cutp=cut_p,s_time=s_time,s_censor=s_censor,s_propo='')\n",
    "                            try:\n",
    "                               print(len(df_p))\n",
    "                            except:\n",
    "                                print(0)\n",
    "                            df_both=pd.concat([df_both,df_p])\n",
    "                        df_both['level1'] = s_center #level1 is center\n",
    "                        df_both['level2'] = s_col #level2 is target\n",
    "                        df_both['level3'] = cut_p #level3 quantile\n",
    "                        # if s_occ.find('FD')>-1:\n",
    "                        #     print((df_both.FD>0.564).value_counts(normalize=True))\n",
    "                        #log rank\n",
    "                        try:\n",
    "                            results = multivariate_logrank_test(event_durations=df_both.loc[:,s_time],\n",
    "                                                            groups=df_both.abundance, event_observed=df_both.loc[:,s_censor])\n",
    "                            ls_pval.append(results.summary.p[0])\n",
    "                        except:\n",
    "                            ls_pval.append(1)\n",
    "                        d_data.update({f'{s_col}_{s_center}_{cut_p}':df_both})\n",
    "                        if s_discovery == 'Correlation Discovery':\n",
    "                            df_both_all = pd.concat([df_both_all,(df_both.rename({s_col:'mean_neighbors'},axis=1))])\n",
    "                    #run multiple test correction\n",
    "                    d_orig,d_correct,d_result = util.run_multi_test(d_data,df_clin,ls_pval,s_discovery,s_subtype,s_censor,s_time,alpha,s_propo='',\n",
    "                       s_center_column=s_col_center,savedir=f'{codedir}/{s_date}/Survival_Plots')\n",
    "                    dd_discover.update({f'{s_subtype}_{s_censor}_{cut_p}':d_orig})\n",
    "                    #cut_p\n",
    "                #break #subtype\n",
    "            #break #surv/recur\n",
    "        #break #discovery\n",
    "      \n",
    "    for key, d_item in dd_discover.items():\n",
    "        for key2, item in d_item.items():\n",
    "            if item < alpha:\n",
    "                print(f'{key} {key2}')\n",
    "    if s_discovery == 'Correlation Discovery':\n",
    "        d_spatial.update({f'Occupancy {s_occ.split(\"_\")[0]}':df_both_all.rename({'mean_neighbors':'value'},axis=1)})\n",
    "        d_spatial[f'Occupancy {s_occ.split(\"_\")[0]}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_spatial.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ripleys L <a name=\"kest\"></a>\n",
    "\n",
    "cycIF_ROI_Kcross.csv\n",
    "\n",
    "cycIF_ROI_Kest\n",
    "\n",
    "[contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load spatstat corrected\n",
    "s_sample = 'cycIF'\n",
    "df_rip = pd.read_csv(f'{codedir}/data/{s_sample}_ROI_Kest.csv')\n",
    "df_rip['Patient'] = df_rip.slide_scene.map(dict(zip(df_lei_both.slide_scene,df_lei_both.Patient)))\n",
    "df_rip['K_correct'] = df_rip.iso - df_rip.theo\n",
    "df_rip['r'] = df_rip.r*.325\n",
    "\n",
    "#mibi and IMC\n",
    "#load spatstat corrected\n",
    "s_sample = 'IMC-MIBI'#'IMC_MIBI'\n",
    "df_rip2 = pd.read_csv(f'{codedir}/data/{s_sample}_ROI_Kest.csv') #ripleys_k.csv\n",
    "df_rip2['Patient'] = df_rip2.slide_scene.map(dict(zip(df_lei_both.slide_scene,df_lei_both.Patient)))\n",
    "df_rip2['K_correct'] = df_rip2.iso - df_rip2.theo\n",
    "df_rip = pd.concat([df_rip,df_rip2])\n",
    "#df.loc[df.index.str.contains('JP-TMA2'),'Platform'] = 'cycIF2'\n",
    "s_cell ='tumor'\n",
    "df_rip['r'] = np.around(df_rip.r, decimals=2)\n",
    "df_r = df_rip[df_rip.cell==s_cell].groupby('Patient').apply(lambda x: (np.quantile(x.loc[:,'r'],0.25),\n",
    "                        np.quantile(x.loc[:,'r'],0.5),np.quantile(x.loc[:,'r'],0.75)))\n",
    "a_r = df_r.iloc[0]\n",
    "a_r = np.around(a_r, decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rip L ()\n",
    "df_rip['L'] = np.sqrt((df_rip.iso/np.pi))\n",
    "dd_discover = {}\n",
    "alpha = 0.2\n",
    "lls_time = [('Survival_time', 'Survival'), ('Recurrence_time', 'Recurrence')]\n",
    "s_group = 'Subtype_prolif'\n",
    "df_both_all = pd.DataFrame()\n",
    "\n",
    "i_r = 50\n",
    "d_discovery = {'Discovery':['cycIF'],\n",
    "               'MIBI':['MIBI'],\n",
    "               'Validation':['IMC','MIBI','cycIF2'], \n",
    "               'Clinical':['IMC','MIBI','cycIF2','cycIF'],\n",
    "              'Correlation Discovery':['IMC','MIBI','cycIF2','cycIF']\n",
    "            }\n",
    "\n",
    "s_median = 'Subtype_prolif'\n",
    "d_validate = {'TNBC':['tumor_0.66'],#'endothelial_0.5'\n",
    "              'ER+':['Quies. str._0.66']}\n",
    "ls_agg = ['tumor', 'Vim+ FB', 'Quies. str.', 'endothelial', \n",
    "       'CD3 T cell', 'Macrophage', 'CD20 B cell',\n",
    "        'CD8 T cell', 'CD4 T cell'] #df_rip.cell.unique()\n",
    "s_col = 'L'\n",
    "for s_discovery, ls_plat in d_discovery.items():\n",
    "    for s_time, s_censor in lls_time:\n",
    "        for s_subtype in ['TNBC','ER+',]:\n",
    "            if s_discovery=='Discovery':\n",
    "                ls_cut_p = [0.33,0.5,0.66]\n",
    "            elif s_discovery == 'Correlation Discovery': \n",
    "                ls_cut_p =[0.5]\n",
    "            else:\n",
    "                ls_agg = d_validate[s_subtype]\n",
    "                ls_cut_p = [1]\n",
    "            ls_pval = []\n",
    "            d_data = {}\n",
    "            for s_center in ls_agg:\n",
    "                for cut_p in ls_cut_p:\n",
    "                    if not (s_discovery == 'Discovery') | (s_discovery == 'Correlation Discovery'):\n",
    "                        cut_p = s_center.split('_')[1]\n",
    "                        print(cut_p)\n",
    "                        s_center = s_center.split('_')[0]\n",
    "                    d_mean = {}\n",
    "                    for s_plat in ls_plat:\n",
    "                        if s_plat == 'cycIF':\n",
    "                            df_sample = df_rip[df_rip.slide_scene.str.contains('JP-TMA1')]\n",
    "                        elif s_plat == 'cycIF2':\n",
    "                            df_sample = df_rip[df_rip.slide_scene.str.contains('JP-TMA2')]\n",
    "                        elif s_plat == 'IMC':\n",
    "                            df_sample = df_rip[~df_rip.slide_scene.str.contains('scene')]\n",
    "                        elif s_plat =='MIBI':\n",
    "                            df_sample = df_rip[(df_rip.slide_scene.str.contains('scene')) & (~df_rip.slide_scene.str.contains('JP-TMA'))]\n",
    "                        df_mean_all = df_sample[(df_sample.cell==s_center) & (df_sample.r==i_r)].groupby(['r','Patient']).mean(numeric_only=True).reset_index()\n",
    "                        df_mean_all['Subtype_prolif'] = df_mean_all.Patient.astype('str').map(d_sub_prolif)\n",
    "                        df_mean = df_mean_all[~df_mean_all.loc[:,s_median].isna()]\n",
    "                        df_mean.set_index('Patient',inplace=True)\n",
    "                        d_mean.update({s_plat:df_mean})\n",
    "                    df_both=pd.DataFrame()\n",
    "                    for s_plat in ls_plat:\n",
    "                        df_sub = d_mean[s_plat][d_mean[s_plat].Subtype_prolif.str.contains(s_subtype)]\n",
    "                        df_sub = df_sub.merge(df_surv,left_index=True,right_index=True)\n",
    "                        df_sub['Platform'] = s_plat\n",
    "                        df_p = util.single_km(df_sub,s_center,s_subtype,s_plat,s_col,savedir = f'{s_date}',alpha=0.000001,\n",
    "                                cutp=0.5,s_time=s_time,s_censor=s_censor,s_propo='Ripleys')\n",
    "                        df_both=pd.concat([df_both,df_p])\n",
    "                    df_both['level1'] = s_center #level1 is ripleys l  cell type\n",
    "                    #log rank\n",
    "                    try:\n",
    "                        results = multivariate_logrank_test(event_durations=df_both.loc[:,s_time],\n",
    "                                                        groups=df_both.abundance, event_observed=df_both.loc[:,s_censor])\n",
    "                        ls_pval.append(results.summary.p[0])\n",
    "                    except:\n",
    "                        ls_pval.append(1)\n",
    "                    d_data.update({f'Ripleys {s_col}_{s_center}_{cut_p}':df_both})\n",
    "                    if s_discovery == 'Correlation Discovery':\n",
    "                        df_both_all = pd.concat([df_both_all,(df_both.rename({s_col:'mean_neighbors'},axis=1))])\n",
    "            #run multiple test correction\n",
    "            d_orig,d_correct,d_result = util.run_multi_test(d_data,df_clin,ls_pval,s_discovery,s_subtype,s_censor,s_time,alpha,s_propo='',\n",
    "                   s_center_column=f'leiden',savedir=f'{codedir}/{s_date}/Survival_Plots')\n",
    "            dd_discover.update({f'{s_subtype}_{s_censor}_{cut_p}':d_orig})\n",
    "            #break #subtype\n",
    "        break #surv/recur\n",
    "    #break #discovery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if s_discovery == 'Correlation Discovery':\n",
    "    d_spatial.update({'ripleys_l':df_both_all.rename({'mean_neighbors':'value'},axis=1)})\n",
    "d_spatial.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_spatial.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K cross  <a name=\"kcross\"></a>\n",
    "\n",
    "[contents](#contents)\n",
    "\n",
    "ripleys K between two cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load spatstat Kcross\n",
    "s_sample = 'cycIF'\n",
    "s_stat = 'Kcross'\n",
    "#ls_kcross = ['JP-TMA1_first','JP-TMA1_second','JP-TMA1_100s','JP-TMA2']\n",
    "#df_rip = pd.DataFrame()\n",
    "#for s_cross in ls_kcross:\n",
    "#    df_rip = pd.concat([df_rip,(pd.read_csv(f'{codedir}/data/{s_sample}_{s_cross}_{s_stat}.csv'))])\n",
    "df_rip = pd.read_csv(f'{codedir}/data/cycIF_ROI_Kcross.csv')\n",
    "df_rip['Patient'] = df_rip.slide_scene.map(dict(zip(df_lei_both.slide_scene,df_lei_both.Patient)))\n",
    "df_rip['Kcross'] = df_rip.iso - df_rip.theo\n",
    "df_rip['r'] = df_rip.r*.325\n",
    "\n",
    "#mibi and IMC\n",
    "#load spatstat corrected\n",
    "s_sample = 'IMC-MIBI'\n",
    "df_rip2 = pd.read_csv(f'{codedir}/data/{s_sample}_ROI_{s_stat}.csv')\n",
    "df_rip2['Patient'] = df_rip2.slide_scene.map(dict(zip(df_lei_both.slide_scene,df_lei_both.Patient)))\n",
    "df_rip2['Kcross'] = df_rip2.iso - df_rip2.theo\n",
    "df_rip = pd.concat([df_rip,df_rip2]) #'''\n",
    "\n",
    "df_rip['r'] = np.around(df_rip.r, decimals=2)\n",
    "a_r = np.array([25., 50., 75.])\n",
    "df_rip['leiden'] = df_rip.to_cell + '-' + df_rip.from_cell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for s_slide in ['JP-TMA1-1_scene034','JP-TMA2-1_scene18','JP-TMA2-1_scene10','JP-TMA2-1_scene05']:\n",
    "    df_plot = df_rip[(df_rip.from_cell=='tumor') & (df_rip.to_cell=='Macrophage') & (df_rip.slide_scene==s_slide)]\n",
    "    fig, ax = plt.subplots(figsize=(2.5,2.5))\n",
    "    df_plot.plot(x='r',y='iso',ax=ax,label='observed')\n",
    "    df_plot.plot(x='r',y='theo',ax=ax,label='theoretical')\n",
    "    ax.legend(frameon=False)\n",
    "    ax.set_ylabel(\"Ripley's K\")\n",
    "    ax.set_xlabel(\"radius\")\n",
    "    ax.ticklabel_format(axis='y', style='sci', scilimits=(4,4))\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(f'{s_date}/{s_slide}_ripleys.pdf',bbox_inches='tight')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add platform\n",
    "for s_plat in ['IMC','MIBI','cycIF2','cycIF']:\n",
    "    if s_plat == 'cycIF':\n",
    "        df_sample = df_rip[df_rip.slide_scene.str.contains('JP-TMA1')]\n",
    "    elif s_plat == 'cycIF2':\n",
    "        df_sample = df_rip[df_rip.slide_scene.str.contains('JP-TMA2')]\n",
    "    elif s_plat == 'IMC':\n",
    "        df_sample = df_rip[~df_rip.slide_scene.str.contains('scene')]\n",
    "    elif s_plat =='MIBI':\n",
    "        df_sample = df_rip[(df_rip.slide_scene.str.contains('scene')) & (~df_rip.slide_scene.str.contains('JP-TMA'))]\n",
    "    df_rip.loc[df_rip.Patient.isin(df_sample.Patient),'Platform'] = s_plat\n",
    "    \n",
    "df_rip['subtype'] = df_rip.Patient.map(dict(zip(df_surv.index,df_surv.subtype)))\n",
    "df_rip.rename({'iso':'K cross'},axis=1,inplace=True)\n",
    "df_rip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# K cross. nothing is significant\n",
    "alpha = 0.05\n",
    "lls_time = [('Survival_time', 'Survival'), ('Recurrence_time', 'Recurrence')]\n",
    "s_group = 'Subtype_prolif'\n",
    "df_both_all = pd.DataFrame()\n",
    "dd_discover = {}\n",
    "d_validate = {'TNBC':['K cross_Quies. str.-CD3 T cell_0.33',\n",
    "                      'K cross_CD20 B cell-CD3 T cell_0.66',\n",
    "                      'K cross_Vim+ FB-CD3 T cell_0.66',\n",
    "                      'K cross_Macrophage-tumor_0.5'\n",
    "                     ],\n",
    "              'ER+':['K cross_Vim+ FB-CD3 T cell_0.33',\n",
    "                     'K cross_Quies. str.-tumor_0.5'\n",
    "                    ]}\n",
    "#set radius      \n",
    "i_r = 50.0\n",
    "df = df_rip[df_rip.r==i_r]\n",
    "\n",
    "ls_all = []        \n",
    "for s_center in ['tumor','CD3 T cell']:\n",
    "    for s_col in ['CD20 B cell','tumor','Vim+ FB', 'Quies. str.', 'Macrophage', 'endothelial', 'CD3 T cell']: #'CD4 T cell', 'CD8 T cell', 'FN+ FB',\n",
    "        ls_all.append(f'K cross_{s_col}-{s_center}')\n",
    "d_discovery = {' Discovery':['cycIF'],\n",
    "               'Validation':['IMC','MIBI','cycIF2'], \n",
    "               'Clinical':['IMC','MIBI','cycIF2','cycIF'],\n",
    "               'Correlation Discovery':['IMC','MIBI','cycIF2','cycIF']\n",
    "              }\n",
    "for s_discovery, ls_plat in d_discovery.items():\n",
    "    for s_time, s_censor in lls_time:\n",
    "        for s_subtype in ['ER+','TNBC']:\n",
    "            if s_discovery == 'Discovery':\n",
    "                ls_cut =[0.33,0.5,0.66]\n",
    "            elif s_discovery == 'Correlation Discovery': \n",
    "                ls_cut =[0.5]\n",
    "            else:\n",
    "                ls_all = d_validate[s_subtype]\n",
    "                ls_cut = [1]\n",
    "            for cut_p in ls_cut: ##added\n",
    "                d_data = {}\n",
    "                ls_pval = []\n",
    "                for s_col_center in ls_all:\n",
    "                    #print(s_col_center)\n",
    "                    s_col = s_col_center.split('_')[0]\n",
    "                    s_center = s_col_center.split('_')[1]\n",
    "                    try:\n",
    "                        cut_p = float(s_col_center.split('_')[2])\n",
    "                    except:\n",
    "                        pass\n",
    "                    df_both=pd.DataFrame()\n",
    "                    for s_plat in ls_plat:\n",
    "                        df_sub = util.make_mean(df,s_plat,s_center,s_subtype,s_col,s_center_column='leiden')\n",
    "                        df_sub = df_sub.merge(df_surv,left_index=True,right_index=True)\n",
    "                        df_p = util.single_km(df_sub,s_center,s_subtype,s_plat,s_col,savedir = f'{s_date}',alpha=0.000001,\n",
    "                                cutp=cut_p,s_time=s_time,s_censor=s_censor,s_propo='')\n",
    "                        df_both=pd.concat([df_both,df_p])\n",
    "                    df_both['level1'] = s_center #level1 is center\n",
    "                    df_both['level2'] = s_col #level2 is target\n",
    "                    df_both['level3'] = cut_p #level3 quantile\n",
    "                    #log rank\n",
    "                    try:\n",
    "                        results = multivariate_logrank_test(event_durations=df_both.loc[:,s_time],\n",
    "                                                        groups=df_both.abundance, event_observed=df_both.loc[:,s_censor])\n",
    "                        ls_pval.append(results.summary.p[0])\n",
    "                    except:\n",
    "                        ls_pval.append(1)\n",
    "                    d_data.update({f'{s_col}_{s_center}_{cut_p}':df_both})\n",
    "                    if s_discovery == 'Correlation Discovery':\n",
    "                        df_both_all = pd.concat([df_both_all,(df_both.rename({s_col:'mean_neighbors'},axis=1))])\n",
    "                #run multiple test correction\n",
    "                d_orig,d_correct,d_result = util.run_multi_test(d_data,df_clin,ls_pval,s_discovery,s_subtype,s_censor,s_time,alpha,s_propo='',\n",
    "                   s_center_column='leiden',savedir=f'{codedir}/{s_date}/Survival_Plots')\n",
    "                dd_discover.update({f'{s_subtype}_{s_censor}_{cut_p}':d_orig})\n",
    "                #cut_p\n",
    "            #break #subtype\n",
    "        break #surv/recur\n",
    "    #break #discovery\n",
    "    \n",
    "for key, d_item in dd_discover.items():\n",
    "    for key2, item in d_item.items():\n",
    "        if item < alpha:\n",
    "            print(f'{key} {key2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if s_discovery == 'Correlation Discovery':\n",
    "    d_spatial.update({'Kcross':df_both_all.rename({'mean_neighbors':'value'},axis=1)})\n",
    "d_spatial.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G cross <a name=\"gcross\"></a>\n",
    "\n",
    "similar to neighbor counts\n",
    "\n",
    "[contents](#contents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load spatstat Kcross\n",
    "s_sample = 'cycIF'\n",
    "s_stat = 'Gcross'\n",
    "#ls_kcross = ['JP-TMA1_first','JP-TMA1_second','JP-TMA1_100s','JP-TMA2']\n",
    "#df_rip = pd.DataFrame()\n",
    "#for s_cross in ls_kcross:\n",
    "#    df_rip = pd.concat([df_rip,(pd.read_csv(f'{codedir}/data/{s_sample}_{s_cross}_{s_stat}.csv'))])\n",
    "df_rip = pd.read_csv(f'{codedir}/data/{s_sample}_ROI_{s_stat}.csv')\n",
    "df_rip['Patient'] = df_rip.slide_scene.map(dict(zip(df_lei_both.slide_scene,df_lei_both.Patient)))\n",
    "df_rip['r'] = df_rip.r*.325\n",
    "\n",
    "#mibi and IMC\n",
    "#load spatstat corrected\n",
    "s_sample = 'IMC-MIBI'\n",
    "df_rip2 = pd.read_csv(f'{codedir}/data/{s_sample}_ROI_{s_stat}.csv')\n",
    "df_rip2['Patient'] = df_rip2.slide_scene.map(dict(zip(df_lei_both.slide_scene,df_lei_both.Patient)))\n",
    "df_rip = pd.concat([df_rip,df_rip2]) #'''\n",
    "\n",
    "df_rip['r'] = np.around(df_rip.r, decimals=2)\n",
    "a_r = np.array([25., 50., 75.])\n",
    "df_rip['leiden'] = df_rip.to_cell + '-' + df_rip.from_cell "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add platform\n",
    "for s_plat in ['IMC','MIBI','cycIF2','cycIF']:\n",
    "    if s_plat == 'cycIF':\n",
    "        df_sample = df_rip[df_rip.slide_scene.str.contains('JP-TMA1')]\n",
    "    elif s_plat == 'cycIF2':\n",
    "        df_sample = df_rip[df_rip.slide_scene.str.contains('JP-TMA2')]\n",
    "    elif s_plat == 'IMC':\n",
    "        df_sample = df_rip[~df_rip.slide_scene.str.contains('scene')]\n",
    "    elif s_plat =='MIBI':\n",
    "        df_sample = df_rip[(df_rip.slide_scene.str.contains('scene')) & (~df_rip.slide_scene.str.contains('JP-TMA'))]\n",
    "    df_rip.loc[df_rip.Patient.isin(df_sample.Patient),'Platform'] = s_plat\n",
    "    \n",
    "df_rip['subtype'] = df_rip.Patient.map(dict(zip(df_surv.index,df_surv.subtype)))\n",
    "df_rip.rename({'km':'Gcross'},axis=1,inplace=True)\n",
    "df_rip['r'] = round(df_rip.r/10)*10\n",
    "df_rip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# G cross - nothing is significant\n",
    "alpha = 1.05\n",
    "lls_time = [('Survival_time', 'Survival'), ('Recurrence_time', 'Recurrence')]\n",
    "s_group = 'Subtype_prolif'\n",
    "df_both_all = pd.DataFrame()\n",
    "dd_discover = {}\n",
    "d_validate = {'TNBC':['Gcross_CD20 B cell-tumor_0.33',\n",
    "                      'Gcross_CD3 T cell-tumor_0.33',\n",
    "                      'Gcross_Macrophage-tumor_0.33',\n",
    "                      'Gcross_Quies. str.-CD3 T cell_0.33'\n",
    "                     ],\n",
    "              'ER+':['Gcross_Vim+ FB-CD3 T cell_0.33'\n",
    "                    ]}\n",
    "#set radius      \n",
    "i_r = 50.0\n",
    "df = df_rip[df_rip.r==i_r]\n",
    "\n",
    "ls_all = []        \n",
    "for s_center in ['tumor','CD3 T cell']:\n",
    "    for s_col in ['CD20 B cell','tumor','Vim+ FB', 'Quies. str.', 'Macrophage', 'endothelial', 'CD3 T cell']: #'tumor','CD4 T cell', 'CD8 T cell', 'FN+ FB',\n",
    "        ls_all.append(f'Gcross_{s_col}-{s_center}')\n",
    "d_discovery = {' Discovery':['cycIF'],\n",
    "               'Validation':['IMC','MIBI','cycIF2'], \n",
    "               'Clinical':['IMC','MIBI','cycIF2','cycIF'],\n",
    "    'Correlation Discovery':['IMC','MIBI','cycIF2','cycIF']\n",
    "              }\n",
    "for s_discovery, ls_plat in d_discovery.items():\n",
    "    for s_time, s_censor in lls_time:\n",
    "        for s_subtype in ['ER+','TNBC']:\n",
    "            if s_discovery == 'Discovery':\n",
    "                ls_cut =[0.33,0.5,0.66]\n",
    "            elif s_discovery == 'Correlation Discovery': \n",
    "                ls_cut =[0.5]\n",
    "            else:\n",
    "                ls_all = d_validate[s_subtype]\n",
    "                ls_cut = [1]\n",
    "            for cut_p in ls_cut: ##added\n",
    "                d_data = {}\n",
    "                ls_pval = []\n",
    "                for s_col_center in ls_all:\n",
    "                    #print(s_col_center)\n",
    "                    s_col = s_col_center.split('_')[0]\n",
    "                    s_center = s_col_center.split('_')[1]\n",
    "                    try:\n",
    "                        cut_p = float(s_col_center.split('_')[2])\n",
    "                    except:\n",
    "                        pass\n",
    "                    df_both=pd.DataFrame()\n",
    "                    for s_plat in ls_plat:\n",
    "                        df_sub = util.make_mean(df,s_plat,s_center,s_subtype,s_col,s_center_column='leiden')\n",
    "                        df_sub = df_sub.merge(df_surv,left_index=True,right_index=True)\n",
    "                        df_p = util.single_km(df_sub,s_center,s_subtype,s_plat,s_col,savedir = f'{s_date}',alpha=0.000001,\n",
    "                                cutp=cut_p,s_time=s_time,s_censor=s_censor,s_propo='')\n",
    "                        df_both=pd.concat([df_both,df_p])\n",
    "                    df_both['level1'] = s_center #level1 is center\n",
    "                    df_both['level2'] = s_col #level2 is target\n",
    "                    df_both['level3'] = cut_p #level3 quantile\n",
    "                    #log rank\n",
    "                    try:\n",
    "                        results = multivariate_logrank_test(event_durations=df_both.loc[:,s_time],\n",
    "                                                        groups=df_both.abundance, event_observed=df_both.loc[:,s_censor])\n",
    "                        ls_pval.append(results.summary.p[0])\n",
    "                    except:\n",
    "                        ls_pval.append(1)\n",
    "                    d_data.update({f'{s_col}_{s_center}_{cut_p}':df_both})\n",
    "                    if s_discovery == 'Correlation Discovery':\n",
    "                        df_both_all = pd.concat([df_both_all,(df_both.rename({s_col:'mean_neighbors'},axis=1))])\n",
    "                #run multiple test correction\n",
    "                try:\n",
    "                    d_orig,d_correct,d_result = util.run_multi_test(d_data,df_clin,ls_pval,s_discovery,s_subtype,s_censor,s_time,alpha,s_propo='',\n",
    "                       s_center_column='leiden',savedir=f'{codedir}/{s_date}/Survival_Plots')\n",
    "                    dd_discover.update({f'{s_subtype}_{s_censor}_{cut_p}':d_orig})\n",
    "                except:\n",
    "                    print(f'error {s_col_center} {cut_p}')\n",
    "                #cut_p\n",
    "            #break #subtype\n",
    "        break #surv/recur\n",
    "    #break #discovery\n",
    "    \n",
    "for key, d_item in dd_discover.items():\n",
    "    for key2, item in d_item.items():\n",
    "        if item < alpha:\n",
    "            print(f'{key} {key2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if s_discovery == 'Correlation Discovery':\n",
    "    d_spatial.update({'Gcross':df_both_all.rename({'mean_neighbors':'value'},axis=1)})\n",
    "\n",
    "d_spatial.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #done\n",
    "# df_out = pd.concat(d_spatial)\n",
    "# df_out.to_csv('20240917_Patient_Spatial_Metrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Immune Tumor Spatial Metrics <a name=\"metric\"></a>\n",
    "\n",
    "- prognostic value of immune tumor metrics\n",
    "- correlation of immune tumor spatial metrics\n",
    "\n",
    "\n",
    "[contents](#contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load spatial metrics per patient\n",
    "#df_spatial = pd.read_csv('20220930_Patient_Spatial_Metrics.csv')\n",
    "#df_spatial = pd.read_csv('20221011_Patient_Spatial_Metrics.csv')\n",
    "df_spatial = pd.read_csv('data/20240917_Patient_Spatial_Metrics.csv')\n",
    "df_spatial.rename({'Unnamed: 0':'metric','Unnamed: 1':'Patient'},axis=1,inplace=True)\n",
    "df_spatial['level2'] = df_spatial.level2.replace({'K cross':np.NaN, 'Gcross':np.NaN})\n",
    "df_spatial['level1'] = df_spatial.level1.replace({'Occupancy':np.NaN,'mixing_score':'tumor-immune'})\n",
    "df_spatial['metric'] = df_spatial.metric.replace({'hh_neighbors':'neighbors'})\n",
    "\n",
    "ls_col = ['metric','level1', 'level2'] #, 'level3'\n",
    "df_spatial['type'] = df_spatial.loc[:,ls_col].fillna('').apply(lambda x: ' '.join(x.values.astype(str)), axis=1)\n",
    "\n",
    "#wide dataframe\n",
    "df_result = df_spatial.loc[:,['type','Patient','value']].pivot_table(index='Patient', columns='type', values='value')\n",
    "\n",
    "#table of pvalues\n",
    "df_result_surv = df_result.merge(df_surv,left_index=True,right_index=True,how='left')\n",
    "len(df_result_surv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tested 75 spatial biomarkers\n",
    "len(df_spatial.type.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## survival across cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(util)\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action='ignore') #category=ApproximationWarning\n",
    "    df_pvalue = pd.DataFrame(index = df_result.columns)\n",
    "    df_direction = pd.DataFrame(index = df_result.columns)\n",
    "    lls_time = [('Survival_time', 'Survival'),('Recurrence_time', 'Recurrence')] #, \n",
    "    \n",
    "    for s_time, s_censor in lls_time:\n",
    "        for s_subtype in ['TNBC','ER+']:\n",
    "            for s_plat in ['IMC','cycIF','MIBI']:\n",
    "                df_subtype = df_result_surv.loc[((df_result_surv.subtype==s_subtype)&(df_result_surv.Platform==s_plat))].copy()\n",
    "                ls_col = df_subtype.loc[:,df_pvalue.index].loc[:,~df_subtype.loc[:,df_pvalue.index].isna().all()].columns\n",
    "                for s_col in ls_col:\n",
    "                    cutp=0.5 #use 0.5 to binarize\n",
    "                    if s_col.find('mixing_score') > -1:\n",
    "                        cutp=0.66\n",
    "                    elif s_col.find('LC') > -1:\n",
    "                        cutp=0.33\n",
    "                    elif s_col.find('Occupancy') > -1:\n",
    "                        cutp=0.33\n",
    "                    ls_index = df_subtype.loc[:,s_col].dropna().index\n",
    "                    pvalue, median_diff, results = util.km_pvalue(df_subtype.loc[ls_index],s_col,s_time,s_censor,cutp)\n",
    "                    df_pvalue.loc[s_col,f'{s_subtype}_{s_plat}_{s_censor}'] = pvalue\n",
    "                    df_direction.loc[s_col,f'{s_subtype}_{s_plat}_{s_censor}'] = median_diff\n",
    "                    #break\n",
    "                #break\n",
    "            #break\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#direction of median survival\n",
    "df_dir = pd.DataFrame(data=np.nan_to_num(df_direction,posinf=5000, neginf=-5000),index=df_direction.index,columns=df_direction.columns)\n",
    "df_dir.index = [item.replace('leiden_',' ').replace('leidencelltype5_','') for item in df_dir.index]\n",
    "df_pvalue.index = [item.replace('leiden_',' ').replace('leidencelltype5_','') for item in df_pvalue.index]\n",
    "\n",
    "#df_pvalue[(df_pvalue < 0.05).any(axis=1)].to_csv('Spatial_stats_pvalues.csv')\n",
    "df_pv = df_pvalue[(df_pvalue < 0.05).any(axis=1)]\n",
    "#plot pvals and survival diffs\n",
    "#df_dir = df_dir.loc[~df_dir.index.duplicated()]\n",
    "fig,ax = plt.subplots(figsize=(12,6.5))\n",
    "sns.heatmap(df_dir.loc[df_pv.index].T,cmap='RdBu_r',xticklabels=1,ax=ax,annot=(df_pv<0.05).replace({True:'*',False:''}).T, fmt = '',#mask=(df_pv.fillna(1)>0.05).T,\n",
    "           linewidths=1,linecolor='gray')\n",
    "ax.set_xlabel('')\n",
    "plt.tight_layout()\n",
    "fig.savefig(f'{s_date}/spatial_metric_survival_heatmap.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just the dendrogram\n",
    "df_result = df_spatial.loc[((~df_spatial.type.str.contains('25.0')) & (~df_spatial.type.str.contains(\n",
    "    '75.0'))& (~df_spatial.type.str.contains('ripleys_k'))),['type','Patient','value']].pivot_table(\n",
    "    index='Patient', columns='type', values='value')\n",
    "df_result.columns = [item.replace('leiden_','').replace('leidencelltype5_','') for item in df_result.columns]\n",
    "\n",
    "#load composition based metrics to compare to spatial metrics\n",
    "\n",
    "df1 = pd.read_csv(f'{codedir}/results/results_20220420_JP-TMAs_IMC-TMAs_MIBI_GatedCellTypes_byPatient_bygatedcelltype5_all.csv',index_col=0)\n",
    "df2 = pd.read_csv(f'{codedir}/results/results_20220420_JP-TMAs_IMC-TMAs_MIBI_LeidenClustering_byPatient_byleidencelltype2_inepithelial_all.csv',index_col=0)\n",
    "df3 = pd.read_csv(f'{codedir}/results/results_20220420_JP-TMAs_IMC-TMAs_MIBI_LeidenClustering_byPatient_byleidencelltype2_instromal_all.csv',index_col=0)\n",
    "\n",
    "ls_str = ['Quies. str.','FN+ FB','Vim+ FB','Macrophage','endothelial','CD3 T cell','CD4 T cell','CD8 T cell','CD20 B cell']\n",
    "df_comp = df1.drop(['endothelial','stromal'],axis=1).merge(df3.loc[:,ls_str],left_index=True,right_index=True)\n",
    "#.merge(df2.loc[:,['Prolif. t.']],left_index=True,right_index=True)\n",
    "df_comp = df_comp.rename({'epithelial':'tumor'},axis=1)\n",
    "\n",
    "df_comp.columns = [f'comp. {item}' for item in df_comp.columns]\n",
    "df_result_comp = df_result.merge(df_comp,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_drop = ['LC All CD20 B cell', 'LC All CD3 T cell']\n",
    "df_result_comp.drop(ls_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dim = (21,21)\n",
    "mask = (np.ones_like(df_result_comp.corr().fillna(0))) #np.tril\n",
    "g = sns.clustermap(df_result_comp.corr().fillna(0),method='weighted',figsize=dim,cmap='RdBu_r',\n",
    "                   cbar=False,dendrogram_ratio=0.1,cbar_pos=None,tree_kws={'linewidths':3},\n",
    "                   mask=mask\n",
    "                  #cbar_kws={'shrink':0.2,'fraction':0.05,'label':'Pearson Correlation','pad':.2}\n",
    "                  )\n",
    "g.savefig(f'{codedir}/{s_date}/clustermap_for_dendrogram_Spatial_Metric_Correlation.pdf')\n",
    "#plt.close()\n",
    "# categories_order = df_result.corr().iloc[g.dendrogram_col.reordered_ind,:].index.tolist()\n",
    "# df_result = df_result.loc[:,categories_order]\n",
    "# rho = df_result.corr().fillna(0)\n",
    "# matrix = np.triu(np.ones_like(rho))\n",
    "# np.fill_diagonal(matrix, val=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with comp\n",
    "dim = (21,21)\n",
    "g = sns.clustermap(df_result_comp.corr().fillna(0),method='weighted',figsize=dim,cmap='RdBu_r',\n",
    "                   cbar=False,dendrogram_ratio=0.1,cbar_pos=None,\n",
    "                  #cbar_kws={'shrink':0.2,'fraction':0.05,'label':'Pearson Correlation','pad':.2}\n",
    "                  )\n",
    "g.savefig(f'{codedir}/{s_date}/clustermap_for_dendrogram_Spatial_Metric_Composition_Correlation.pdf',dpi=300)\n",
    "plt.close()\n",
    "categories_order = df_result_comp.corr().iloc[g.dendrogram_col.reordered_ind,:].index.tolist()\n",
    "df_result_comp = df_result_comp.loc[:,categories_order]\n",
    "rho = df_result_comp.corr().fillna(0)\n",
    "pval = df_result_comp.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
    "p_vals = pval.applymap(lambda x: ''.join(['*' for t in [0.05] if x<=t])) #[0.001,0.005,0.05]\n",
    "#np.fill_diagonal(p_vals.values,'')\n",
    "fig, ax = plt.subplots(figsize=dim,dpi=300)\n",
    "sns.heatmap(df_result_comp.corr(), vmin=-1, vmax=1,  fmt = '', cmap='RdBu_r',annot=p_vals,#mask=matrix\n",
    "            ax=ax,cbar_kws={'shrink':0.85,'label':'Pearson Correlation'}) #'anchor':(-1.4,0.0)\n",
    "ax.set_title(f'Spatial Metric Correlation', fontdict={'fontsize':16}, y=1)\n",
    "ax.tick_params(axis='both', which='both', length=0)\n",
    "fig.savefig(f'{codedir}/{s_date}/heatmap_Spatial_Metric_Composition_Correlation.pdf', bbox_inches='tight')#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_comp.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zoom in (for presentations)\n",
    "#fewer rows\n",
    "df_result = df_spatial.loc[((~df_spatial.type.str.contains('25.0')) & (~df_spatial.type.str.contains(\n",
    "    '75.0'))& (df_spatial.type.str.contains('CD3 T cell'))),['type','Patient','value']].pivot_table(\n",
    "    index='Patient', columns='type', values='value')\n",
    "df_result.columns = [item.replace('leiden_','').replace('leidencelltype5_','') for item in df_result.columns]\n",
    "ls_drop = [ 'LC All CD3 T cell']#'LC All CD20 B cell',\n",
    "df_result.drop(ls_drop,axis=1,inplace=True)\n",
    "# with comp\n",
    "dim = (11,11)\n",
    "df_comp.columns = [f' {item.replace(\"comp.\",\"Abundance\")}' for item in df_comp.columns]\n",
    "df_result_comp = df_result.merge(df_comp.loc[:,df_comp.columns.str.contains('CD3 T cell')],left_index=True,right_index=True)\n",
    "g = sns.clustermap(df_result_comp.corr().fillna(0),method='weighted',figsize=dim,cmap='RdBu_r',\n",
    "                   cbar=False,dendrogram_ratio=0.1,cbar_pos=None,\n",
    "                  #cbar_kws={'shrink':0.2,'fraction':0.05,'label':'Pearson Correlation','pad':.2}\n",
    "                  )\n",
    "g.savefig(f'{codedir}/{s_date}/clustermap_for_dendrogram_Spatial_Metric_Composition_Correlation.pdf',dpi=300)\n",
    "plt.close()\n",
    "categories_order = df_result_comp.corr().iloc[g.dendrogram_col.reordered_ind,:].index.tolist()\n",
    "df_result_comp = df_result_comp.loc[:,categories_order]\n",
    "rho = df_result_comp.corr().fillna(0)\n",
    "pval = df_result_comp.corr(method=lambda x, y: pearsonr(x, y)[1]) - np.eye(*rho.shape)\n",
    "p_vals = pval.applymap(lambda x: ''.join(['*' for t in [0.05] if x<=t])) #[0.001,0.005,0.05]\n",
    "#np.fill_diagonal(p_vals.values,'')\n",
    "fig, ax = plt.subplots(figsize=dim,dpi=300)\n",
    "sns.heatmap(df_result_comp.corr(), vmin=-1, vmax=1,  fmt = '', cmap='RdBu_r',annot=p_vals,#mask=matrix\n",
    "            ax=ax,cbar_kws={'shrink':0.85,'label':'Pearson Correlation'}) #'anchor':(-1.4,0.0)\n",
    "ax.set_title(f'Spatial Metric Correlation', fontdict={'fontsize':16}, y=1)\n",
    "ax.tick_params(axis='both', which='both', length=0)\n",
    "fig.savefig(f'{codedir}/{s_date}/heatmap_Zoom_Spatial_Metric_Composition_Correlation.pdf', dpi=300, bbox_inches='tight')#'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Immunoregulatory <a name=\"sqpy\"></a>\n",
    "\n",
    "Patwa et al. Comm Biol. 2021. \"We highlight the immunological relevance of the immunoregulatory proteins PD-1, PD-L1, IDO, and Lag3 by tying interactions involving them to recurrence and survival. Multivariate analysis reveals that our methods provide additional prognostic information compared to clinical variables.\"\n",
    "\n",
    "[contents](#contents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted(os.listdir('data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load combined\n",
    "s_sample = '20220420_JP-TMAs_IMC-TMAs_MIBI' \n",
    "s_type = 'all'\n",
    "df_lei = pd.read_csv(f'{codedir}/data/{s_sample}_CombinedCelltypes_{s_type}.csv',index_col=0,low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#protein positivity (use cycIF thresholds)\n",
    "\n",
    "ls_man = ['20211207_JP-TMA1_ManualPositive.csv',\n",
    " '20211221_JP-TMA2_ManualPositive.csv',]\n",
    "df_pos = pd.DataFrame()\n",
    "for s_man in ls_man:\n",
    "    df = pd.read_csv(f'data/{s_man}',index_col=0)\n",
    "    df_pos = pd.concat([df_pos,df])\n",
    "df_pos.rename({'DAPI_X':'Column','DAPI_Y':'Row'},axis=1,inplace=True)  \n",
    "d_celltype = dict(zip(df_lei.index,df_lei.leiden))\n",
    "df_pos['Celltype'] = df_pos.index.map(d_celltype)\n",
    "df_pos['slide_scene'] = [item.split('_cell')[0] for item in df_pos.index]\n",
    "\n",
    "centroid_df_columns = ['row', 'column', 'celltype']\n",
    "for s_col in centroid_df_columns:\n",
    "    df_pos[s_col] = df_pos.loc[:,s_col.title()]\n",
    "    \n",
    "#only clustered cells\n",
    "df_pos = df_pos[df_pos.Celltype.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_marker = (df_pos.dtypes=='bool') & (~df_pos.columns.str.contains('DAPI'))\n",
    "ls_marker = df_pos.loc[:,b_marker].columns.tolist()\n",
    "print(len(ls_marker))\n",
    "biom_df_columns = ['Row', 'Column', 'Celltype'] + ls_marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos.loc[:,['slide_scene','PD1']].groupby('slide_scene').sum().sort_values(by='PD1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s_scene='JP-TMA1-1_scene075'\n",
    "s_scene='JP-TMA2-1_scene34'\n",
    "centdf = df_pos[df_pos.slide_scene==s_scene]\n",
    "centdf_pd1 = df_pos[(df_pos.slide_scene==s_scene) & (df_pos.PD1)]\n",
    "#centdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.cm.Set1.colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_palette(((0.21568627450980393, 0.49411764705882355, 0.7215686274509804),(0.8941176470588236, 0.10196078431372549, 0.10980392156862745)))\n",
    "vor = Voronoi(np.c_[centdf.Column.values, centdf.Row.values])\n",
    "vor2 = Voronoi(np.c_[centdf_pd1.Column.values, centdf_pd1.Row.values])\n",
    "fig,ax = plt.subplots(figsize=(4,4),dpi=300)\n",
    "voronoi_plot_2d(vor,ax=ax,show_points=False)\n",
    "voronoi_plot_2d(vor2,ax=ax,show_points=False)\n",
    "fig.savefig('Voronoi_example.pdf')\n",
    "sns.set_palette('tab10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voronoi-based Cell-To-Cell Interactions (Patwa et al.) <a name=\"voronoi\"></a>\n",
    "\n",
    "**Purpose**: calculate cell-to-cell interactions using Voronoi diagrams.  \n",
    "**Output**: interaction matrices in intermediate_data/created_interaction_matrices. The reader can compare this output to interaction_matrices/ to ensure reproducibility.  \n",
    "**Estimated time**: 40 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(ls_marker).to_csv(f'proteins_by_frame.csv')\n",
    "# biomarker_frames = pd.read_csv(\"proteins_by_frame.csv\",index_col=0)\n",
    "# biomarker_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #voroni - done\n",
    "# # binary_infopath = \"intermediate_data/protein_positivity/\"\n",
    "# # centroid_path = \"intermediate_data/centroids/\"\n",
    "# biomarker_frames = pd.read_csv(\"proteins_by_frame.csv\")\n",
    "\n",
    "# biom_columns =  biomarker_frames[\"0\"].values\n",
    "\n",
    "# for patient in df_pos.slide_scene.unique():#os.listdir(binary_infopath):\n",
    "#     print (patient)\n",
    "#     com = np.zeros((42,42))\n",
    "#     b_patient = df_pos.slide_scene==patient\n",
    "#     centroid_df = df_pos.loc[b_patient,centroid_df_columns].copy()\n",
    "#     centroid_df.reset_index(inplace=True)\n",
    "#     biom_df = df_pos.loc[b_patient,biom_df_columns].copy()\n",
    "#     biom_df.reset_index(inplace=True)\n",
    "#     biom_df.rename(dict(zip(biomarker_frames.loc[:,'0'],biomarker_frames.index)),axis=1,inplace=True)\n",
    "#     vor = create_voronoi(centroid_df)\n",
    "#     edges = vor.ridge_points\n",
    "#     # Iterate through the ridge points because they define a certain combination\n",
    "#     for edge in edges:\n",
    "#         # Find the indices of the cells that the edge separates\n",
    "#         first_centroid = int(edge[0])\n",
    "#         second_centroid = int(edge[1])\n",
    "        \n",
    "#         # Find their expression\n",
    "#         first_cell = biom_df.loc[[first_centroid]]\n",
    "#         second_cell = biom_df.loc[[second_centroid]]\n",
    "    \n",
    "#         first_pos = []\n",
    "#         second_pos = []\n",
    "#         for column in first_cell.columns[3:]:\n",
    "#             if first_cell[column].values[0] == 1:\n",
    "#                 first_pos.append(int(column))\n",
    "#             if second_cell[column].values[0] == 1:\n",
    "#                 second_pos.append(int(column))\n",
    "        \n",
    "#         #Cartesian product of the proteins that each cell in the adjacency are positive for\n",
    "#         combinations = product(first_pos, second_pos)\n",
    "#         for comb in combinations:\n",
    "#             first_marker = comb[0]\n",
    "#             second_marker = comb[1]\n",
    "#             com[first_marker, second_marker] += 1\n",
    "#             if (first_marker != second_marker):\n",
    "#                 com[second_marker, first_marker] += 1\n",
    "#     com_df = pd.DataFrame(com, columns=biom_columns)\n",
    "#     com_df.set_index(pd.Index(biom_columns), inplace=True)\n",
    "#     com_df.to_csv(f\"intermediate_data/created_interaction_matrices/{patient}.csv\")\n",
    "#     #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sorted(os.listdir('intermediate_data/created_interaction_matrices'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #load annotation\n",
    "# df_surv = pd.read_csv('data/TMA_Survival_Subtype.csv',index_col=0)\n",
    "# df_clin = pd.read_csv('data/TMA_Clinical_Variables.csv',index_col=0)\n",
    "# df_surv.loc[df_surv.index.str.contains('JP-TMA2'),'Platform'] = 'cycIF2'\n",
    "\n",
    "# func Proteins\n",
    "ls_func = [#'Beta Catenin, CD138, CD45RO, CD63, \n",
    "    'FoxP3', 'H3K27', 'H3K9',# HLA-DR, HLA #Class 1, IDO, \n",
    "    'CK17', 'CK5', 'Ki67',  'PD1','pS6RP'] #Phospho-S6' #Lag3, p53, PD-L1,\n",
    "\n",
    "#lineage \n",
    "ls_lin = [#'CD11b, CD11c, CD16,  CD209,CD56,\n",
    "    'CD20', 'CD3', 'CD31', 'CD4', 'CD45',  'CD68', 'CD8', #dsDNA, MPO,\n",
    "  'EGFR', 'CK19', 'aSMA', 'Vim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "biomarker_frames = pd.read_csv(\"data/proteins_by_frame.csv\")\n",
    "d_markers = {'Immunoregulatory':[15],\n",
    " 'Functional':biomarker_frames[biomarker_frames.loc[:,\"0\"].isin(ls_func)].index.tolist(),\n",
    " 'Lineage':biomarker_frames[biomarker_frames.loc[:,\"0\"].isin(ls_lin)].index.tolist(),\n",
    " }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#interactions\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from lifelines import KaplanMeierFitter\n",
    "from lifelines.statistics import logrank_test\n",
    "import seaborn\n",
    "\n",
    "import lifelines\n",
    "import seaborn as sns\n",
    "\n",
    "#load clinical covariates\n",
    "df_clin = pd.read_csv('data/TMA_Clinical_Variables.csv')\n",
    "df_clin.rename({'Unnamed: 0':'ID'},axis=1,inplace=True)\n",
    "\n",
    "#Path to the clinical data. \n",
    "clinical_path = 'data/TMA_Survival_Subtype.csv'#\"rawdata/clinical_data.csv\"\n",
    "clinical_df = pd.read_csv(clinical_path, index_col=0)#[\"ID\"])\n",
    "\n",
    "#Path to interaction matrices\n",
    "matrices_path = \"data/interaction_matrices/\"\n",
    "\n",
    "for key, markers_to_include in d_markers.items():\n",
    "    # Out of all proteins, only include the functional proteins\n",
    "    #markers_to_include = [ 15] #CD44 7, PD1 15 , FoxP3 29 #[27, 31, 37, 38]\n",
    "    \n",
    "    columns = []\n",
    "    feature_list = []\n",
    "    \n",
    "    #Iterate over all of the co-occurrence matrices in this certain radius. \n",
    "    for patient_index in range(len(os.listdir(matrices_path))):\n",
    "        patient_glcm = os.listdir(matrices_path)[patient_index]\n",
    "    \n",
    "        #Skip over the pesky .DS_Store file that shows up in Mac file systems.\n",
    "        if (patient_glcm[0] == \".\"):\n",
    "            continue\n",
    "    \n",
    "        #Find the internal_ID of the current patient. \n",
    "        identifier = patient_glcm.split(\".\")[0]\n",
    "    \n",
    "    \n",
    "        #Read the co-occurrence matrix of the current patient and cast to a numpy array excluding the first col.\n",
    "        current_patient_glcm = pd.read_csv(os.path.join(matrices_path, patient_glcm), index_col=\"Unnamed: 0\")\n",
    "        current_patient_glcm.set_index(current_patient_glcm.columns, inplace=True)\n",
    "    \n",
    "        #feature_name = current_patient_glcm.columns[chosen_feature]\n",
    "        np_glcm = current_patient_glcm.to_numpy()    \n",
    "    \n",
    "        patient_features = []\n",
    "    \n",
    "        #Flatten the co-occurrence matrix into a feature vector.\n",
    "        #Cannot simply run np.flatten because the matrix is symmetrical - I only want the top-right triangle\n",
    "        #But, have to include the diagonal as well.\n",
    "        for row in range(np_glcm.shape[0]):\n",
    "            for column in range(row, np_glcm.shape[1]):\n",
    "                if row in markers_to_include and column in markers_to_include:\n",
    "                    if patient_index == 0:\n",
    "                        feature_name = current_patient_glcm.index[row] + \" \" + current_patient_glcm.columns[column]\n",
    "                        columns.append(feature_name)\n",
    "                    patient_features.append(np_glcm[row][column])\n",
    "    \n",
    "        #Find the recurrence outcome of this current patient and how long it took for them to recur\n",
    "        #Add these values to the feature list for eventual use in the Kaplan-Meier plot.\n",
    "        try:\n",
    "            patient_features.append(clinical_df.at[identifier, \"Recurrence\"]) #int(identifier)\n",
    "            patient_features.append(clinical_df.at[identifier, \"Survival\"])\n",
    "        except KeyError:\n",
    "            identifier = df_cyc_sub.at[identifier, \"Accession\"]\n",
    "            try:\n",
    "                patient_features.append(clinical_df.at[identifier, \"Recurrence\"]) #int(identifier)\n",
    "                patient_features.append(clinical_df.at[identifier, \"Survival\"])\n",
    "            except:\n",
    "                continue\n",
    "        #print(identifier)\n",
    "        patient_features.append(clinical_df.at[identifier, \"Recurrence_time\"]) #int\n",
    "        patient_features.append(clinical_df.at[identifier, \"Survival_time\"])\n",
    "        patient_features.append(identifier)\n",
    "        feature_list.append(patient_features)\n",
    "    \n",
    "    #Determine the names of the columns in the DataFrame for easier future access.\n",
    "    columns.append(\"Recurrence\")\n",
    "    columns.append(\"Survival\")\n",
    "    columns.append(\"Recurrence_time\")\n",
    "    \n",
    "    columns.append(\"Survival_time\")\n",
    "    columns.append(\"ID\")\n",
    "    \n",
    "    #Create a dataframe using the features, the recurrence events, and the time taken to recur.\n",
    "    features_df = pd.DataFrame(feature_list, columns=columns)\n",
    "    #only TNBC\n",
    "    features_df['subtype'] = features_df.ID.map(dict(zip(clinical_df.index,clinical_df.subtype)))\n",
    "    features_df = features_df[features_df.subtype=='TNBC']\n",
    "    #Obtain a versino of this dataframe with only the features.\n",
    "    data_only = features_df.drop(columns=[\"Recurrence_time\", \"Recurrence\",\"Survival\",\"Survival_time\", \"ID\",\"subtype\"])\n",
    "    data_only.set_index(features_df[\"ID\"], inplace=True)\n",
    "    \n",
    "    #Create the dendrogram.\n",
    "    if len(markers_to_include) > 1:\n",
    "        clustergram = seaborn.clustermap(data_only, method=\"weighted\",\n",
    "                                    metric=\"canberra\", standard_scale = 1, cmap=\"viridis\", figsize=(10,8), cbar_pos=None)\n",
    "        \n",
    "        plt.suptitle(f'{key} Interactions')\n",
    "        \n",
    "        #Number of clusters to take from the dendrogram\n",
    "        k = 2\n",
    "        \n",
    "        #Use scipy fcluster to find clusters from the clustered dendrograms.\n",
    "        clusters = list(fcluster(clustergram.dendrogram_row.linkage, k, criterion='maxclust'))\n",
    "        \n",
    "        unique_clusters = len(np.unique(np.array(clusters)))\n",
    "        \n",
    "        if (unique_clusters < 2):\n",
    "            print (\"Not able to find more than one cluster. \") #If there was no clustering, this method failed.\n",
    "        \n",
    "        #Create a new column in the DataFrame that includes what cluster each patient falls into\n",
    "        features_df[\"clust\"] = clusters\n",
    "        \n",
    "        first_cluster_count = clusters.count(1)\n",
    "        second_cluster_count = clusters.count(2)\n",
    "    \n",
    "    else:\n",
    "        features_df.loc[features_df.iloc[:,0]>0,\"clust\"] = 2\n",
    "        features_df.clust.fillna(1, inplace=True)\n",
    "    features_df = features_df.dropna()\n",
    "\n",
    "    \n",
    "    #Define the KaplanMeierFitter\n",
    "    lls_time = [('Survival_time', 'Survival'),\n",
    "                ('Recurrence_time', 'Recurrence')] #, \n",
    "    for s_time, s_censor in lls_time:\n",
    "        kmf = KaplanMeierFitter()\n",
    "        \n",
    "        #T = Time, E=Event. These are the two parameters that go into Kaplan-Meier curves. \n",
    "        T = features_df[s_time]\n",
    "        E = features_df[s_censor]\n",
    "        \n",
    "        group1 = (features_df[\"clust\"] == 1)\n",
    "        group2 = (features_df[\"clust\"] == 2)\n",
    "        \n",
    "        T1 = T[group1]\n",
    "        E1 = E[group1]\n",
    "        T2 = T[group2]\n",
    "        E2 = E[group2]\n",
    "        \n",
    "        color_clust1 = \"#F39B7FFF\"\n",
    "        color_clust2 = \"#4DBBD5FF\"\n",
    "        \n",
    "        # Just for visualization purposes, make the worse-outcome cluster orange and the other blue\n",
    "        if E1.mean() < E2.mean():\n",
    "            T1 = T[group2]\n",
    "            E1 = E[group2]\n",
    "            T2 = T[group1]\n",
    "            E2 = E[group1]\n",
    "        \n",
    "            features_df[\"clust\"][group1] = 2\n",
    "            features_df[\"clust\"][group2] = 1\n",
    "        \n",
    "        first_cluster_count = len(T1.index)\n",
    "        second_cluster_count = len(T2.index)\n",
    "        \n",
    "        results_first = logrank_test(T1,T2, event_observed_A=E1, event_observed_B=E2)\n",
    "        \n",
    "        p1 = round(results_first.p_value, 4)\n",
    "        \n",
    "        plt.figure(figsize=(7,8))\n",
    "        if key == 'Immunoregulatory':\n",
    "            kmf.fit(T1, E1, label='Low: n=' + str(first_cluster_count))\n",
    "            ax = kmf.plot(ci_show=False, show_censors=True, color=color_clust1, lw=5)\n",
    "            \n",
    "            kmf.fit(T2, E2, label='High: n=' + str(second_cluster_count))\n",
    "            ax = kmf.plot(ax=ax, ci_show=False, show_censors=True, color=color_clust2, lw=5)\n",
    "        else:\n",
    "            kmf.fit(T1, E1, label='Cluster 1: n=' + str(first_cluster_count))\n",
    "            ax = kmf.plot(ci_show=False, show_censors=True, color=color_clust1, lw=5)\n",
    "            \n",
    "            kmf.fit(T2, E2, label='Cluster 2: n=' + str(second_cluster_count))\n",
    "            ax = kmf.plot(ax=ax, ci_show=False, show_censors=True, color=color_clust2, lw=5)\n",
    "        plt.annotate(\"Log-rank p: \" + str(p1), xy=(0.3, 0.15), xycoords=\"figure fraction\", fontsize=25,\n",
    "            bbox=dict(facecolor='none', edgecolor='black', alpha=0.3, boxstyle=\"Round, pad=0.5, rounding_size=0.2\"))\n",
    "        plt.legend(fontsize=25,loc='upper right')\n",
    "        plt.xlabel(f\"{s_time.replace('_',' ')} (days)\", fontsize=25)\n",
    "        plt.xticks(fontsize=15)\n",
    "        if s_censor ==\"Survival\":\n",
    "            plt.ylabel(f\"Proportion Alive\", fontsize=25)\n",
    "        else:\n",
    "            plt.ylabel(f\"Proportion Non-Recurrent\", fontsize=25)\n",
    "        plt.yticks(fontsize=15)\n",
    "        plt.ylim(0,1)\n",
    "        ax.set_title(f'{key} Interactions:\\n{\" \".join([item for item in biomarker_frames.loc[markers_to_include,\"0\"]])}',fontsize=25)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"results/KM_{key}_interactions_km_{s_censor}.pdf\", dpi=300)\n",
    "        if key =='Immunoregulatory':\n",
    "            features_df['PD1 Interactions'] = features_df.clust.replace({1:'Low',2:'High'})\n",
    "            if s_censor == 'Survival': \n",
    "                fig, ax, __ = plotting.km_plot_cat(features_df,'PD1 Interactions',s_time,s_censor,fontsize='small',loc=(0.3,.74),alpha=0,figsize=(3.1,3.1),x=0.8)\n",
    "                ax.set_title('PD1 Interactions',pad=14,fontsize='x-large')\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"KM_{key}_interactions_km_{s_censor}.pdf\", dpi=300)\n",
    "    #add clinical \n",
    "    features_df = features_df.merge(df_clin,on='ID',how='left')\n",
    "    cluster_choice = 'clust'\n",
    "    df = features_df.copy()\n",
    "    \n",
    "    #manipulate the architecture distinction the variable which is originally dtype: str into a quantitative categorical variable\n",
    "    #df[\"Architecture\"] = df[\"clust\"].astype(\"category\").cat.codes\n",
    "    \n",
    "    #Create two separate feature matrices for recurrence and survival\n",
    "    recurrence_df = df.drop(columns=[\"Survival\", \"Survival_time\"])[[cluster_choice, \"Stage\", \"age\", \"tumor_size\", \"Recurrence\", \"Recurrence_time\"]]\n",
    "    survival_df = df.drop(columns=[\"Recurrence\", \"Recurrence_time\"])[[cluster_choice, \"Stage\", \"age\", \"tumor_size\", \"Survival\", \"Survival_time\"]]\n",
    "    \n",
    "    recurrence_df.dropna(inplace=True)\n",
    "    survival_df.dropna(inplace=True)\n",
    "    #Define and fit Cox PH Fitter for recurrence\n",
    "    recurrence_cph = lifelines.CoxPHFitter()\n",
    "    recurrence_cph.fit(recurrence_df, duration_col='Recurrence_time', event_col='Recurrence')\n",
    "    fig,ax=plt.subplots(figsize=(2.2,2),dpi=300)\n",
    "    recurrence_cph.plot(ax=ax)\n",
    "    pval = recurrence_cph.summary.loc['clust','p']\n",
    "    ax.set_title(f'{key} Recurrence\\np={pval:.2}')\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(f'{key}_Recurrence.pdf')\n",
    "    #recurrence_summary = recurrence_cph.print_summary()\n",
    "    \n",
    "    #Define and fit Cox PH Fitter for survival\n",
    "    survival_cph = lifelines.CoxPHFitter()\n",
    "    survival_cph.fit(survival_df, duration_col='Survival_time', event_col='Survival')\n",
    "    fig,ax=plt.subplots(figsize=(2.2,1.8),dpi=300)\n",
    "    survival_cph.plot(ax=ax)\n",
    "    pval = survival_cph.summary.loc['clust','p']\n",
    "    ax.set_title(f'{key} Survival\\np={pval:.1}')\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(f'{key}_Survival.pdf')\n",
    "    #     break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survival_cph.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# co-expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# co-expression DONE\n",
    "# #binary_infopath = \"intermediate_data/protein_positivity/\"\n",
    "# #biomarker_frames = pd.read_csv(\"rawdata/proteins_by_frame.csv\")\n",
    "\n",
    "# biom_columns = biomarker_frames[\"0\"].values\n",
    "\n",
    "# #for patient in os.listdir(binary_infopath):\n",
    "# for patient in df_pos.slide_scene.unique():#os.listdir(binary_infopath):\n",
    "#     #print (patient)\n",
    "#     com = np.zeros((42,42))\n",
    "#     b_patient = df_pos.slide_scene==patient\n",
    "#     # centroid_df = df_pos.loc[b_patient,centroid_df_columns].copy()\n",
    "#     # centroid_df.reset_index(inplace=True)\n",
    "#     infodf = df_pos.loc[b_patient,biom_df_columns].copy()\n",
    "#     infodf.reset_index(inplace=True)\n",
    "#     infodf.rename(dict(zip(biomarker_frames.loc[:,'0'],biomarker_frames.index)),axis=1,inplace=True)\n",
    "#     print (patient)\n",
    "#     #com = np.zeros((44,44))\n",
    "    \n",
    "#     #infodf = pd.read_csv(binary_infopath + patient)\n",
    "        \n",
    "#     n_cells = len(infodf.index)\n",
    "    \n",
    "#     for cell in range(n_cells):\n",
    "#         this_cell = infodf.iloc[[cell]]\n",
    "#         pos_columns = []\n",
    "#         for column in this_cell.columns[3:]:\n",
    "#             if this_cell[column].values[0] == 1:\n",
    "#                 pos_columns.append(int(column))\n",
    "#         combs = combinations(pos_columns, 2)\n",
    "#         for combination in combs:\n",
    "#             com[combination[0], combination[1]] += 1\n",
    "#             com[combination[1], combination[0]] += 1\n",
    "#     com_df = pd.DataFrame(com, columns=biom_columns)\n",
    "#     com_df.set_index(pd.Index(biom_columns), inplace=True)\n",
    "#     com_df.to_csv(f\"intermediate_data/created_coexpression_matrices/{patient}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#os.mkdir(\"intermediate_data/created_coexpression_matrices/\")\n",
    "biomarker_frames = pd.read_csv(\"data/proteins_by_frame.csv\")\n",
    "d_markers = {#'All':biomarker_frames.index.tolist(),\n",
    " 'Functional':biomarker_frames[biomarker_frames.loc[:,\"0\"].isin(ls_func)].index.tolist(),\n",
    " 'Lineage':biomarker_frames[biomarker_frames.loc[:,\"0\"].isin(ls_lin)].index.tolist(),\n",
    " #'Immunoregulatory':[15],\n",
    "}\n",
    "\n",
    "#Path to the clinical data. \n",
    "clinical_path = 'data/TMA_Survival_Subtype.csv'#\"rawdata/clinical_data.csv\"\n",
    "clinical_df = pd.read_csv(clinical_path, index_col=0)#[\"ID\"])\n",
    "\n",
    "#Path to interaction matrices\n",
    "matrices_path = \"data/coexpression_matrices/\"\n",
    "\n",
    "for key, markers_to_include in d_markers.items():\n",
    "    # Out of all proteins, only include the functional proteins\n",
    "    #markers_to_include = [ 15] #CD44 7, PD1 15 , FoxP3 29 #[27, 31, 37, 38]\n",
    "    \n",
    "    columns = []\n",
    "    feature_list = []\n",
    "    \n",
    "    #Iterate over all of the co-occurrence matrices in this certain radius. \n",
    "    for patient_index in range(len(os.listdir(matrices_path))):\n",
    "        patient_glcm = os.listdir(matrices_path)[patient_index]\n",
    "    \n",
    "        #Skip over the pesky .DS_Store file that shows up in Mac file systems.\n",
    "        if (patient_glcm[0] == \".\"):\n",
    "            continue\n",
    "    \n",
    "        #Find the internal_ID of the current patient. \n",
    "        identifier = patient_glcm.split(\".\")[0]\n",
    "    \n",
    "    \n",
    "        #Read the co-occurrence matrix of the current patient and cast to a numpy array excluding the first col.\n",
    "        current_patient_glcm = pd.read_csv(os.path.join(matrices_path, patient_glcm), index_col=\"Unnamed: 0\")\n",
    "        current_patient_glcm.set_index(current_patient_glcm.columns, inplace=True)\n",
    "    \n",
    "        #feature_name = current_patient_glcm.columns[chosen_feature]\n",
    "        np_glcm = current_patient_glcm.to_numpy()    \n",
    "    \n",
    "        patient_features = []\n",
    "    \n",
    "        #Flatten the co-occurrence matrix into a feature vector.\n",
    "        #Cannot simply run np.flatten because the matrix is symmetrical - I only want the top-right triangle\n",
    "        #But, have to include the diagonal as well.\n",
    "        for row in range(np_glcm.shape[0]):\n",
    "            for column in range(row, np_glcm.shape[1]):\n",
    "                if row in markers_to_include and column in markers_to_include:\n",
    "                    if patient_index == 0:\n",
    "                        feature_name = current_patient_glcm.index[row] + \" \" + current_patient_glcm.columns[column]\n",
    "                        columns.append(feature_name)\n",
    "                    patient_features.append(np_glcm[row][column])\n",
    "    \n",
    "        #Find the recurrence outcome of this current patient and how long it took for them to recur\n",
    "        #Add these values to the feature list for eventual use in the Kaplan-Meier plot.\n",
    "        try:\n",
    "            patient_features.append(clinical_df.at[identifier, \"Recurrence\"]) #int(identifier)\n",
    "            patient_features.append(clinical_df.at[identifier, \"Survival\"])\n",
    "        except KeyError:\n",
    "            identifier = df_cyc_sub.at[identifier, \"Accession\"]\n",
    "            try:\n",
    "                patient_features.append(clinical_df.at[identifier, \"Recurrence\"]) #int(identifier)\n",
    "                patient_features.append(clinical_df.at[identifier, \"Survival\"])\n",
    "            except:\n",
    "                continue\n",
    "        #print(identifier)\n",
    "        patient_features.append(clinical_df.at[identifier, \"Recurrence_time\"]) #int\n",
    "        patient_features.append(clinical_df.at[identifier, \"Survival_time\"])\n",
    "        patient_features.append(identifier)\n",
    "        feature_list.append(patient_features)\n",
    "    \n",
    "    #Determine the names of the columns in the DataFrame for easier future access.\n",
    "    columns.append(\"Recurrence\")\n",
    "    columns.append(\"Survival\")\n",
    "    columns.append(\"Recurrence_time\")\n",
    "    \n",
    "    columns.append(\"Survival_time\")\n",
    "    columns.append(\"ID\")\n",
    "    \n",
    "    #Create a dataframe using the features, the recurrence events, and the time taken to recur.\n",
    "    features_df = pd.DataFrame(feature_list, columns=columns)\n",
    "    #only TNBC\n",
    "    features_df['subtype'] = features_df.ID.map(dict(zip(clinical_df.index,clinical_df.subtype)))\n",
    "    features_df = features_df[features_df.subtype=='TNBC']\n",
    "    #Obtain a versino of this dataframe with only the features.\n",
    "    data_only = features_df.drop(columns=[\"Recurrence_time\", \"Recurrence\",\"Survival\",\"Survival_time\", \"ID\",\"subtype\"])\n",
    "    data_only.set_index(features_df[\"ID\"], inplace=True)\n",
    "    ls_drop = data_only.loc[:,data_only.sum() == 0].columns\n",
    "    data_only.drop(ls_drop,axis=1,inplace=True)\n",
    "    #Create the dendrogram.\n",
    "    if len(markers_to_include) > 1:\n",
    "        clustergram = seaborn.clustermap(data_only, method=\"weighted\",\n",
    "                                    metric=\"canberra\", standard_scale = 1, cmap=\"viridis\", figsize=(10,8), cbar_pos=None)\n",
    "        \n",
    "        plt.suptitle(f'{key} Co-expression')\n",
    "        \n",
    "        #Number of clusters to take from the dendrogram\n",
    "        k = 2\n",
    "        \n",
    "        #Use scipy fcluster to find clusters from the clustered dendrograms.\n",
    "        clusters = list(fcluster(clustergram.dendrogram_row.linkage, k, criterion='maxclust'))\n",
    "        \n",
    "        unique_clusters = len(np.unique(np.array(clusters)))\n",
    "        \n",
    "        if (unique_clusters < 2):\n",
    "            print (\"Not able to find more than one cluster. \") #If there was no clustering, this method failed.\n",
    "        \n",
    "        #Create a new column in the DataFrame that includes what cluster each patient falls into\n",
    "        features_df[\"clust\"] = clusters\n",
    "        \n",
    "        first_cluster_count = clusters.count(1)\n",
    "        second_cluster_count = clusters.count(2)\n",
    "    \n",
    "    else:\n",
    "        features_df.loc[features_df.iloc[:,0]>0,\"clust\"] = 2\n",
    "        features_df.clust.fillna(1, inplace=True)\n",
    "    features_df = features_df.dropna()\n",
    "    \n",
    "    #Define the KaplanMeierFitter\n",
    "    lls_time = [('Survival_time', 'Survival'),\n",
    "                ('Recurrence_time', 'Recurrence')] #, \n",
    "    for s_time, s_censor in lls_time:\n",
    "        kmf = KaplanMeierFitter()\n",
    "        \n",
    "        #T = Time, E=Event. These are the two parameters that go into Kaplan-Meier curves. \n",
    "        T = features_df[s_time]\n",
    "        E = features_df[s_censor]\n",
    "        \n",
    "        group1 = (features_df[\"clust\"] == 1)\n",
    "        group2 = (features_df[\"clust\"] == 2)\n",
    "        \n",
    "        T1 = T[group1]\n",
    "        E1 = E[group1]\n",
    "        T2 = T[group2]\n",
    "        E2 = E[group2]\n",
    "        \n",
    "        color_clust1 = \"#F39B7FFF\"\n",
    "        color_clust2 = \"#4DBBD5FF\"\n",
    "        \n",
    "        # Just for visualization purposes, make the worse-outcome cluster orange and the other blue\n",
    "        if E1.mean() < E2.mean():\n",
    "            T1 = T[group2]\n",
    "            E1 = E[group2]\n",
    "            T2 = T[group1]\n",
    "            E2 = E[group1]\n",
    "        \n",
    "            features_df[\"clust\"][group1] = 2\n",
    "            features_df[\"clust\"][group2] = 1\n",
    "        \n",
    "        first_cluster_count = len(T1.index)\n",
    "        second_cluster_count = len(T2.index)\n",
    "        \n",
    "        results_first = logrank_test(T1,T2, event_observed_A=E1, event_observed_B=E2)\n",
    "        \n",
    "        p1 = round(results_first.p_value, 4)\n",
    "        \n",
    "        plt.figure(figsize=(7,8))\n",
    "        kmf.fit(T1, E1, label='Cluster 1: n=' + str(first_cluster_count))\n",
    "        ax = kmf.plot(ci_show=False, show_censors=True, color=color_clust1, lw=5)\n",
    "        \n",
    "        kmf.fit(T2, E2, label='Cluster 2: n=' + str(second_cluster_count))\n",
    "        ax = kmf.plot(ax=ax, ci_show=False, show_censors=True, color=color_clust2, lw=5)\n",
    "        plt.annotate(\"Log-rank p: \" + str(p1), xy=(0.6, 0.15), xycoords=\"figure fraction\", fontsize=25,\n",
    "            bbox=dict(facecolor='none', edgecolor='black', alpha=0.3, boxstyle=\"Round, pad=0.5, rounding_size=0.2\"))\n",
    "        plt.legend(fontsize=25,loc='upper right')\n",
    "        plt.xlabel(s_time, fontsize=25)\n",
    "        plt.xticks(fontsize=15)\n",
    "        if s_censor ==\"Survival\":\n",
    "            plt.ylabel(f\"Proportion Alive\", fontsize=25)\n",
    "        else:\n",
    "            plt.ylabel(f\"Proportion Non-Recurrent\", fontsize=25)\n",
    "        plt.yticks(fontsize=15)\n",
    "        plt.ylim(0,1)\n",
    "        ax.set_title(f'{key} Co-expression:\\n{\" \".join([item for item in biomarker_frames.loc[markers_to_include,\"0\"]])}',fontsize=25)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plt.savefig(f\"results/KM_{key}_coexpression_km_{s_censor}.pdf\", dpi=300)\n",
    "    #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add clinical covariates to immunoregulatory\n",
    "df_clin = pd.read_csv('data/TMA_Clinical_Variables.csv')\n",
    "df_clin.rename({'Unnamed: 0':'ID'},axis=1,inplace=True)\n",
    "features_df = features_df.merge(df_clin,on='ID',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lifelines\n",
    "import seaborn as sns\n",
    "\n",
    "# CSV_PATH = \"intermediate_data/covariate_rsf_data.csv\" #put path to csv summarizing cluster features, clinical variables, architecutre distinction, and clinical outcome\n",
    "\n",
    "# #Read csv summarizing cluster features, clinical variables, morphology distinction, and clinical outcome\n",
    "# df = pd.read_csv(CSV_PATH, index_col=\"ID\")\n",
    "\n",
    "# #define which cluster feature to examine\n",
    "# #options: [coexpression_cluster, functional_proteins_cluster, immunoregulatory_protein_cluster]\n",
    "# #can either examine each one-at-a-time or iterate through them\n",
    "# cluster_choice = \"coexpression_cluster\" \n",
    "cluster_choice = 'clust'\n",
    "df = features_df.copy()\n",
    "\n",
    "#manipulate the architecture distinction the variable which is originally dtype: str into a quantitative categorical variable\n",
    "#df[\"Architecture\"] = df[\"clust\"].astype(\"category\").cat.codes\n",
    "\n",
    "#Create two separate feature matrices for recurrence and survival\n",
    "recurrence_df = df.drop(columns=[\"Survival\", \"Survival_time\"])[[cluster_choice, \"Stage\", \"age\", \"tumor_size\", \"Recurrence\", \"Recurrence_time\"]]\n",
    "survival_df = df.drop(columns=[\"Recurrence\", \"Recurrence_time\"])[[cluster_choice, \"Stage\", \"age\", \"tumor_size\", \"Survival\", \"Survival_time\"]]\n",
    "\n",
    "recurrence_df.dropna(inplace=True)\n",
    "survival_df.dropna(inplace=True)\n",
    "#Define and fit Cox PH Fitter for recurrence\n",
    "recurrence_cph = lifelines.CoxPHFitter()\n",
    "recurrence_cph.fit(recurrence_df, duration_col='Recurrence_time', event_col='Recurrence')\n",
    "fig,ax=plt.subplots(figsize=(3,1.5),dpi=300)\n",
    "recurrence_cph.plot(ax=ax)\n",
    "pval = recurrence_cph.summary.loc['clust','p']\n",
    "ax.set_title(f'Co-expression Recurrence\\np={pval:.2}')\n",
    "#recurrence_summary = recurrence_cph.print_summary()\n",
    "\n",
    "#Define and fit Cox PH Fitter for survival\n",
    "survival_cph = lifelines.CoxPHFitter()\n",
    "survival_cph.fit(survival_df, duration_col='Survival_time', event_col='Survival')\n",
    "fig,ax=plt.subplots(figsize=(3,1.5),dpi=300)\n",
    "survival_cph.plot(ax=ax)\n",
    "pval = survival_cph.summary.loc['clust','p']\n",
    "ax.set_title(f'Co-expression Survival\\np={pval:.1}')#\n",
    "#survival_summary = survival_cph.print_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survival_cph.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## distances <a name=\"dist\"></a>\n",
    "\n",
    "- distance to non-cellular components in ECM\n",
    "\n",
    "- as in Johnson et al Cell Rep Med 2022\n",
    "\n",
    "- old, did not use\n",
    "\n",
    "\n",
    "[contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#neighbor distance\n",
    "# collagen detection\n",
    "'''\n",
    "# ColI, ColIV\n",
    "d_thresh =  {'SMT101Bx2-5-Scene-001':[3.8,18],\n",
    " 'SMT101Bx2-5-Scene-002':[3.8,18],\n",
    " 'SMT101Bx3-Scene-004': [9,7],\n",
    " 'SMT101Bx4-3-Scene-001': [15,4],\n",
    " 'SMT101Bx4-3-Scene-002': [6,4]\n",
    " }\n",
    "from mplex_image import features\n",
    "import importlib\n",
    "importlib.reload(features)\n",
    "from skimage import io\n",
    "from matplotlib.colors import LogNorm\n",
    "df_thresh = pd.read_csv('/home/groups/graylab_share/OMERO.rdsStore/engje/Data/20201105_SMT101/101paper_data/thresh_JE_SMT101.csv',index_col=0)\n",
    "for s_sample in ls_sample:\n",
    "    df_xy = pd.read_csv(f'{segdir}/features_{s_sample}_CentroidXY.csv',index_col=0)\n",
    "    os.chdir(f'{subdir}/{s_sample}')\n",
    "    df_img = mpimage.parse_org()\n",
    "    for idxs, s_marker in enumerate(['CD31','PDPN','Vim','aSMA','CD68','ColI','ColIV']):\n",
    "        df_marker = df_img[(df_img.marker==s_marker) & (df_img.scene=='SMT101Bx3-Scene-004')]\n",
    "        df_dist = pd.DataFrame()\n",
    "        for idx, s_index in enumerate(df_marker.index):\n",
    "            img = io.imread(s_index)\n",
    "            s_scene = df_marker.loc[s_index,'scene']\n",
    "            print(s_scene)\n",
    "            #i_thresh = d_thresh[s_scene][idxs]*256\n",
    "            i_thresh = df_thresh.loc[s_scene.replace('-Scene-','_scene'),s_marker]*256\n",
    "            mask = img > i_thresh\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.imshow(mask)\n",
    "            fig.savefig(f'{qcdir}/mask_{s_scene}_{s_marker}.pdf',dpi=200)\n",
    "            mask_out,shrunk_mask,maskdist,distances = features.mask_border(~mask,type='inner',pixel_distance= 50)\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.imshow(distances.clip(min=0.01), norm=LogNorm(vmin=0.01, vmax=2000))\n",
    "            fig.savefig(f'{qcdir}/mask_{s_scene}_{s_marker}_distances.pdf',dpi=200)\n",
    "            df_scene = features.cell_distances(df_xy,s_scene,distances)\n",
    "            df_dist = df_dist.append(df_scene)\n",
    "        df_dist.rename({'pixel_dist':f'{s_marker}_dist'},axis=1,inplace=True)\n",
    "        df_xy = df_xy.merge(df_dist.loc[:,f'{s_marker}_dist'],left_index=True,right_index=True,how='left')\n",
    "    df_xy.to_csv(f'{segdir}/features_{s_sample}_MaskDistances.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy\n",
    "# def mask_border(mask,type='inner',pixel_distance = 50):\n",
    "#     '''\n",
    "#     for inner, distance transform from mask to background\n",
    "#     for outer, distance transform from back ground to mask\n",
    "#     returns a mask\n",
    "#     '''\n",
    "#     shrunk_mask = mask.copy()\n",
    "#     if type == 'inner':\n",
    "#         foreground = ~mask\n",
    "#         background = mask\n",
    "#     elif type == 'outer':\n",
    "#         foreground = ~mask\n",
    "#         background = mask\n",
    "#     distances, (i, j) = scipy.ndimage.distance_transform_edt(\n",
    "#                 background, return_indices=True\n",
    "#             )\n",
    "#     maskdist = mask & (distances <= pixel_distance)\n",
    "#     shrunk_mask[maskdist] = shrunk_mask[i[maskdist], j[maskdist]]\n",
    "#     mask_out = np.logical_and(mask,np.logical_not(shrunk_mask))\n",
    "#     return(mask_out,shrunk_mask,maskdist,distances)\n",
    "\n",
    "# def cell_distances(df_scene,distances):\n",
    "#     '''\n",
    "#     load a binary mask of tissue, cell labels, and xy coord datafreame.\n",
    "#     return data frame of cells witin binary mask\n",
    "#     '''\n",
    "#     df_scene = df_scene.copy()\n",
    "#     df_scene['DAPI_Y'] = df_scene.DAPI_Y.astype('int64')\n",
    "#     df_scene['DAPI_X'] = df_scene.DAPI_X.astype('int64')\n",
    "#     df_scene['pixel_dist'] = distances[df_scene.DAPI_Y,df_scene.DAPI_X]\n",
    "#     return(df_scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #mask will be positive cell centroids\n",
    "# df_result = pd.DataFrame()\n",
    "# for s_scene in sorted(set(df_lei.slide_scene)):\n",
    "#     print(s_scene)\n",
    "#     df_scene = df_lei[df_lei.slide_scene==s_scene]   \n",
    "#     df_result_scene=pd.DataFrame(index=df_scene.index)\n",
    "#     for s_cell in df_scene.leiden.unique():\n",
    "#         #print(s_cell)\n",
    "#         a_scene = np.zeros(shape=(round(df_scene.DAPI_Y.max()+1),round(df_scene.DAPI_X.max())+1),dtype='int')\n",
    "#         df_cell = df_scene[df_scene.leiden==s_cell]\n",
    "#         #print(len(df_cell))\n",
    "#         a_scene[round(df_cell.DAPI_Y).astype('int').values,round(df_cell.DAPI_X).astype('int').values] = 255\n",
    "#         mask = a_scene > 200\n",
    "#         distances, (i, j) = scipy.ndimage.distance_transform_edt(~mask, return_indices=True)\n",
    "#         df_scene_dist = cell_distances(df_scene.loc[:,['DAPI_X','DAPI_Y']],distances)\n",
    "#         df_result_scene[f'{s_cell}_dist'] = df_scene_dist.pixel_dist\n",
    "#         #break\n",
    "#     df_result = df_result.append(df_result_scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_result.to_csv(f'{codedir}/data/{s_sample}_PixelDistances.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax=plt.subplots()\n",
    "# ax.imshow(distances.clip(min=0.01),norm=LogNorm(vmin=0.01, vmax=3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lei = pd.read_csv(f'{codedir}/data/20220118_JP-TMAs_LeidenClustering_neighbors30_resolution0.4_markers22_2sub.csv',index_col=0)\n",
    "# df_lei['slide_scene'] = [item.split('_cell')[0] for item in df_lei.index]\n",
    "# df_lei['Patient'] = df_lei.slide_scene.map(dict(zip(df_cyc_sub.index,df_cyc_sub.Accession)))\n",
    "# df_lei['subtype'] = df_lei.slide_scene.map(dict(zip(df_cyc_sub.index,df_cyc_sub.ID)))\n",
    "# df_lei['leidencelltype2'] = df_lei.leidencelltype3.replace({'tumor':'epithelial','endothelial':'stromal','immune':'stromal'})\n",
    "# df_lei['celltype1'] = 'all'\n",
    "# df_lei['countme'] = True\n",
    "# df_lei['Platform'] = 'cycIF'\n",
    "# df_lei['gatedcelltype3'] = df_lei.celltype.replace({'endothelial':'stromal'})\n",
    "# df_lei['leiden'] = df_lei.leiden.replace(d_celltype_cycif)\n",
    "# df_lei = df_lei.rename({'aSMA':'SMA'},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_sample = '20220118_JP-TMAs_s'\n",
    "# df_dist = pd.read_csv(f'{codedir}/data/{s_sample}_PixelDistances.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joypy import joyplot\n",
    "# s_subtype = 'ER+'\n",
    "# ls_er_index = df_lei[(df_lei.leiden=='Luminal ER+ t.') & (df_lei.subtype==s_subtype)].index\n",
    "# ls_pro_index = df_lei[(df_lei.leiden=='Proliferating t.')& (df_lei.subtype==s_subtype)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #proliferating cell counts\n",
    "# ls_str = ['Vim++ str._dist','NOS str._dist', 'Macrophage_dist', 'Endothelial_dist',\n",
    "#         'CD3 T cell_dist', 'CD44+ str._dist', \n",
    "#       'ECM++ str._dist', 'CD20 B cell_dist', ]\n",
    "# ls_tum = ['Vim+ t._dist', 'Ecad- t._dist', 'poorly diff t._dist', 'Basal t._dist','Large t._dist',\n",
    "#          'Myoepithelial_dist', #'Proliferating t._dist',\n",
    "#           'CD44+ t._dist', 'EGFR hi t._dist','Luminal ER+ t._dist',\n",
    "#           'Luminal t._dist', 'Luminal hi t._dist']\n",
    "# fig, ax = joyplot(data=df_dist.loc[ls_pro_index,df_dist.loc[ls_pro_index,ls_str].mean().sort_values().index],grid=True)\n",
    "# fig2, ax2 = joyplot(data=df_dist.loc[ls_pro_index,df_dist.loc[ls_pro_index,ls_tum].mean().sort_values().index],grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #ER + cell counts\n",
    "# ls_str = ['NOS str._dist', 'Macrophage_dist', 'Endothelial_dist',\n",
    "#        'Vim++ str._dist', 'CD3 T cell_dist', 'CD44+ str._dist', \n",
    "#       'ECM++ str._dist', 'CD20 B cell_dist', ]\n",
    "# ls_tum = ['Vim+ t._dist', 'Ecad- t._dist', 'poorly diff t._dist', 'Large t._dist','Basal t._dist',\n",
    "#          'Myoepithelial_dist', 'Proliferating t._dist','CD44+ t._dist', 'EGFR hi t._dist',#'Luminal ER+ t._dist',\n",
    "#           'Luminal t._dist', 'Luminal hi t._dist']\n",
    "# fig, ax = joyplot(data=df_dist.loc[ls_er_index,df_dist.loc[ls_er_index,ls_str].mean().sort_values().index],grid=True)\n",
    "# fig2, ax2 = joyplot(data=df_dist.loc[ls_er_index,df_dist.loc[ls_er_index,ls_tum].mean().sort_values().index],grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #ER expression vs stromal\n",
    "# bins = pd.IntervalIndex.from_tuples([(75, 150), (150, 225), (225, 300), (300, 375), (375, 450), (450, 525), (525, 600)])\n",
    "\n",
    "# df_er = df_lei.loc[ls_er_index,['ER']]\n",
    "# for s_dist in ls_str:  #df_dist.columns:\n",
    "#     df_dist.loc[ls_er_index,s_dist]\n",
    "#     #se_q,bins = pd.qcut(x=df_dist.loc[ls_er_index,s_dist], q=20,retbins=True)\n",
    "#     se_q = pd.cut(df_dist.loc[ls_er_index,s_dist], bins)\n",
    "#     s_cell = s_dist.split('_dist')[0]\n",
    "#     df_er['Distance_Quartile'] = se_q\n",
    "#     df_er[f'{s_dist}_Quartile'] = se_q\n",
    "#     print(s_dist)\n",
    "#     df_er.groupby('Distance_Quartile').median().plot(title=s_dist)\n",
    "#     df_er.groupby('Distance_Quartile').mean().plot(title=s_dist)\n",
    "#     #plot\n",
    "#     fig,ax = joyplot(data=df_er.dropna(),by='Distance_Quartile',grid=True)\n",
    "#     ax[0].set_title(s_cell)\n",
    "#     #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ls_columns= ['Vim++ str._dist_Quartile', 'NOS str._dist_Quartile',\n",
    "#        'Macrophage_dist_Quartile', 'Endothelial_dist_Quartile',\n",
    "#        'CD3 T cell_dist_Quartile', 'CD44+ str._dist_Quartile',\n",
    "#        'ECM++ str._dist_Quartile', 'CD20 B cell_dist_Quartile']\n",
    "# #\n",
    "# df_er['slide_scene'] =[item.split('_cell')[0] for item in df_er.index]\n",
    "# for s_marker in ls_columns:\n",
    "#     df_plot = df_er.drop('Distance_Quartile',axis=1).groupby(['slide_scene',s_marker]).mean().reset_index()\n",
    "#     fig,ax=plt.subplots()\n",
    "#     sns.boxplot(data=df_plot,y='ER',x=s_marker,showfliers=False,ax=ax,palette='muted')\n",
    "#     sns.stripplot(data=df_plot,y='ER',x=s_marker,ax=ax,palette='dark')\n",
    "#     ax.set_title(s_marker)\n",
    "#     ax.set_ylim(0,5)\n",
    "#     #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #ER expression vs tumor\n",
    "# ls_tum = ['Vim+ t._dist', 'Ecad- t._dist', 'poorly diff t._dist', 'Basal t._dist','Large t._dist',\n",
    "#          'Myoepithelial_dist', 'Proliferating t._dist','CD44+ t._dist', #'EGFR hi t._dist',#'Luminal ER+ t._dist',\n",
    "#           'Luminal t._dist', 'Luminal hi t._dist']\n",
    "# df_er = df_lei.loc[ls_er_index,['ER']]\n",
    "# for s_dist in ls_tum:  #df_dist.columns:\n",
    "#     df_dist.loc[ls_er_index,s_dist]\n",
    "#     #se_q,bins = pd.qcut(x=df_dist.loc[ls_er_index,s_dist], q=15,retbins=True)\n",
    "#     se_q = pd.cut(df_dist.loc[ls_er_index,s_dist], bins)\n",
    "#     s_cell = s_dist.split('_dist')[0]\n",
    "#     df_er['Distance_Quartile'] = se_q\n",
    "#     df_er[f'{s_dist}_Quartile'] = se_q\n",
    "#     #plot\n",
    "#     fig,ax = joyplot(data=df_er.dropna(),by='Distance_Quartile',grid=True)\n",
    "#     ax[0].set_title(s_cell)\n",
    "#     #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls_columns = ['Vim+ t._dist_Quartile',\n",
    "#        'Ecad- t._dist_Quartile', 'poorly diff t._dist_Quartile',\n",
    "#        'Basal t._dist_Quartile', 'Large t._dist_Quartile',\n",
    "#        'Myoepithelial_dist_Quartile', 'Proliferating t._dist_Quartile',\n",
    "#        'CD44+ t._dist_Quartile', 'Luminal t._dist_Quartile']\n",
    "# #\n",
    "# df_er['slide_scene'] =[item.split('_cell')[0] for item in df_er.index]\n",
    "# for s_marker in ls_columns:\n",
    "#     df_plot = df_er.drop('Distance_Quartile',axis=1).groupby(['slide_scene',s_marker]).mean().reset_index()\n",
    "#     fig,ax=plt.subplots()\n",
    "#     sns.boxplot(data=df_plot,y='ER',x=s_marker,showfliers=False,ax=ax,palette='muted')\n",
    "#     sns.stripplot(data=df_plot,y='ER',x=s_marker,ax=ax,palette='dark')\n",
    "#     ax.set_title(s_marker)\n",
    "#     ax.set_ylim(0,5)\n",
    "#     #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_er = df_lei.loc[ls_pro_index,['Ki67']]\n",
    "# df_ki67 = df_er.copy()\n",
    "# ls_str = ['NOS str._dist', 'Macrophage_dist', 'Endothelial_dist',\n",
    "#        'Vim++ str._dist',\n",
    "#           'CD3 T cell_dist', 'CD44+ str._dist', \n",
    "#       'ECM++ str._dist', 'CD20 B cell_dist',\n",
    "#          ]\n",
    "# for s_dist in ls_str:  #df_dist.columns:\n",
    "#     df_dist.loc[ls_pro_index,s_dist]\n",
    "#     #se_q,bins = pd.qcut(x=df_dist.loc[ls_pro_index,s_dist], q=20,retbins=True)\n",
    "#     se_q = pd.cut(df_dist.loc[ls_pro_index,s_dist], bins)\n",
    "#     s_cell = s_dist.split('_dist')[0]\n",
    "#     df_er['Distance_Quartile'] = se_q\n",
    "#     df_ki67[f'{s_dist}_Quartile'] = se_q\n",
    "#     #df_er.groupby('Distance_Quartile').median().plot(title=s_dist)\n",
    "#     #df_er.groupby('Distance_Quartile').mean().plot(title=s_dist)\n",
    "#     #plot\n",
    "#     fig,ax = joyplot(data=df_er.dropna(),by='Distance_Quartile',grid=True)\n",
    "#     ax[0].set_title(s_cell)\n",
    "#     #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ls_columns= ['Vim++ str._dist_Quartile', 'NOS str._dist_Quartile',\n",
    "#        'Macrophage_dist_Quartile', 'Endothelial_dist_Quartile',\n",
    "#        'CD3 T cell_dist_Quartile', 'CD44+ str._dist_Quartile',\n",
    "#        'ECM++ str._dist_Quartile', 'CD20 B cell_dist_Quartile']\n",
    "# #\n",
    "# df_ki67['slide_scene'] =[item.split('_cell')[0] for item in df_ki67.index]\n",
    "# for s_marker in ls_columns:\n",
    "#     df_plot = df_ki67.groupby(['slide_scene',s_marker]).mean().reset_index()\n",
    "#     fig,ax=plt.subplots()\n",
    "#     sns.boxplot(data=df_plot,y='Ki67',x=s_marker,showfliers=False,ax=ax,palette='muted')\n",
    "#     sns.stripplot(data=df_plot,y='Ki67',x=s_marker,ax=ax,palette='dark')\n",
    "#     ax.set_title(s_marker)\n",
    "#     ax.set_ylim(0,5)\n",
    "#     #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ls_tum = ['Vim+ t._dist', 'Ecad- t._dist', 'poorly diff t._dist', #'Basal t._dist',\n",
    "#           'Large t._dist',\n",
    "#          'Myoepithelial_dist',# 'Proliferating t._dist',\n",
    "#           'CD44+ t._dist', 'EGFR hi t._dist','Luminal ER+ t._dist',\n",
    "#           'Luminal t._dist', 'Luminal hi t._dist']\n",
    "# for s_dist in ls_tum:  #df_dist.columns:\n",
    "#     df_dist.loc[ls_pro_index,s_dist]\n",
    "#     #se_q,bins = pd.qcut(x=df_dist.loc[ls_pro_index,s_dist], q=15,retbins=True)\n",
    "#     se_q = pd.cut(df_dist.loc[ls_pro_index,s_dist], bins)\n",
    "#     s_cell = s_dist.split('_dist')[0]\n",
    "#     df_er['Distance_Quartile'] = se_q\n",
    "#     df_ki67[f'{s_dist}_Quartile'] = se_q\n",
    "#     #plot\n",
    "#     fig,ax = joyplot(data=df_er.dropna(),by='Distance_Quartile',grid=True)\n",
    "#     ax[0].set_title(s_cell)\n",
    "#     #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ls_columns= ['Vim+ t._dist_Quartile', 'Ecad- t._dist_Quartile',\n",
    "#        'poorly diff t._dist_Quartile', 'Large t._dist_Quartile',\n",
    "#        'Myoepithelial_dist_Quartile', 'CD44+ t._dist_Quartile',\n",
    "#        'EGFR hi t._dist_Quartile', 'Luminal ER+ t._dist_Quartile',\n",
    "#        'Luminal t._dist_Quartile', 'Luminal hi t._dist_Quartile']\n",
    "# #\n",
    "# df_ki67['slide_scene'] =[item.split('_cell')[0] for item in df_ki67.index]\n",
    "# for s_marker in ls_columns:\n",
    "#     df_plot = df_ki67.groupby(['slide_scene',s_marker]).mean().reset_index()\n",
    "#     fig,ax=plt.subplots()\n",
    "#     sns.boxplot(data=df_plot,y='Ki67',x=s_marker,showfliers=False,ax=ax,palette='muted')\n",
    "#     sns.stripplot(data=df_plot,y='Ki67',x=s_marker,ax=ax,palette='dark')\n",
    "#     ax.set_title(s_marker)\n",
    "#     ax.set_ylim(0,10)\n",
    "#     #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
